{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tselane2110/Brain-Tumor-Detection-And-Classification/blob/main/implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sbIIjUI3Nd8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64645dc2-3c67-4cac-e9c5-c6cb2daaa9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SSCLNet-Implementation'...\n",
            "remote: Enumerating objects: 307, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "Receiving objects: 100% (307/307), 589.57 KiB | 7.86 MiB/s, done.\n",
            "remote: Total 307 (delta 95), reused 74 (delta 32), pack-reused 143 (from 1)\u001b[K\n",
            "Resolving deltas: 100% (170/170), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tselane2110/SSCLNet-Implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SSCLNet-Implementation"
      ],
      "metadata": {
        "id": "VDBJRkIFBIt0",
        "outputId": "bd9ef50b-2e30-48c8-ed6c-924eef833625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SSCLNet-Implementation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Loading & Preprocessing"
      ],
      "metadata": {
        "id": "bp8ivRpez212"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dataset"
      ],
      "metadata": {
        "id": "Ks6yLvOFN1Fn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.load_data(\"https://drive.google.com/file/d/1Ke4oXJiZiUnomAwUfjjlmxzeI6HK1Zz4/view?usp=drive_link\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gSSgcKkYBAvF",
        "outputId": "45c2324d-a9d6-4549-f597-31e492b75287"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Ke4oXJiZiUnomAwUfjjlmxzeI6HK1Zz4\n",
            "From (redirected): https://drive.google.com/uc?id=1Ke4oXJiZiUnomAwUfjjlmxzeI6HK1Zz4&confirm=t&uuid=15b8be63-fa48-4326-ba61-93b106a6d06c\n",
            "To: /content/dataset.zip\n",
            "100%|██████████| 429M/429M [00:01<00:00, 287MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Dataset ready at: /content/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# moving dataset folder\n",
        "!mv /content/content/Dataset-Brain-MRI /content"
      ],
      "metadata": {
        "id": "7JbNO_HZNSab"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting the extra \"content\" folder\n",
        "!rm -r /content/content"
      ],
      "metadata": {
        "id": "nPI7f3UZOusU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting the \"duplicates_backup\" folder from the \"Dataset-Brain-MRI\" folder, since we wont be using it anyways\n",
        "!rm -r /content/Dataset-Brain-MRI/duplicates_backup"
      ],
      "metadata": {
        "id": "mTxUE_twPGck"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.split_data_disjoint_pretrain(\"/content/Dataset-Brain-MRI\", \"/content/splitted-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzkojWZpBffN",
        "outputId": "227798ca-5358-44ad-e791-80c8ab34e25a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting DISJOINT dataset splitting (70% pretrain, 20% train, 10% test)...\n",
            "Input directory: /content/Dataset-Brain-MRI\n",
            "Output directory: /content/splitted-dataset\n",
            "Created: /content/splitted-dataset/pretrain\n",
            "Created: /content/splitted-dataset/train/2-class/yes\n",
            "Created: /content/splitted-dataset/train/2-class/no\n",
            "Created: /content/splitted-dataset/train/4-class/glioma_tumor\n",
            "Created: /content/splitted-dataset/train/4-class/meningioma_tumor\n",
            "Created: /content/splitted-dataset/train/4-class/no_tumor\n",
            "Created: /content/splitted-dataset/train/4-class/pituitary_tumor\n",
            "Created: /content/splitted-dataset/test/2-class/yes\n",
            "Created: /content/splitted-dataset/test/2-class/no\n",
            "Created: /content/splitted-dataset/test/4-class/glioma_tumor\n",
            "Created: /content/splitted-dataset/test/4-class/meningioma_tumor\n",
            "Created: /content/splitted-dataset/test/4-class/no_tumor\n",
            "Created: /content/splitted-dataset/test/4-class/pituitary_tumor\n",
            "\n",
            "Total images collected: 11073\n",
            "\n",
            "Copying files...\n",
            "\n",
            "=== SPLITTING COMPLETED ===\n",
            "Pre-train: 7751 images (70% of total)\n",
            "Train: 2214 images (20% of total)\n",
            "Test: 1108 images (10% of total)\n",
            "Total: 11073 images\n",
            "\n",
            "Final structure:\n",
            "/content/splitted-dataset/\n",
            "├── pretrain/          # 70% of ALL data (no labels needed)\n",
            "├── train/\n",
            "│   ├── 2-class/       # 20% of original 2-class data\n",
            "│   │   ├── yes/\n",
            "│   │   └── no/\n",
            "│   └── 4-class/       # 20% of original 4-class data\n",
            "│       ├── glioma_tumor/\n",
            "│       ├── meningioma_tumor/\n",
            "│       ├── no_tumor/\n",
            "│       └── pituitary_tumor/\n",
            "└── test/\n",
            "    ├── 2-class/       # 10% of original 2-class data\n",
            "    │   ├── yes/\n",
            "    │   └── no/\n",
            "    └── 4-class/       # 10% of original 4-class data\n",
            "        ├── glioma_tumor/\n",
            "        ├── meningioma_tumor/\n",
            "        ├── no_tumor/\n",
            "        └── pituitary_tumor/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.preprocess_split_data(\"/content/splitted-dataset\", \"/content/preprocessed-splitted-data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FCmgjjJB7rD",
        "outputId": "40d8b325-614a-469c-9a84-ced6646a1144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing split dataset with new structure...\n",
            "Input path: /content/splitted-dataset\n",
            "Output path: /content/preprocessed-splitted-data\n",
            "\n",
            "Processing pretrain folder...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/content/preprocessed_splitted_data.zip\" \"/content/preprocessed-splitted-data\""
      ],
      "metadata": {
        "id": "kzOnki8CCJnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Downloaded the `preprocessed_splitted_data.zip` file manually and uploaded it to the gdrive folder."
      ],
      "metadata": {
        "id": "J7J_owlgIFz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training Phase 1 - Contrastive Learning"
      ],
      "metadata": {
        "id": "FbOAd7E-0B6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tselane2110/SSCLNet-Implementation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TiXxFBM9ItD",
        "outputId": "92bd7d4c-2a2a-4fb2-8c39-27c50dc67de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SSCLNet-Implementation'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 286 (delta 83), reused 70 (delta 30), pack-reused 143 (from 1)\u001b[K\n",
            "Receiving objects: 100% (286/286), 493.49 KiB | 679.00 KiB/s, done.\n",
            "Resolving deltas: 100% (158/158), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/16-v8HBPN_Nnj8JnQSDRSnfq5C1YqD-8y/view?usp=drive_link\"\n",
        "!unzip -q /content/Preprocessed-splitted-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj4fJAf413LZ",
        "outputId": "3d9e8dc1-cf22-4b8a-eca4-1f3cdf1ef7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16-v8HBPN_Nnj8JnQSDRSnfq5C1YqD-8y\n",
            "From (redirected): https://drive.google.com/uc?id=16-v8HBPN_Nnj8JnQSDRSnfq5C1YqD-8y&confirm=t&uuid=f185da7b-c19b-47e4-8243-121296f1a1a6\n",
            "To: /content/Preprocessed-splitted-data.zip\n",
            "100% 84.7M/84.7M [00:04<00:00, 20.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# updating file paths for pretrain and train data in the config.py file\n",
        "# PRETRAIN_DATA_PATH = \"/content/Preprocessed-splitted-data/pretrain\"\n",
        "# TRAIN_DATA_PATH = \"/content/Preprocessed-splitted-data/train/5-class\"\n",
        "# we will perform the supervised training again on 2-class data"
      ],
      "metadata": {
        "id": "5eYOmyxK2VzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/SSCLNet-Implementation/train_contrastive.py\""
      ],
      "metadata": {
        "id": "nv_YUV2GIui8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31ff9bc-d7df-421a-a86b-0b05a7b95b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-03 07:27:54.675942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762154874.696471    1469 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762154874.703004    1469 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762154874.718711    1469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762154874.718742    1469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762154874.718746    1469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762154874.718749    1469 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-03 07:27:54.723236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ All directories created\n",
            "✓ All directories created\n",
            "✓ Random seed set to: 42\n",
            "2025-11-03 07:27:59,769 - contrastive_pretraining - INFO - === Starting Contrastive Pre-training ===\n",
            "================================================================================\n",
            "MODEL SUMMARY\n",
            "================================================================================\n",
            "Model: SSCLNet\n",
            "Total trainable parameters: 25,669,541\n",
            "Model size: 98.12 MB\n",
            "\n",
            "Layer breakdown:\n",
            "  encoder.conv1.weight: 3,136\n",
            "  encoder.bn1.weight: 64\n",
            "  encoder.bn1.bias: 64\n",
            "  encoder.layer1.0.conv1.weight: 4,096\n",
            "  encoder.layer1.0.bn1.weight: 64\n",
            "  encoder.layer1.0.bn1.bias: 64\n",
            "  encoder.layer1.0.conv2.weight: 36,864\n",
            "  encoder.layer1.0.bn2.weight: 64\n",
            "  encoder.layer1.0.bn2.bias: 64\n",
            "  encoder.layer1.0.conv3.weight: 16,384\n",
            "  encoder.layer1.0.bn3.weight: 256\n",
            "  encoder.layer1.0.bn3.bias: 256\n",
            "  encoder.layer1.0.downsample.0.weight: 16,384\n",
            "  encoder.layer1.0.downsample.1.weight: 256\n",
            "  encoder.layer1.0.downsample.1.bias: 256\n",
            "  encoder.layer1.1.conv1.weight: 16,384\n",
            "  encoder.layer1.1.bn1.weight: 64\n",
            "  encoder.layer1.1.bn1.bias: 64\n",
            "  encoder.layer1.1.conv2.weight: 36,864\n",
            "  encoder.layer1.1.bn2.weight: 64\n",
            "  encoder.layer1.1.bn2.bias: 64\n",
            "  encoder.layer1.1.conv3.weight: 16,384\n",
            "  encoder.layer1.1.bn3.weight: 256\n",
            "  encoder.layer1.1.bn3.bias: 256\n",
            "  encoder.layer1.2.conv1.weight: 16,384\n",
            "  encoder.layer1.2.bn1.weight: 64\n",
            "  encoder.layer1.2.bn1.bias: 64\n",
            "  encoder.layer1.2.conv2.weight: 36,864\n",
            "  encoder.layer1.2.bn2.weight: 64\n",
            "  encoder.layer1.2.bn2.bias: 64\n",
            "  encoder.layer1.2.conv3.weight: 16,384\n",
            "  encoder.layer1.2.bn3.weight: 256\n",
            "  encoder.layer1.2.bn3.bias: 256\n",
            "  encoder.layer2.0.conv1.weight: 32,768\n",
            "  encoder.layer2.0.bn1.weight: 128\n",
            "  encoder.layer2.0.bn1.bias: 128\n",
            "  encoder.layer2.0.conv2.weight: 147,456\n",
            "  encoder.layer2.0.bn2.weight: 128\n",
            "  encoder.layer2.0.bn2.bias: 128\n",
            "  encoder.layer2.0.conv3.weight: 65,536\n",
            "  encoder.layer2.0.bn3.weight: 512\n",
            "  encoder.layer2.0.bn3.bias: 512\n",
            "  encoder.layer2.0.downsample.0.weight: 131,072\n",
            "  encoder.layer2.0.downsample.1.weight: 512\n",
            "  encoder.layer2.0.downsample.1.bias: 512\n",
            "  encoder.layer2.1.conv1.weight: 65,536\n",
            "  encoder.layer2.1.bn1.weight: 128\n",
            "  encoder.layer2.1.bn1.bias: 128\n",
            "  encoder.layer2.1.conv2.weight: 147,456\n",
            "  encoder.layer2.1.bn2.weight: 128\n",
            "  encoder.layer2.1.bn2.bias: 128\n",
            "  encoder.layer2.1.conv3.weight: 65,536\n",
            "  encoder.layer2.1.bn3.weight: 512\n",
            "  encoder.layer2.1.bn3.bias: 512\n",
            "  encoder.layer2.2.conv1.weight: 65,536\n",
            "  encoder.layer2.2.bn1.weight: 128\n",
            "  encoder.layer2.2.bn1.bias: 128\n",
            "  encoder.layer2.2.conv2.weight: 147,456\n",
            "  encoder.layer2.2.bn2.weight: 128\n",
            "  encoder.layer2.2.bn2.bias: 128\n",
            "  encoder.layer2.2.conv3.weight: 65,536\n",
            "  encoder.layer2.2.bn3.weight: 512\n",
            "  encoder.layer2.2.bn3.bias: 512\n",
            "  encoder.layer2.3.conv1.weight: 65,536\n",
            "  encoder.layer2.3.bn1.weight: 128\n",
            "  encoder.layer2.3.bn1.bias: 128\n",
            "  encoder.layer2.3.conv2.weight: 147,456\n",
            "  encoder.layer2.3.bn2.weight: 128\n",
            "  encoder.layer2.3.bn2.bias: 128\n",
            "  encoder.layer2.3.conv3.weight: 65,536\n",
            "  encoder.layer2.3.bn3.weight: 512\n",
            "  encoder.layer2.3.bn3.bias: 512\n",
            "  encoder.layer3.0.conv1.weight: 131,072\n",
            "  encoder.layer3.0.bn1.weight: 256\n",
            "  encoder.layer3.0.bn1.bias: 256\n",
            "  encoder.layer3.0.conv2.weight: 589,824\n",
            "  encoder.layer3.0.bn2.weight: 256\n",
            "  encoder.layer3.0.bn2.bias: 256\n",
            "  encoder.layer3.0.conv3.weight: 262,144\n",
            "  encoder.layer3.0.bn3.weight: 1,024\n",
            "  encoder.layer3.0.bn3.bias: 1,024\n",
            "  encoder.layer3.0.downsample.0.weight: 524,288\n",
            "  encoder.layer3.0.downsample.1.weight: 1,024\n",
            "  encoder.layer3.0.downsample.1.bias: 1,024\n",
            "  encoder.layer3.1.conv1.weight: 262,144\n",
            "  encoder.layer3.1.bn1.weight: 256\n",
            "  encoder.layer3.1.bn1.bias: 256\n",
            "  encoder.layer3.1.conv2.weight: 589,824\n",
            "  encoder.layer3.1.bn2.weight: 256\n",
            "  encoder.layer3.1.bn2.bias: 256\n",
            "  encoder.layer3.1.conv3.weight: 262,144\n",
            "  encoder.layer3.1.bn3.weight: 1,024\n",
            "  encoder.layer3.1.bn3.bias: 1,024\n",
            "  encoder.layer3.2.conv1.weight: 262,144\n",
            "  encoder.layer3.2.bn1.weight: 256\n",
            "  encoder.layer3.2.bn1.bias: 256\n",
            "  encoder.layer3.2.conv2.weight: 589,824\n",
            "  encoder.layer3.2.bn2.weight: 256\n",
            "  encoder.layer3.2.bn2.bias: 256\n",
            "  encoder.layer3.2.conv3.weight: 262,144\n",
            "  encoder.layer3.2.bn3.weight: 1,024\n",
            "  encoder.layer3.2.bn3.bias: 1,024\n",
            "  encoder.layer3.3.conv1.weight: 262,144\n",
            "  encoder.layer3.3.bn1.weight: 256\n",
            "  encoder.layer3.3.bn1.bias: 256\n",
            "  encoder.layer3.3.conv2.weight: 589,824\n",
            "  encoder.layer3.3.bn2.weight: 256\n",
            "  encoder.layer3.3.bn2.bias: 256\n",
            "  encoder.layer3.3.conv3.weight: 262,144\n",
            "  encoder.layer3.3.bn3.weight: 1,024\n",
            "  encoder.layer3.3.bn3.bias: 1,024\n",
            "  encoder.layer3.4.conv1.weight: 262,144\n",
            "  encoder.layer3.4.bn1.weight: 256\n",
            "  encoder.layer3.4.bn1.bias: 256\n",
            "  encoder.layer3.4.conv2.weight: 589,824\n",
            "  encoder.layer3.4.bn2.weight: 256\n",
            "  encoder.layer3.4.bn2.bias: 256\n",
            "  encoder.layer3.4.conv3.weight: 262,144\n",
            "  encoder.layer3.4.bn3.weight: 1,024\n",
            "  encoder.layer3.4.bn3.bias: 1,024\n",
            "  encoder.layer3.5.conv1.weight: 262,144\n",
            "  encoder.layer3.5.bn1.weight: 256\n",
            "  encoder.layer3.5.bn1.bias: 256\n",
            "  encoder.layer3.5.conv2.weight: 589,824\n",
            "  encoder.layer3.5.bn2.weight: 256\n",
            "  encoder.layer3.5.bn2.bias: 256\n",
            "  encoder.layer3.5.conv3.weight: 262,144\n",
            "  encoder.layer3.5.bn3.weight: 1,024\n",
            "  encoder.layer3.5.bn3.bias: 1,024\n",
            "  encoder.layer4.0.conv1.weight: 524,288\n",
            "  encoder.layer4.0.bn1.weight: 512\n",
            "  encoder.layer4.0.bn1.bias: 512\n",
            "  encoder.layer4.0.conv2.weight: 2,359,296\n",
            "  encoder.layer4.0.bn2.weight: 512\n",
            "  encoder.layer4.0.bn2.bias: 512\n",
            "  encoder.layer4.0.conv3.weight: 1,048,576\n",
            "  encoder.layer4.0.bn3.weight: 2,048\n",
            "  encoder.layer4.0.bn3.bias: 2,048\n",
            "  encoder.layer4.0.downsample.0.weight: 2,097,152\n",
            "  encoder.layer4.0.downsample.1.weight: 2,048\n",
            "  encoder.layer4.0.downsample.1.bias: 2,048\n",
            "  encoder.layer4.1.conv1.weight: 1,048,576\n",
            "  encoder.layer4.1.bn1.weight: 512\n",
            "  encoder.layer4.1.bn1.bias: 512\n",
            "  encoder.layer4.1.conv2.weight: 2,359,296\n",
            "  encoder.layer4.1.bn2.weight: 512\n",
            "  encoder.layer4.1.bn2.bias: 512\n",
            "  encoder.layer4.1.conv3.weight: 1,048,576\n",
            "  encoder.layer4.1.bn3.weight: 2,048\n",
            "  encoder.layer4.1.bn3.bias: 2,048\n",
            "  encoder.layer4.2.conv1.weight: 1,048,576\n",
            "  encoder.layer4.2.bn1.weight: 512\n",
            "  encoder.layer4.2.bn1.bias: 512\n",
            "  encoder.layer4.2.conv2.weight: 2,359,296\n",
            "  encoder.layer4.2.bn2.weight: 512\n",
            "  encoder.layer4.2.bn2.bias: 512\n",
            "  encoder.layer4.2.conv3.weight: 1,048,576\n",
            "  encoder.layer4.2.bn3.weight: 2,048\n",
            "  encoder.layer4.2.bn3.bias: 2,048\n",
            "  projection_head.mlp.0.weight: 1,048,576\n",
            "  projection_head.mlp.0.bias: 512\n",
            "  projection_head.mlp.2.weight: 262,144\n",
            "  projection_head.mlp.2.bias: 512\n",
            "  projection_head.mlp.4.weight: 131,072\n",
            "  projection_head.mlp.4.bias: 256\n",
            "  projection_head.mlp.6.weight: 65,536\n",
            "  projection_head.mlp.6.bias: 256\n",
            "  projection_head.mlp.9.weight: 8,192\n",
            "  projection_head.mlp.9.bias: 32\n",
            "  classifier.classifier.0.weight: 524,288\n",
            "  classifier.classifier.0.bias: 256\n",
            "  classifier.classifier.2.weight: 65,536\n",
            "  classifier.classifier.2.bias: 256\n",
            "  classifier.classifier.4.weight: 32,768\n",
            "  classifier.classifier.4.bias: 128\n",
            "  classifier.classifier.6.weight: 16,384\n",
            "  classifier.classifier.6.bias: 128\n",
            "  classifier.classifier.8.weight: 8,192\n",
            "  classifier.classifier.8.bias: 64\n",
            "  classifier.classifier.10.weight: 2,048\n",
            "  classifier.classifier.10.bias: 32\n",
            "  classifier.classifier.12.weight: 512\n",
            "  classifier.classifier.12.bias: 16\n",
            "  classifier.classifier.14.weight: 80\n",
            "  classifier.classifier.14.bias: 5\n",
            "================================================================================\n",
            "Created pretrain DataLoader:\n",
            "  - Batch size: 64\n",
            "  - Shuffle: True\n",
            "  - Workers: 2\n",
            "  - Augmentation pool: random_cropping, random_brightness, random_contrast, random_noise\n",
            "  - Number of samples: 4556\n",
            "  - Returns: (augmented_image1, augmented_image2) pairs\n",
            "2025-11-03 07:28:00,672 - contrastive_pretraining - INFO - Pre-training with 4556 unlabeled images\n",
            "Epoch 1/100:   0% 0/72 [00:04<?, ?it/s, Loss=4.8759]2025-11-03 07:28:04,775 - contrastive_pretraining - INFO - Epoch 0 - contrastive_loss/batch: 4.8759\n",
            "2025-11-03 07:28:04,776 - contrastive_pretraining - INFO - Epoch 0 - learning_rate: 0.0003\n",
            "Epoch 1/100:  69% 50/72 [01:03<00:26,  1.21s/it, Loss=3.0897]2025-11-03 07:29:03,680 - contrastive_pretraining - INFO - Epoch 50 - contrastive_loss/batch: 3.0897\n",
            "2025-11-03 07:29:03,680 - contrastive_pretraining - INFO - Epoch 50 - learning_rate: 0.0003\n",
            "Epoch 1/100: 100% 72/72 [01:28<00:00,  1.22s/it, Loss=0.8097]\n",
            "2025-11-03 07:29:28,684 - contrastive_pretraining - INFO - Epoch 1 - Average Loss: 3.5092\n",
            "2025-11-03 07:29:28,684 - contrastive_pretraining - INFO - Epoch 0 - contrastive_loss/epoch: 3.5092\n",
            "Epoch 2/100:   0% 0/72 [00:01<?, ?it/s, Loss=2.6934]2025-11-03 07:29:30,537 - contrastive_pretraining - INFO - Epoch 72 - contrastive_loss/batch: 2.6934\n",
            "2025-11-03 07:29:30,538 - contrastive_pretraining - INFO - Epoch 72 - learning_rate: 0.0003\n",
            "Epoch 2/100:  69% 50/72 [01:03<00:27,  1.23s/it, Loss=2.2544]2025-11-03 07:30:32,552 - contrastive_pretraining - INFO - Epoch 122 - contrastive_loss/batch: 2.2544\n",
            "2025-11-03 07:30:32,553 - contrastive_pretraining - INFO - Epoch 122 - learning_rate: 0.0003\n",
            "Epoch 2/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=1.9598]\n",
            "2025-11-03 07:30:57,648 - contrastive_pretraining - INFO - Epoch 2 - Average Loss: 2.3454\n",
            "2025-11-03 07:30:57,648 - contrastive_pretraining - INFO - Epoch 1 - contrastive_loss/epoch: 2.3454\n",
            "Epoch 3/100:   0% 0/72 [00:01<?, ?it/s, Loss=2.1496]2025-11-03 07:30:59,543 - contrastive_pretraining - INFO - Epoch 144 - contrastive_loss/batch: 2.1496\n",
            "2025-11-03 07:30:59,544 - contrastive_pretraining - INFO - Epoch 144 - learning_rate: 0.0003\n",
            "Epoch 3/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=1.8761]2025-11-03 07:32:01,532 - contrastive_pretraining - INFO - Epoch 194 - contrastive_loss/batch: 1.8761\n",
            "2025-11-03 07:32:01,533 - contrastive_pretraining - INFO - Epoch 194 - learning_rate: 0.0003\n",
            "Epoch 3/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.8901]\n",
            "2025-11-03 07:32:26,649 - contrastive_pretraining - INFO - Epoch 3 - Average Loss: 1.9894\n",
            "2025-11-03 07:32:26,649 - contrastive_pretraining - INFO - Epoch 2 - contrastive_loss/epoch: 1.9894\n",
            "Epoch 4/100:   0% 0/72 [00:01<?, ?it/s, Loss=2.0386]2025-11-03 07:32:28,517 - contrastive_pretraining - INFO - Epoch 216 - contrastive_loss/batch: 2.0386\n",
            "2025-11-03 07:32:28,518 - contrastive_pretraining - INFO - Epoch 216 - learning_rate: 0.0003\n",
            "Epoch 4/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=1.6732]2025-11-03 07:33:30,668 - contrastive_pretraining - INFO - Epoch 266 - contrastive_loss/batch: 1.6732\n",
            "2025-11-03 07:33:30,669 - contrastive_pretraining - INFO - Epoch 266 - learning_rate: 0.0003\n",
            "Epoch 4/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.4302]\n",
            "2025-11-03 07:33:55,827 - contrastive_pretraining - INFO - Epoch 4 - Average Loss: 1.7439\n",
            "2025-11-03 07:33:55,827 - contrastive_pretraining - INFO - Epoch 3 - contrastive_loss/epoch: 1.7439\n",
            "Epoch 5/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.7580]2025-11-03 07:33:57,655 - contrastive_pretraining - INFO - Epoch 288 - contrastive_loss/batch: 1.7580\n",
            "2025-11-03 07:33:57,655 - contrastive_pretraining - INFO - Epoch 288 - learning_rate: 0.0003\n",
            "Epoch 5/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=1.3537]2025-11-03 07:34:59,652 - contrastive_pretraining - INFO - Epoch 338 - contrastive_loss/batch: 1.3537\n",
            "2025-11-03 07:34:59,653 - contrastive_pretraining - INFO - Epoch 338 - learning_rate: 0.0003\n",
            "Epoch 5/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.4290]\n",
            "2025-11-03 07:35:24,802 - contrastive_pretraining - INFO - Epoch 5 - Average Loss: 1.5421\n",
            "2025-11-03 07:35:24,803 - contrastive_pretraining - INFO - Epoch 4 - contrastive_loss/epoch: 1.5421\n",
            "Epoch 6/100:   0% 0/72 [00:02<?, ?it/s, Loss=1.4718]2025-11-03 07:35:27,191 - contrastive_pretraining - INFO - Epoch 360 - contrastive_loss/batch: 1.4718\n",
            "2025-11-03 07:35:27,192 - contrastive_pretraining - INFO - Epoch 360 - learning_rate: 0.0003\n",
            "Epoch 6/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=1.2418]2025-11-03 07:36:29,238 - contrastive_pretraining - INFO - Epoch 410 - contrastive_loss/batch: 1.2418\n",
            "2025-11-03 07:36:29,238 - contrastive_pretraining - INFO - Epoch 410 - learning_rate: 0.0003\n",
            "Epoch 6/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2780]\n",
            "2025-11-03 07:36:54,390 - contrastive_pretraining - INFO - Epoch 6 - Average Loss: 1.3297\n",
            "2025-11-03 07:36:54,391 - contrastive_pretraining - INFO - Epoch 5 - contrastive_loss/epoch: 1.3297\n",
            "Epoch 7/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.1360]2025-11-03 07:36:56,250 - contrastive_pretraining - INFO - Epoch 432 - contrastive_loss/batch: 1.1360\n",
            "2025-11-03 07:36:56,251 - contrastive_pretraining - INFO - Epoch 432 - learning_rate: 0.0003\n",
            "Epoch 7/100:  69% 50/72 [01:04<00:27,  1.25s/it, Loss=1.1660]2025-11-03 07:37:58,435 - contrastive_pretraining - INFO - Epoch 482 - contrastive_loss/batch: 1.1660\n",
            "2025-11-03 07:37:58,436 - contrastive_pretraining - INFO - Epoch 482 - learning_rate: 0.0003\n",
            "Epoch 7/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0712]\n",
            "2025-11-03 07:38:23,585 - contrastive_pretraining - INFO - Epoch 7 - Average Loss: 1.1979\n",
            "2025-11-03 07:38:23,586 - contrastive_pretraining - INFO - Epoch 6 - contrastive_loss/epoch: 1.1979\n",
            "Epoch 8/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.3109]2025-11-03 07:38:25,472 - contrastive_pretraining - INFO - Epoch 504 - contrastive_loss/batch: 1.3109\n",
            "2025-11-03 07:38:25,473 - contrastive_pretraining - INFO - Epoch 504 - learning_rate: 0.0003\n",
            "Epoch 8/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=1.0344]2025-11-03 07:39:27,602 - contrastive_pretraining - INFO - Epoch 554 - contrastive_loss/batch: 1.0344\n",
            "2025-11-03 07:39:27,602 - contrastive_pretraining - INFO - Epoch 554 - learning_rate: 0.0003\n",
            "Epoch 8/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1623]\n",
            "2025-11-03 07:39:52,742 - contrastive_pretraining - INFO - Epoch 8 - Average Loss: 1.0915\n",
            "2025-11-03 07:39:52,743 - contrastive_pretraining - INFO - Epoch 7 - contrastive_loss/epoch: 1.0915\n",
            "Epoch 9/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.1663]2025-11-03 07:39:54,607 - contrastive_pretraining - INFO - Epoch 576 - contrastive_loss/batch: 1.1663\n",
            "2025-11-03 07:39:54,608 - contrastive_pretraining - INFO - Epoch 576 - learning_rate: 0.0003\n",
            "Epoch 9/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=1.1095]2025-11-03 07:40:56,680 - contrastive_pretraining - INFO - Epoch 626 - contrastive_loss/batch: 1.1095\n",
            "2025-11-03 07:40:56,681 - contrastive_pretraining - INFO - Epoch 626 - learning_rate: 0.0003\n",
            "Epoch 9/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1127]\n",
            "2025-11-03 07:41:21,804 - contrastive_pretraining - INFO - Epoch 9 - Average Loss: 1.0749\n",
            "2025-11-03 07:41:21,804 - contrastive_pretraining - INFO - Epoch 8 - contrastive_loss/epoch: 1.0749\n",
            "Epoch 10/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.0090]2025-11-03 07:41:23,647 - contrastive_pretraining - INFO - Epoch 648 - contrastive_loss/batch: 1.0090\n",
            "2025-11-03 07:41:23,647 - contrastive_pretraining - INFO - Epoch 648 - learning_rate: 0.0003\n",
            "Epoch 10/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=1.0465]2025-11-03 07:42:25,651 - contrastive_pretraining - INFO - Epoch 698 - contrastive_loss/batch: 1.0465\n",
            "2025-11-03 07:42:25,652 - contrastive_pretraining - INFO - Epoch 698 - learning_rate: 0.0003\n",
            "Epoch 10/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.3766]\n",
            "2025-11-03 07:42:50,785 - contrastive_pretraining - INFO - Epoch 10 - Average Loss: 1.0217\n",
            "2025-11-03 07:42:50,786 - contrastive_pretraining - INFO - Epoch 9 - contrastive_loss/epoch: 1.0217\n",
            "Epoch 11/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.0302]2025-11-03 07:42:52,780 - contrastive_pretraining - INFO - Epoch 720 - contrastive_loss/batch: 1.0302\n",
            "2025-11-03 07:42:52,783 - contrastive_pretraining - INFO - Epoch 720 - learning_rate: 0.0003\n",
            "Epoch 11/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.9137]2025-11-03 07:43:54,822 - contrastive_pretraining - INFO - Epoch 770 - contrastive_loss/batch: 0.9137\n",
            "2025-11-03 07:43:54,822 - contrastive_pretraining - INFO - Epoch 770 - learning_rate: 0.0003\n",
            "Epoch 11/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0406]\n",
            "2025-11-03 07:44:19,990 - contrastive_pretraining - INFO - Epoch 11 - Average Loss: 0.9761\n",
            "2025-11-03 07:44:19,991 - contrastive_pretraining - INFO - Epoch 10 - contrastive_loss/epoch: 0.9761\n",
            "Epoch 12/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.8672]2025-11-03 07:44:21,872 - contrastive_pretraining - INFO - Epoch 792 - contrastive_loss/batch: 0.8672\n",
            "2025-11-03 07:44:21,873 - contrastive_pretraining - INFO - Epoch 792 - learning_rate: 0.0003\n",
            "Epoch 12/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.8716]2025-11-03 07:45:23,928 - contrastive_pretraining - INFO - Epoch 842 - contrastive_loss/batch: 0.8716\n",
            "2025-11-03 07:45:23,929 - contrastive_pretraining - INFO - Epoch 842 - learning_rate: 0.0003\n",
            "Epoch 12/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0708]\n",
            "2025-11-03 07:45:49,079 - contrastive_pretraining - INFO - Epoch 12 - Average Loss: 0.9218\n",
            "2025-11-03 07:45:49,079 - contrastive_pretraining - INFO - Epoch 11 - contrastive_loss/epoch: 0.9218\n",
            "Epoch 13/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7778]2025-11-03 07:45:50,967 - contrastive_pretraining - INFO - Epoch 864 - contrastive_loss/batch: 0.7778\n",
            "2025-11-03 07:45:50,968 - contrastive_pretraining - INFO - Epoch 864 - learning_rate: 0.0003\n",
            "Epoch 13/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.9162]2025-11-03 07:46:53,063 - contrastive_pretraining - INFO - Epoch 914 - contrastive_loss/batch: 0.9162\n",
            "2025-11-03 07:46:53,063 - contrastive_pretraining - INFO - Epoch 914 - learning_rate: 0.0003\n",
            "Epoch 13/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2213]\n",
            "2025-11-03 07:47:18,218 - contrastive_pretraining - INFO - Epoch 13 - Average Loss: 0.8715\n",
            "2025-11-03 07:47:18,219 - contrastive_pretraining - INFO - Epoch 12 - contrastive_loss/epoch: 0.8715\n",
            "Epoch 14/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.9009]2025-11-03 07:47:20,105 - contrastive_pretraining - INFO - Epoch 936 - contrastive_loss/batch: 0.9009\n",
            "2025-11-03 07:47:20,106 - contrastive_pretraining - INFO - Epoch 936 - learning_rate: 0.0003\n",
            "Epoch 14/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=1.0280]2025-11-03 07:48:22,121 - contrastive_pretraining - INFO - Epoch 986 - contrastive_loss/batch: 1.0280\n",
            "2025-11-03 07:48:22,121 - contrastive_pretraining - INFO - Epoch 986 - learning_rate: 0.0003\n",
            "Epoch 14/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0756]\n",
            "2025-11-03 07:48:47,231 - contrastive_pretraining - INFO - Epoch 14 - Average Loss: 0.8723\n",
            "2025-11-03 07:48:47,232 - contrastive_pretraining - INFO - Epoch 13 - contrastive_loss/epoch: 0.8723\n",
            "Epoch 15/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.9210]2025-11-03 07:48:49,127 - contrastive_pretraining - INFO - Epoch 1008 - contrastive_loss/batch: 0.9210\n",
            "2025-11-03 07:48:49,128 - contrastive_pretraining - INFO - Epoch 1008 - learning_rate: 0.0003\n",
            "Epoch 15/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.8465]2025-11-03 07:49:51,130 - contrastive_pretraining - INFO - Epoch 1058 - contrastive_loss/batch: 0.8465\n",
            "2025-11-03 07:49:51,131 - contrastive_pretraining - INFO - Epoch 1058 - learning_rate: 0.0003\n",
            "Epoch 15/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0272]\n",
            "2025-11-03 07:50:16,299 - contrastive_pretraining - INFO - Epoch 15 - Average Loss: 0.8510\n",
            "2025-11-03 07:50:16,299 - contrastive_pretraining - INFO - Epoch 14 - contrastive_loss/epoch: 0.8510\n",
            "Epoch 16/100:   0% 0/72 [00:02<?, ?it/s, Loss=1.0347]2025-11-03 07:50:18,518 - contrastive_pretraining - INFO - Epoch 1080 - contrastive_loss/batch: 1.0347\n",
            "2025-11-03 07:50:18,519 - contrastive_pretraining - INFO - Epoch 1080 - learning_rate: 0.0003\n",
            "Epoch 16/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.9968]2025-11-03 07:51:20,563 - contrastive_pretraining - INFO - Epoch 1130 - contrastive_loss/batch: 0.9968\n",
            "2025-11-03 07:51:20,563 - contrastive_pretraining - INFO - Epoch 1130 - learning_rate: 0.0003\n",
            "Epoch 16/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2581]\n",
            "2025-11-03 07:51:45,758 - contrastive_pretraining - INFO - Epoch 16 - Average Loss: 0.8485\n",
            "2025-11-03 07:51:45,759 - contrastive_pretraining - INFO - Epoch 15 - contrastive_loss/epoch: 0.8485\n",
            "Epoch 17/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7706]2025-11-03 07:51:47,703 - contrastive_pretraining - INFO - Epoch 1152 - contrastive_loss/batch: 0.7706\n",
            "2025-11-03 07:51:47,704 - contrastive_pretraining - INFO - Epoch 1152 - learning_rate: 0.0003\n",
            "Epoch 17/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.8593]2025-11-03 07:52:49,663 - contrastive_pretraining - INFO - Epoch 1202 - contrastive_loss/batch: 0.8593\n",
            "2025-11-03 07:52:49,664 - contrastive_pretraining - INFO - Epoch 1202 - learning_rate: 0.0003\n",
            "Epoch 17/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0406]\n",
            "2025-11-03 07:53:14,741 - contrastive_pretraining - INFO - Epoch 17 - Average Loss: 0.7976\n",
            "2025-11-03 07:53:14,742 - contrastive_pretraining - INFO - Epoch 16 - contrastive_loss/epoch: 0.7976\n",
            "Epoch 18/100:   0% 0/72 [00:01<?, ?it/s, Loss=1.1328]2025-11-03 07:53:16,548 - contrastive_pretraining - INFO - Epoch 1224 - contrastive_loss/batch: 1.1328\n",
            "2025-11-03 07:53:16,549 - contrastive_pretraining - INFO - Epoch 1224 - learning_rate: 0.0003\n",
            "Epoch 18/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.9429]2025-11-03 07:54:18,554 - contrastive_pretraining - INFO - Epoch 1274 - contrastive_loss/batch: 0.9429\n",
            "2025-11-03 07:54:18,554 - contrastive_pretraining - INFO - Epoch 1274 - learning_rate: 0.0003\n",
            "Epoch 18/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.1253]\n",
            "2025-11-03 07:54:43,681 - contrastive_pretraining - INFO - Epoch 18 - Average Loss: 0.8394\n",
            "2025-11-03 07:54:43,682 - contrastive_pretraining - INFO - Epoch 17 - contrastive_loss/epoch: 0.8394\n",
            "Epoch 19/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7891]2025-11-03 07:54:45,542 - contrastive_pretraining - INFO - Epoch 1296 - contrastive_loss/batch: 0.7891\n",
            "2025-11-03 07:54:45,542 - contrastive_pretraining - INFO - Epoch 1296 - learning_rate: 0.0003\n",
            "Epoch 19/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.8220]2025-11-03 07:55:47,648 - contrastive_pretraining - INFO - Epoch 1346 - contrastive_loss/batch: 0.8220\n",
            "2025-11-03 07:55:47,648 - contrastive_pretraining - INFO - Epoch 1346 - learning_rate: 0.0003\n",
            "Epoch 19/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0659]\n",
            "2025-11-03 07:56:12,801 - contrastive_pretraining - INFO - Epoch 19 - Average Loss: 0.7879\n",
            "2025-11-03 07:56:12,802 - contrastive_pretraining - INFO - Epoch 18 - contrastive_loss/epoch: 0.7879\n",
            "Epoch 20/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7765]2025-11-03 07:56:14,662 - contrastive_pretraining - INFO - Epoch 1368 - contrastive_loss/batch: 0.7765\n",
            "2025-11-03 07:56:14,662 - contrastive_pretraining - INFO - Epoch 1368 - learning_rate: 0.0003\n",
            "Epoch 20/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.9429]2025-11-03 07:57:16,733 - contrastive_pretraining - INFO - Epoch 1418 - contrastive_loss/batch: 0.9429\n",
            "2025-11-03 07:57:16,734 - contrastive_pretraining - INFO - Epoch 1418 - learning_rate: 0.0003\n",
            "Epoch 20/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1050]\n",
            "2025-11-03 07:57:41,858 - contrastive_pretraining - INFO - Epoch 20 - Average Loss: 0.8244\n",
            "2025-11-03 07:57:41,859 - contrastive_pretraining - INFO - Epoch 19 - contrastive_loss/epoch: 0.8244\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 07:57:47,636 - contrastive_pretraining - INFO - Checkpoint saved: checkpoints/contrastive_epoch_20.pth\n",
            "Epoch 21/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7115]2025-11-03 07:57:49,474 - contrastive_pretraining - INFO - Epoch 1440 - contrastive_loss/batch: 0.7115\n",
            "2025-11-03 07:57:49,475 - contrastive_pretraining - INFO - Epoch 1440 - learning_rate: 0.0003\n",
            "Epoch 21/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.7470]2025-11-03 07:58:51,632 - contrastive_pretraining - INFO - Epoch 1490 - contrastive_loss/batch: 0.7470\n",
            "2025-11-03 07:58:51,632 - contrastive_pretraining - INFO - Epoch 1490 - learning_rate: 0.0003\n",
            "Epoch 21/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.1132]\n",
            "2025-11-03 07:59:16,618 - contrastive_pretraining - INFO - Epoch 21 - Average Loss: 0.7708\n",
            "2025-11-03 07:59:16,619 - contrastive_pretraining - INFO - Epoch 20 - contrastive_loss/epoch: 0.7708\n",
            "Epoch 22/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6278]2025-11-03 07:59:18,494 - contrastive_pretraining - INFO - Epoch 1512 - contrastive_loss/batch: 0.6278\n",
            "2025-11-03 07:59:18,495 - contrastive_pretraining - INFO - Epoch 1512 - learning_rate: 0.0003\n",
            "Epoch 22/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6860]2025-11-03 08:00:20,590 - contrastive_pretraining - INFO - Epoch 1562 - contrastive_loss/batch: 0.6860\n",
            "2025-11-03 08:00:20,590 - contrastive_pretraining - INFO - Epoch 1562 - learning_rate: 0.0003\n",
            "Epoch 22/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2867]\n",
            "2025-11-03 08:00:45,691 - contrastive_pretraining - INFO - Epoch 22 - Average Loss: 0.7437\n",
            "2025-11-03 08:00:45,691 - contrastive_pretraining - INFO - Epoch 21 - contrastive_loss/epoch: 0.7437\n",
            "Epoch 23/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7411]2025-11-03 08:00:47,519 - contrastive_pretraining - INFO - Epoch 1584 - contrastive_loss/batch: 0.7411\n",
            "2025-11-03 08:00:47,519 - contrastive_pretraining - INFO - Epoch 1584 - learning_rate: 0.0003\n",
            "Epoch 23/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6948]2025-11-03 08:01:49,423 - contrastive_pretraining - INFO - Epoch 1634 - contrastive_loss/batch: 0.6948\n",
            "2025-11-03 08:01:49,424 - contrastive_pretraining - INFO - Epoch 1634 - learning_rate: 0.0003\n",
            "Epoch 23/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0762]\n",
            "2025-11-03 08:02:14,540 - contrastive_pretraining - INFO - Epoch 23 - Average Loss: 0.7860\n",
            "2025-11-03 08:02:14,540 - contrastive_pretraining - INFO - Epoch 22 - contrastive_loss/epoch: 0.7860\n",
            "Epoch 24/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.7363]2025-11-03 08:02:16,612 - contrastive_pretraining - INFO - Epoch 1656 - contrastive_loss/batch: 0.7363\n",
            "2025-11-03 08:02:16,613 - contrastive_pretraining - INFO - Epoch 1656 - learning_rate: 0.0003\n",
            "Epoch 24/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.7611]2025-11-03 08:03:18,573 - contrastive_pretraining - INFO - Epoch 1706 - contrastive_loss/batch: 0.7611\n",
            "2025-11-03 08:03:18,573 - contrastive_pretraining - INFO - Epoch 1706 - learning_rate: 0.0003\n",
            "Epoch 24/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1183]\n",
            "2025-11-03 08:03:43,683 - contrastive_pretraining - INFO - Epoch 24 - Average Loss: 0.7149\n",
            "2025-11-03 08:03:43,684 - contrastive_pretraining - INFO - Epoch 23 - contrastive_loss/epoch: 0.7149\n",
            "Epoch 25/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.9573]2025-11-03 08:03:45,521 - contrastive_pretraining - INFO - Epoch 1728 - contrastive_loss/batch: 0.9573\n",
            "2025-11-03 08:03:45,522 - contrastive_pretraining - INFO - Epoch 1728 - learning_rate: 0.0003\n",
            "Epoch 25/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5821]2025-11-03 08:04:47,543 - contrastive_pretraining - INFO - Epoch 1778 - contrastive_loss/batch: 0.5821\n",
            "2025-11-03 08:04:47,544 - contrastive_pretraining - INFO - Epoch 1778 - learning_rate: 0.0003\n",
            "Epoch 25/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.2195]\n",
            "2025-11-03 08:05:12,644 - contrastive_pretraining - INFO - Epoch 25 - Average Loss: 0.7352\n",
            "2025-11-03 08:05:12,644 - contrastive_pretraining - INFO - Epoch 24 - contrastive_loss/epoch: 0.7352\n",
            "Epoch 26/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.8583]2025-11-03 08:05:14,497 - contrastive_pretraining - INFO - Epoch 1800 - contrastive_loss/batch: 0.8583\n",
            "2025-11-03 08:05:14,498 - contrastive_pretraining - INFO - Epoch 1800 - learning_rate: 0.0003\n",
            "Epoch 26/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.7069]2025-11-03 08:06:16,456 - contrastive_pretraining - INFO - Epoch 1850 - contrastive_loss/batch: 0.7069\n",
            "2025-11-03 08:06:16,457 - contrastive_pretraining - INFO - Epoch 1850 - learning_rate: 0.0003\n",
            "Epoch 26/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.2695]\n",
            "2025-11-03 08:06:41,565 - contrastive_pretraining - INFO - Epoch 26 - Average Loss: 0.7158\n",
            "2025-11-03 08:06:41,566 - contrastive_pretraining - INFO - Epoch 25 - contrastive_loss/epoch: 0.7158\n",
            "Epoch 27/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.8290]2025-11-03 08:06:43,397 - contrastive_pretraining - INFO - Epoch 1872 - contrastive_loss/batch: 0.8290\n",
            "2025-11-03 08:06:43,398 - contrastive_pretraining - INFO - Epoch 1872 - learning_rate: 0.0003\n",
            "Epoch 27/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6505]2025-11-03 08:07:45,412 - contrastive_pretraining - INFO - Epoch 1922 - contrastive_loss/batch: 0.6505\n",
            "2025-11-03 08:07:45,413 - contrastive_pretraining - INFO - Epoch 1922 - learning_rate: 0.0003\n",
            "Epoch 27/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.1035]\n",
            "2025-11-03 08:08:10,555 - contrastive_pretraining - INFO - Epoch 27 - Average Loss: 0.7266\n",
            "2025-11-03 08:08:10,555 - contrastive_pretraining - INFO - Epoch 26 - contrastive_loss/epoch: 0.7266\n",
            "Epoch 28/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6025]2025-11-03 08:08:12,438 - contrastive_pretraining - INFO - Epoch 1944 - contrastive_loss/batch: 0.6025\n",
            "2025-11-03 08:08:12,439 - contrastive_pretraining - INFO - Epoch 1944 - learning_rate: 0.0003\n",
            "Epoch 28/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.8393]2025-11-03 08:09:14,407 - contrastive_pretraining - INFO - Epoch 1994 - contrastive_loss/batch: 0.8393\n",
            "2025-11-03 08:09:14,407 - contrastive_pretraining - INFO - Epoch 1994 - learning_rate: 0.0003\n",
            "Epoch 28/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0360]\n",
            "2025-11-03 08:09:39,527 - contrastive_pretraining - INFO - Epoch 28 - Average Loss: 0.7176\n",
            "2025-11-03 08:09:39,528 - contrastive_pretraining - INFO - Epoch 27 - contrastive_loss/epoch: 0.7176\n",
            "Epoch 29/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.6812]2025-11-03 08:09:41,561 - contrastive_pretraining - INFO - Epoch 2016 - contrastive_loss/batch: 0.6812\n",
            "2025-11-03 08:09:41,561 - contrastive_pretraining - INFO - Epoch 2016 - learning_rate: 0.0003\n",
            "Epoch 29/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6766]2025-11-03 08:10:43,455 - contrastive_pretraining - INFO - Epoch 2066 - contrastive_loss/batch: 0.6766\n",
            "2025-11-03 08:10:43,455 - contrastive_pretraining - INFO - Epoch 2066 - learning_rate: 0.0003\n",
            "Epoch 29/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2111]\n",
            "2025-11-03 08:11:08,563 - contrastive_pretraining - INFO - Epoch 29 - Average Loss: 0.7112\n",
            "2025-11-03 08:11:08,563 - contrastive_pretraining - INFO - Epoch 28 - contrastive_loss/epoch: 0.7112\n",
            "Epoch 30/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.6727]2025-11-03 08:11:10,678 - contrastive_pretraining - INFO - Epoch 2088 - contrastive_loss/batch: 0.6727\n",
            "2025-11-03 08:11:10,679 - contrastive_pretraining - INFO - Epoch 2088 - learning_rate: 0.0003\n",
            "Epoch 30/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.5962]2025-11-03 08:12:12,629 - contrastive_pretraining - INFO - Epoch 2138 - contrastive_loss/batch: 0.5962\n",
            "2025-11-03 08:12:12,629 - contrastive_pretraining - INFO - Epoch 2138 - learning_rate: 0.0003\n",
            "Epoch 30/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0566]\n",
            "2025-11-03 08:12:37,716 - contrastive_pretraining - INFO - Epoch 30 - Average Loss: 0.6670\n",
            "2025-11-03 08:12:37,717 - contrastive_pretraining - INFO - Epoch 29 - contrastive_loss/epoch: 0.6670\n",
            "Epoch 31/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6411]2025-11-03 08:12:39,563 - contrastive_pretraining - INFO - Epoch 2160 - contrastive_loss/batch: 0.6411\n",
            "2025-11-03 08:12:39,564 - contrastive_pretraining - INFO - Epoch 2160 - learning_rate: 0.0003\n",
            "Epoch 31/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.7412]2025-11-03 08:13:41,600 - contrastive_pretraining - INFO - Epoch 2210 - contrastive_loss/batch: 0.7412\n",
            "2025-11-03 08:13:41,601 - contrastive_pretraining - INFO - Epoch 2210 - learning_rate: 0.0003\n",
            "Epoch 31/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1375]\n",
            "2025-11-03 08:14:06,745 - contrastive_pretraining - INFO - Epoch 31 - Average Loss: 0.6863\n",
            "2025-11-03 08:14:06,745 - contrastive_pretraining - INFO - Epoch 30 - contrastive_loss/epoch: 0.6863\n",
            "Epoch 32/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6762]2025-11-03 08:14:08,634 - contrastive_pretraining - INFO - Epoch 2232 - contrastive_loss/batch: 0.6762\n",
            "2025-11-03 08:14:08,634 - contrastive_pretraining - INFO - Epoch 2232 - learning_rate: 0.0003\n",
            "Epoch 32/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.7932]2025-11-03 08:15:10,674 - contrastive_pretraining - INFO - Epoch 2282 - contrastive_loss/batch: 0.7932\n",
            "2025-11-03 08:15:10,675 - contrastive_pretraining - INFO - Epoch 2282 - learning_rate: 0.0003\n",
            "Epoch 32/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0240]\n",
            "2025-11-03 08:15:35,810 - contrastive_pretraining - INFO - Epoch 32 - Average Loss: 0.6715\n",
            "2025-11-03 08:15:35,811 - contrastive_pretraining - INFO - Epoch 31 - contrastive_loss/epoch: 0.6715\n",
            "Epoch 33/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7025]2025-11-03 08:15:37,703 - contrastive_pretraining - INFO - Epoch 2304 - contrastive_loss/batch: 0.7025\n",
            "2025-11-03 08:15:37,704 - contrastive_pretraining - INFO - Epoch 2304 - learning_rate: 0.0003\n",
            "Epoch 33/100:  69% 50/72 [01:03<00:27,  1.23s/it, Loss=0.6263]2025-11-03 08:16:39,570 - contrastive_pretraining - INFO - Epoch 2354 - contrastive_loss/batch: 0.6263\n",
            "2025-11-03 08:16:39,570 - contrastive_pretraining - INFO - Epoch 2354 - learning_rate: 0.0003\n",
            "Epoch 33/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0246]\n",
            "2025-11-03 08:17:04,649 - contrastive_pretraining - INFO - Epoch 33 - Average Loss: 0.6494\n",
            "2025-11-03 08:17:04,650 - contrastive_pretraining - INFO - Epoch 32 - contrastive_loss/epoch: 0.6494\n",
            "Epoch 34/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5165]2025-11-03 08:17:06,547 - contrastive_pretraining - INFO - Epoch 2376 - contrastive_loss/batch: 0.5165\n",
            "2025-11-03 08:17:06,548 - contrastive_pretraining - INFO - Epoch 2376 - learning_rate: 0.0003\n",
            "Epoch 34/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6595]2025-11-03 08:18:08,566 - contrastive_pretraining - INFO - Epoch 2426 - contrastive_loss/batch: 0.6595\n",
            "2025-11-03 08:18:08,566 - contrastive_pretraining - INFO - Epoch 2426 - learning_rate: 0.0003\n",
            "Epoch 34/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0256]\n",
            "2025-11-03 08:18:33,744 - contrastive_pretraining - INFO - Epoch 34 - Average Loss: 0.6512\n",
            "2025-11-03 08:18:33,745 - contrastive_pretraining - INFO - Epoch 33 - contrastive_loss/epoch: 0.6512\n",
            "Epoch 35/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.7044]2025-11-03 08:18:35,987 - contrastive_pretraining - INFO - Epoch 2448 - contrastive_loss/batch: 0.7044\n",
            "2025-11-03 08:18:35,988 - contrastive_pretraining - INFO - Epoch 2448 - learning_rate: 0.0003\n",
            "Epoch 35/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.5315]2025-11-03 08:19:38,079 - contrastive_pretraining - INFO - Epoch 2498 - contrastive_loss/batch: 0.5315\n",
            "2025-11-03 08:19:38,079 - contrastive_pretraining - INFO - Epoch 2498 - learning_rate: 0.0003\n",
            "Epoch 35/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0151]\n",
            "2025-11-03 08:20:03,235 - contrastive_pretraining - INFO - Epoch 35 - Average Loss: 0.6462\n",
            "2025-11-03 08:20:03,235 - contrastive_pretraining - INFO - Epoch 34 - contrastive_loss/epoch: 0.6462\n",
            "Epoch 36/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7453]2025-11-03 08:20:05,078 - contrastive_pretraining - INFO - Epoch 2520 - contrastive_loss/batch: 0.7453\n",
            "2025-11-03 08:20:05,079 - contrastive_pretraining - INFO - Epoch 2520 - learning_rate: 0.0003\n",
            "Epoch 36/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6172]2025-11-03 08:21:07,118 - contrastive_pretraining - INFO - Epoch 2570 - contrastive_loss/batch: 0.6172\n",
            "2025-11-03 08:21:07,118 - contrastive_pretraining - INFO - Epoch 2570 - learning_rate: 0.0003\n",
            "Epoch 36/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0385]\n",
            "2025-11-03 08:21:32,137 - contrastive_pretraining - INFO - Epoch 36 - Average Loss: 0.6305\n",
            "2025-11-03 08:21:32,137 - contrastive_pretraining - INFO - Epoch 35 - contrastive_loss/epoch: 0.6305\n",
            "Epoch 37/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6090]2025-11-03 08:21:33,995 - contrastive_pretraining - INFO - Epoch 2592 - contrastive_loss/batch: 0.6090\n",
            "2025-11-03 08:21:33,996 - contrastive_pretraining - INFO - Epoch 2592 - learning_rate: 0.0003\n",
            "Epoch 37/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6311]2025-11-03 08:22:35,993 - contrastive_pretraining - INFO - Epoch 2642 - contrastive_loss/batch: 0.6311\n",
            "2025-11-03 08:22:35,993 - contrastive_pretraining - INFO - Epoch 2642 - learning_rate: 0.0003\n",
            "Epoch 37/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.1745]\n",
            "2025-11-03 08:23:01,100 - contrastive_pretraining - INFO - Epoch 37 - Average Loss: 0.6393\n",
            "2025-11-03 08:23:01,100 - contrastive_pretraining - INFO - Epoch 36 - contrastive_loss/epoch: 0.6393\n",
            "Epoch 38/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7481]2025-11-03 08:23:02,913 - contrastive_pretraining - INFO - Epoch 2664 - contrastive_loss/batch: 0.7481\n",
            "2025-11-03 08:23:02,914 - contrastive_pretraining - INFO - Epoch 2664 - learning_rate: 0.0003\n",
            "Epoch 38/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6613]2025-11-03 08:24:04,836 - contrastive_pretraining - INFO - Epoch 2714 - contrastive_loss/batch: 0.6613\n",
            "2025-11-03 08:24:04,837 - contrastive_pretraining - INFO - Epoch 2714 - learning_rate: 0.0003\n",
            "Epoch 38/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0206]\n",
            "2025-11-03 08:24:29,975 - contrastive_pretraining - INFO - Epoch 38 - Average Loss: 0.6162\n",
            "2025-11-03 08:24:29,976 - contrastive_pretraining - INFO - Epoch 37 - contrastive_loss/epoch: 0.6162\n",
            "Epoch 39/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5931]2025-11-03 08:24:31,875 - contrastive_pretraining - INFO - Epoch 2736 - contrastive_loss/batch: 0.5931\n",
            "2025-11-03 08:24:31,876 - contrastive_pretraining - INFO - Epoch 2736 - learning_rate: 0.0003\n",
            "Epoch 39/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.7883]2025-11-03 08:25:33,810 - contrastive_pretraining - INFO - Epoch 2786 - contrastive_loss/batch: 0.7883\n",
            "2025-11-03 08:25:33,810 - contrastive_pretraining - INFO - Epoch 2786 - learning_rate: 0.0003\n",
            "Epoch 39/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0754]\n",
            "2025-11-03 08:25:58,863 - contrastive_pretraining - INFO - Epoch 39 - Average Loss: 0.6192\n",
            "2025-11-03 08:25:58,864 - contrastive_pretraining - INFO - Epoch 38 - contrastive_loss/epoch: 0.6192\n",
            "Epoch 40/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.6326]2025-11-03 08:26:00,969 - contrastive_pretraining - INFO - Epoch 2808 - contrastive_loss/batch: 0.6326\n",
            "2025-11-03 08:26:00,970 - contrastive_pretraining - INFO - Epoch 2808 - learning_rate: 0.0003\n",
            "Epoch 40/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5580]2025-11-03 08:27:02,800 - contrastive_pretraining - INFO - Epoch 2858 - contrastive_loss/batch: 0.5580\n",
            "2025-11-03 08:27:02,800 - contrastive_pretraining - INFO - Epoch 2858 - learning_rate: 0.0003\n",
            "Epoch 40/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0367]\n",
            "2025-11-03 08:27:27,938 - contrastive_pretraining - INFO - Epoch 40 - Average Loss: 0.6023\n",
            "2025-11-03 08:27:27,938 - contrastive_pretraining - INFO - Epoch 39 - contrastive_loss/epoch: 0.6023\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 08:27:33,441 - contrastive_pretraining - INFO - Checkpoint saved: checkpoints/contrastive_epoch_40.pth\n",
            "Epoch 41/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5177]2025-11-03 08:27:35,346 - contrastive_pretraining - INFO - Epoch 2880 - contrastive_loss/batch: 0.5177\n",
            "2025-11-03 08:27:35,347 - contrastive_pretraining - INFO - Epoch 2880 - learning_rate: 0.0003\n",
            "Epoch 41/100:  69% 50/72 [01:04<00:27,  1.23s/it, Loss=0.5755]2025-11-03 08:28:37,452 - contrastive_pretraining - INFO - Epoch 2930 - contrastive_loss/batch: 0.5755\n",
            "2025-11-03 08:28:37,452 - contrastive_pretraining - INFO - Epoch 2930 - learning_rate: 0.0003\n",
            "Epoch 41/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1372]\n",
            "2025-11-03 08:29:02,465 - contrastive_pretraining - INFO - Epoch 41 - Average Loss: 0.5733\n",
            "2025-11-03 08:29:02,466 - contrastive_pretraining - INFO - Epoch 40 - contrastive_loss/epoch: 0.5733\n",
            "Epoch 42/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6798]2025-11-03 08:29:04,343 - contrastive_pretraining - INFO - Epoch 2952 - contrastive_loss/batch: 0.6798\n",
            "2025-11-03 08:29:04,344 - contrastive_pretraining - INFO - Epoch 2952 - learning_rate: 0.0003\n",
            "Epoch 42/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6476]2025-11-03 08:30:06,395 - contrastive_pretraining - INFO - Epoch 3002 - contrastive_loss/batch: 0.6476\n",
            "2025-11-03 08:30:06,395 - contrastive_pretraining - INFO - Epoch 3002 - learning_rate: 0.0003\n",
            "Epoch 42/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0573]\n",
            "2025-11-03 08:30:31,545 - contrastive_pretraining - INFO - Epoch 42 - Average Loss: 0.5896\n",
            "2025-11-03 08:30:31,546 - contrastive_pretraining - INFO - Epoch 41 - contrastive_loss/epoch: 0.5896\n",
            "Epoch 43/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.6260]2025-11-03 08:30:33,672 - contrastive_pretraining - INFO - Epoch 3024 - contrastive_loss/batch: 0.6260\n",
            "2025-11-03 08:30:33,673 - contrastive_pretraining - INFO - Epoch 3024 - learning_rate: 0.0003\n",
            "Epoch 43/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.7515]2025-11-03 08:31:35,620 - contrastive_pretraining - INFO - Epoch 3074 - contrastive_loss/batch: 0.7515\n",
            "2025-11-03 08:31:35,621 - contrastive_pretraining - INFO - Epoch 3074 - learning_rate: 0.0003\n",
            "Epoch 43/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0980]\n",
            "2025-11-03 08:32:00,639 - contrastive_pretraining - INFO - Epoch 43 - Average Loss: 0.5891\n",
            "2025-11-03 08:32:00,639 - contrastive_pretraining - INFO - Epoch 42 - contrastive_loss/epoch: 0.5891\n",
            "Epoch 44/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5982]2025-11-03 08:32:02,468 - contrastive_pretraining - INFO - Epoch 3096 - contrastive_loss/batch: 0.5982\n",
            "2025-11-03 08:32:02,468 - contrastive_pretraining - INFO - Epoch 3096 - learning_rate: 0.0003\n",
            "Epoch 44/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.7393]2025-11-03 08:33:04,477 - contrastive_pretraining - INFO - Epoch 3146 - contrastive_loss/batch: 0.7393\n",
            "2025-11-03 08:33:04,478 - contrastive_pretraining - INFO - Epoch 3146 - learning_rate: 0.0003\n",
            "Epoch 44/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0207]\n",
            "2025-11-03 08:33:29,600 - contrastive_pretraining - INFO - Epoch 44 - Average Loss: 0.5701\n",
            "2025-11-03 08:33:29,600 - contrastive_pretraining - INFO - Epoch 43 - contrastive_loss/epoch: 0.5701\n",
            "Epoch 45/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5433]2025-11-03 08:33:31,426 - contrastive_pretraining - INFO - Epoch 3168 - contrastive_loss/batch: 0.5433\n",
            "2025-11-03 08:33:31,427 - contrastive_pretraining - INFO - Epoch 3168 - learning_rate: 0.0003\n",
            "Epoch 45/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5630]2025-11-03 08:34:33,541 - contrastive_pretraining - INFO - Epoch 3218 - contrastive_loss/batch: 0.5630\n",
            "2025-11-03 08:34:33,541 - contrastive_pretraining - INFO - Epoch 3218 - learning_rate: 0.0003\n",
            "Epoch 45/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2253]\n",
            "2025-11-03 08:34:58,664 - contrastive_pretraining - INFO - Epoch 45 - Average Loss: 0.5567\n",
            "2025-11-03 08:34:58,664 - contrastive_pretraining - INFO - Epoch 44 - contrastive_loss/epoch: 0.5567\n",
            "Epoch 46/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.7190]2025-11-03 08:35:00,523 - contrastive_pretraining - INFO - Epoch 3240 - contrastive_loss/batch: 0.7190\n",
            "2025-11-03 08:35:00,523 - contrastive_pretraining - INFO - Epoch 3240 - learning_rate: 0.0003\n",
            "Epoch 46/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6305]2025-11-03 08:36:02,529 - contrastive_pretraining - INFO - Epoch 3290 - contrastive_loss/batch: 0.6305\n",
            "2025-11-03 08:36:02,529 - contrastive_pretraining - INFO - Epoch 3290 - learning_rate: 0.0003\n",
            "Epoch 46/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.1893]\n",
            "2025-11-03 08:36:27,645 - contrastive_pretraining - INFO - Epoch 46 - Average Loss: 0.5665\n",
            "2025-11-03 08:36:27,645 - contrastive_pretraining - INFO - Epoch 45 - contrastive_loss/epoch: 0.5665\n",
            "Epoch 47/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6248]2025-11-03 08:36:29,505 - contrastive_pretraining - INFO - Epoch 3312 - contrastive_loss/batch: 0.6248\n",
            "2025-11-03 08:36:29,506 - contrastive_pretraining - INFO - Epoch 3312 - learning_rate: 0.0003\n",
            "Epoch 47/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5457]2025-11-03 08:37:31,502 - contrastive_pretraining - INFO - Epoch 3362 - contrastive_loss/batch: 0.5457\n",
            "2025-11-03 08:37:31,502 - contrastive_pretraining - INFO - Epoch 3362 - learning_rate: 0.0003\n",
            "Epoch 47/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0447]\n",
            "2025-11-03 08:37:56,570 - contrastive_pretraining - INFO - Epoch 47 - Average Loss: 0.5490\n",
            "2025-11-03 08:37:56,570 - contrastive_pretraining - INFO - Epoch 46 - contrastive_loss/epoch: 0.5490\n",
            "Epoch 48/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4514]2025-11-03 08:37:58,460 - contrastive_pretraining - INFO - Epoch 3384 - contrastive_loss/batch: 0.4514\n",
            "2025-11-03 08:37:58,462 - contrastive_pretraining - INFO - Epoch 3384 - learning_rate: 0.0003\n",
            "Epoch 48/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4354]2025-11-03 08:39:00,403 - contrastive_pretraining - INFO - Epoch 3434 - contrastive_loss/batch: 0.4354\n",
            "2025-11-03 08:39:00,404 - contrastive_pretraining - INFO - Epoch 3434 - learning_rate: 0.0003\n",
            "Epoch 48/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0435]\n",
            "2025-11-03 08:39:25,576 - contrastive_pretraining - INFO - Epoch 48 - Average Loss: 0.5368\n",
            "2025-11-03 08:39:25,577 - contrastive_pretraining - INFO - Epoch 47 - contrastive_loss/epoch: 0.5368\n",
            "Epoch 49/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4510]2025-11-03 08:39:27,704 - contrastive_pretraining - INFO - Epoch 3456 - contrastive_loss/batch: 0.4510\n",
            "2025-11-03 08:39:27,706 - contrastive_pretraining - INFO - Epoch 3456 - learning_rate: 0.0003\n",
            "Epoch 49/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.4731]2025-11-03 08:40:29,678 - contrastive_pretraining - INFO - Epoch 3506 - contrastive_loss/batch: 0.4731\n",
            "2025-11-03 08:40:29,678 - contrastive_pretraining - INFO - Epoch 3506 - learning_rate: 0.0003\n",
            "Epoch 49/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0488]\n",
            "2025-11-03 08:40:54,814 - contrastive_pretraining - INFO - Epoch 49 - Average Loss: 0.5306\n",
            "2025-11-03 08:40:54,814 - contrastive_pretraining - INFO - Epoch 48 - contrastive_loss/epoch: 0.5306\n",
            "Epoch 50/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5053]2025-11-03 08:40:56,779 - contrastive_pretraining - INFO - Epoch 3528 - contrastive_loss/batch: 0.5053\n",
            "2025-11-03 08:40:56,780 - contrastive_pretraining - INFO - Epoch 3528 - learning_rate: 0.0003\n",
            "Epoch 50/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4305]2025-11-03 08:41:58,769 - contrastive_pretraining - INFO - Epoch 3578 - contrastive_loss/batch: 0.4305\n",
            "2025-11-03 08:41:58,769 - contrastive_pretraining - INFO - Epoch 3578 - learning_rate: 0.0003\n",
            "Epoch 50/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1497]\n",
            "2025-11-03 08:42:23,867 - contrastive_pretraining - INFO - Epoch 50 - Average Loss: 0.5246\n",
            "2025-11-03 08:42:23,868 - contrastive_pretraining - INFO - Epoch 49 - contrastive_loss/epoch: 0.5246\n",
            "Epoch 51/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.6448]2025-11-03 08:42:25,694 - contrastive_pretraining - INFO - Epoch 3600 - contrastive_loss/batch: 0.6448\n",
            "2025-11-03 08:42:25,695 - contrastive_pretraining - INFO - Epoch 3600 - learning_rate: 0.0003\n",
            "Epoch 51/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5113]2025-11-03 08:43:27,671 - contrastive_pretraining - INFO - Epoch 3650 - contrastive_loss/batch: 0.5113\n",
            "2025-11-03 08:43:27,672 - contrastive_pretraining - INFO - Epoch 3650 - learning_rate: 0.0003\n",
            "Epoch 51/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0155]\n",
            "2025-11-03 08:43:52,795 - contrastive_pretraining - INFO - Epoch 51 - Average Loss: 0.5324\n",
            "2025-11-03 08:43:52,796 - contrastive_pretraining - INFO - Epoch 50 - contrastive_loss/epoch: 0.5324\n",
            "Epoch 52/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5657]2025-11-03 08:43:54,658 - contrastive_pretraining - INFO - Epoch 3672 - contrastive_loss/batch: 0.5657\n",
            "2025-11-03 08:43:54,659 - contrastive_pretraining - INFO - Epoch 3672 - learning_rate: 0.0003\n",
            "Epoch 52/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.6094]2025-11-03 08:44:56,693 - contrastive_pretraining - INFO - Epoch 3722 - contrastive_loss/batch: 0.6094\n",
            "2025-11-03 08:44:56,693 - contrastive_pretraining - INFO - Epoch 3722 - learning_rate: 0.0003\n",
            "Epoch 52/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2580]\n",
            "2025-11-03 08:45:21,832 - contrastive_pretraining - INFO - Epoch 52 - Average Loss: 0.5328\n",
            "2025-11-03 08:45:21,832 - contrastive_pretraining - INFO - Epoch 51 - contrastive_loss/epoch: 0.5328\n",
            "Epoch 53/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4838]2025-11-03 08:45:23,701 - contrastive_pretraining - INFO - Epoch 3744 - contrastive_loss/batch: 0.4838\n",
            "2025-11-03 08:45:23,702 - contrastive_pretraining - INFO - Epoch 3744 - learning_rate: 0.0003\n",
            "Epoch 53/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5930]2025-11-03 08:46:25,745 - contrastive_pretraining - INFO - Epoch 3794 - contrastive_loss/batch: 0.5930\n",
            "2025-11-03 08:46:25,745 - contrastive_pretraining - INFO - Epoch 3794 - learning_rate: 0.0003\n",
            "Epoch 53/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1698]\n",
            "2025-11-03 08:46:50,881 - contrastive_pretraining - INFO - Epoch 53 - Average Loss: 0.5530\n",
            "2025-11-03 08:46:50,881 - contrastive_pretraining - INFO - Epoch 52 - contrastive_loss/epoch: 0.5530\n",
            "Epoch 54/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5469]2025-11-03 08:46:52,743 - contrastive_pretraining - INFO - Epoch 3816 - contrastive_loss/batch: 0.5469\n",
            "2025-11-03 08:46:52,744 - contrastive_pretraining - INFO - Epoch 3816 - learning_rate: 0.0003\n",
            "Epoch 54/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4489]2025-11-03 08:47:54,844 - contrastive_pretraining - INFO - Epoch 3866 - contrastive_loss/batch: 0.4489\n",
            "2025-11-03 08:47:54,845 - contrastive_pretraining - INFO - Epoch 3866 - learning_rate: 0.0003\n",
            "Epoch 54/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1384]\n",
            "2025-11-03 08:48:19,992 - contrastive_pretraining - INFO - Epoch 54 - Average Loss: 0.5319\n",
            "2025-11-03 08:48:19,992 - contrastive_pretraining - INFO - Epoch 53 - contrastive_loss/epoch: 0.5319\n",
            "Epoch 55/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4870]2025-11-03 08:48:22,073 - contrastive_pretraining - INFO - Epoch 3888 - contrastive_loss/batch: 0.4870\n",
            "2025-11-03 08:48:22,075 - contrastive_pretraining - INFO - Epoch 3888 - learning_rate: 0.0003\n",
            "Epoch 55/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.5445]2025-11-03 08:49:24,195 - contrastive_pretraining - INFO - Epoch 3938 - contrastive_loss/batch: 0.5445\n",
            "2025-11-03 08:49:24,195 - contrastive_pretraining - INFO - Epoch 3938 - learning_rate: 0.0003\n",
            "Epoch 55/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0568]\n",
            "2025-11-03 08:49:49,381 - contrastive_pretraining - INFO - Epoch 55 - Average Loss: 0.4935\n",
            "2025-11-03 08:49:49,381 - contrastive_pretraining - INFO - Epoch 54 - contrastive_loss/epoch: 0.4935\n",
            "Epoch 56/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.5519]2025-11-03 08:49:51,463 - contrastive_pretraining - INFO - Epoch 3960 - contrastive_loss/batch: 0.5519\n",
            "2025-11-03 08:49:51,464 - contrastive_pretraining - INFO - Epoch 3960 - learning_rate: 0.0003\n",
            "Epoch 56/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.5783]2025-11-03 08:50:53,426 - contrastive_pretraining - INFO - Epoch 4010 - contrastive_loss/batch: 0.5783\n",
            "2025-11-03 08:50:53,427 - contrastive_pretraining - INFO - Epoch 4010 - learning_rate: 0.0003\n",
            "Epoch 56/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0379]\n",
            "2025-11-03 08:51:18,468 - contrastive_pretraining - INFO - Epoch 56 - Average Loss: 0.5144\n",
            "2025-11-03 08:51:18,468 - contrastive_pretraining - INFO - Epoch 55 - contrastive_loss/epoch: 0.5144\n",
            "Epoch 57/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4593]2025-11-03 08:51:20,332 - contrastive_pretraining - INFO - Epoch 4032 - contrastive_loss/batch: 0.4593\n",
            "2025-11-03 08:51:20,332 - contrastive_pretraining - INFO - Epoch 4032 - learning_rate: 0.0003\n",
            "Epoch 57/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5512]2025-11-03 08:52:22,230 - contrastive_pretraining - INFO - Epoch 4082 - contrastive_loss/batch: 0.5512\n",
            "2025-11-03 08:52:22,230 - contrastive_pretraining - INFO - Epoch 4082 - learning_rate: 0.0003\n",
            "Epoch 57/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.2488]\n",
            "2025-11-03 08:52:47,328 - contrastive_pretraining - INFO - Epoch 57 - Average Loss: 0.5012\n",
            "2025-11-03 08:52:47,329 - contrastive_pretraining - INFO - Epoch 56 - contrastive_loss/epoch: 0.5012\n",
            "Epoch 58/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4980]2025-11-03 08:52:49,238 - contrastive_pretraining - INFO - Epoch 4104 - contrastive_loss/batch: 0.4980\n",
            "2025-11-03 08:52:49,239 - contrastive_pretraining - INFO - Epoch 4104 - learning_rate: 0.0003\n",
            "Epoch 58/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5258]2025-11-03 08:53:51,230 - contrastive_pretraining - INFO - Epoch 4154 - contrastive_loss/batch: 0.5258\n",
            "2025-11-03 08:53:51,231 - contrastive_pretraining - INFO - Epoch 4154 - learning_rate: 0.0003\n",
            "Epoch 58/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0562]\n",
            "2025-11-03 08:54:16,373 - contrastive_pretraining - INFO - Epoch 58 - Average Loss: 0.4970\n",
            "2025-11-03 08:54:16,374 - contrastive_pretraining - INFO - Epoch 57 - contrastive_loss/epoch: 0.4970\n",
            "Epoch 59/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4497]2025-11-03 08:54:18,210 - contrastive_pretraining - INFO - Epoch 4176 - contrastive_loss/batch: 0.4497\n",
            "2025-11-03 08:54:18,211 - contrastive_pretraining - INFO - Epoch 4176 - learning_rate: 0.0003\n",
            "Epoch 59/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3933]2025-11-03 08:55:20,259 - contrastive_pretraining - INFO - Epoch 4226 - contrastive_loss/batch: 0.3933\n",
            "2025-11-03 08:55:20,259 - contrastive_pretraining - INFO - Epoch 4226 - learning_rate: 0.0003\n",
            "Epoch 59/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.1018]\n",
            "2025-11-03 08:55:45,361 - contrastive_pretraining - INFO - Epoch 59 - Average Loss: 0.4805\n",
            "2025-11-03 08:55:45,362 - contrastive_pretraining - INFO - Epoch 58 - contrastive_loss/epoch: 0.4805\n",
            "Epoch 60/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3996]2025-11-03 08:55:47,263 - contrastive_pretraining - INFO - Epoch 4248 - contrastive_loss/batch: 0.3996\n",
            "2025-11-03 08:55:47,264 - contrastive_pretraining - INFO - Epoch 4248 - learning_rate: 0.0003\n",
            "Epoch 60/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.5530]2025-11-03 08:56:49,167 - contrastive_pretraining - INFO - Epoch 4298 - contrastive_loss/batch: 0.5530\n",
            "2025-11-03 08:56:49,168 - contrastive_pretraining - INFO - Epoch 4298 - learning_rate: 0.0003\n",
            "Epoch 60/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0444]\n",
            "2025-11-03 08:57:14,225 - contrastive_pretraining - INFO - Epoch 60 - Average Loss: 0.4700\n",
            "2025-11-03 08:57:14,226 - contrastive_pretraining - INFO - Epoch 59 - contrastive_loss/epoch: 0.4700\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 08:57:19,840 - contrastive_pretraining - INFO - Checkpoint saved: checkpoints/contrastive_epoch_60.pth\n",
            "Epoch 61/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4859]2025-11-03 08:57:21,746 - contrastive_pretraining - INFO - Epoch 4320 - contrastive_loss/batch: 0.4859\n",
            "2025-11-03 08:57:21,747 - contrastive_pretraining - INFO - Epoch 4320 - learning_rate: 0.0003\n",
            "Epoch 61/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.4897]2025-11-03 08:58:23,895 - contrastive_pretraining - INFO - Epoch 4370 - contrastive_loss/batch: 0.4897\n",
            "2025-11-03 08:58:23,896 - contrastive_pretraining - INFO - Epoch 4370 - learning_rate: 0.0003\n",
            "Epoch 61/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0591]\n",
            "2025-11-03 08:58:48,907 - contrastive_pretraining - INFO - Epoch 61 - Average Loss: 0.4726\n",
            "2025-11-03 08:58:48,907 - contrastive_pretraining - INFO - Epoch 60 - contrastive_loss/epoch: 0.4726\n",
            "Epoch 62/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4729]2025-11-03 08:58:50,778 - contrastive_pretraining - INFO - Epoch 4392 - contrastive_loss/batch: 0.4729\n",
            "2025-11-03 08:58:50,778 - contrastive_pretraining - INFO - Epoch 4392 - learning_rate: 0.0003\n",
            "Epoch 62/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4778]2025-11-03 08:59:52,836 - contrastive_pretraining - INFO - Epoch 4442 - contrastive_loss/batch: 0.4778\n",
            "2025-11-03 08:59:52,836 - contrastive_pretraining - INFO - Epoch 4442 - learning_rate: 0.0003\n",
            "Epoch 62/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0776]\n",
            "2025-11-03 09:00:17,882 - contrastive_pretraining - INFO - Epoch 62 - Average Loss: 0.4572\n",
            "2025-11-03 09:00:17,883 - contrastive_pretraining - INFO - Epoch 61 - contrastive_loss/epoch: 0.4572\n",
            "Epoch 63/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4199]2025-11-03 09:00:19,755 - contrastive_pretraining - INFO - Epoch 4464 - contrastive_loss/batch: 0.4199\n",
            "2025-11-03 09:00:19,758 - contrastive_pretraining - INFO - Epoch 4464 - learning_rate: 0.0003\n",
            "Epoch 63/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4898]2025-11-03 09:01:21,730 - contrastive_pretraining - INFO - Epoch 4514 - contrastive_loss/batch: 0.4898\n",
            "2025-11-03 09:01:21,731 - contrastive_pretraining - INFO - Epoch 4514 - learning_rate: 0.0003\n",
            "Epoch 63/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0256]\n",
            "2025-11-03 09:01:46,913 - contrastive_pretraining - INFO - Epoch 63 - Average Loss: 0.4574\n",
            "2025-11-03 09:01:46,913 - contrastive_pretraining - INFO - Epoch 62 - contrastive_loss/epoch: 0.4574\n",
            "Epoch 64/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.5185]2025-11-03 09:01:49,141 - contrastive_pretraining - INFO - Epoch 4536 - contrastive_loss/batch: 0.5185\n",
            "2025-11-03 09:01:49,141 - contrastive_pretraining - INFO - Epoch 4536 - learning_rate: 0.0003\n",
            "Epoch 64/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.5135]2025-11-03 09:02:51,222 - contrastive_pretraining - INFO - Epoch 4586 - contrastive_loss/batch: 0.5135\n",
            "2025-11-03 09:02:51,223 - contrastive_pretraining - INFO - Epoch 4586 - learning_rate: 0.0003\n",
            "Epoch 64/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0758]\n",
            "2025-11-03 09:03:16,369 - contrastive_pretraining - INFO - Epoch 64 - Average Loss: 0.4542\n",
            "2025-11-03 09:03:16,369 - contrastive_pretraining - INFO - Epoch 63 - contrastive_loss/epoch: 0.4542\n",
            "Epoch 65/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5094]2025-11-03 09:03:18,218 - contrastive_pretraining - INFO - Epoch 4608 - contrastive_loss/batch: 0.5094\n",
            "2025-11-03 09:03:18,219 - contrastive_pretraining - INFO - Epoch 4608 - learning_rate: 0.0003\n",
            "Epoch 65/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4129]2025-11-03 09:04:20,266 - contrastive_pretraining - INFO - Epoch 4658 - contrastive_loss/batch: 0.4129\n",
            "2025-11-03 09:04:20,266 - contrastive_pretraining - INFO - Epoch 4658 - learning_rate: 0.0003\n",
            "Epoch 65/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0528]\n",
            "2025-11-03 09:04:45,378 - contrastive_pretraining - INFO - Epoch 65 - Average Loss: 0.4372\n",
            "2025-11-03 09:04:45,379 - contrastive_pretraining - INFO - Epoch 64 - contrastive_loss/epoch: 0.4372\n",
            "Epoch 66/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4595]2025-11-03 09:04:47,257 - contrastive_pretraining - INFO - Epoch 4680 - contrastive_loss/batch: 0.4595\n",
            "2025-11-03 09:04:47,258 - contrastive_pretraining - INFO - Epoch 4680 - learning_rate: 0.0003\n",
            "Epoch 66/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4225]2025-11-03 09:05:49,233 - contrastive_pretraining - INFO - Epoch 4730 - contrastive_loss/batch: 0.4225\n",
            "2025-11-03 09:05:49,234 - contrastive_pretraining - INFO - Epoch 4730 - learning_rate: 0.0003\n",
            "Epoch 66/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0238]\n",
            "2025-11-03 09:06:14,357 - contrastive_pretraining - INFO - Epoch 66 - Average Loss: 0.4408\n",
            "2025-11-03 09:06:14,357 - contrastive_pretraining - INFO - Epoch 65 - contrastive_loss/epoch: 0.4408\n",
            "Epoch 67/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3332]2025-11-03 09:06:16,223 - contrastive_pretraining - INFO - Epoch 4752 - contrastive_loss/batch: 0.3332\n",
            "2025-11-03 09:06:16,224 - contrastive_pretraining - INFO - Epoch 4752 - learning_rate: 0.0003\n",
            "Epoch 67/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3676]2025-11-03 09:07:18,266 - contrastive_pretraining - INFO - Epoch 4802 - contrastive_loss/batch: 0.3676\n",
            "2025-11-03 09:07:18,267 - contrastive_pretraining - INFO - Epoch 4802 - learning_rate: 0.0003\n",
            "Epoch 67/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0218]\n",
            "2025-11-03 09:07:43,437 - contrastive_pretraining - INFO - Epoch 67 - Average Loss: 0.4459\n",
            "2025-11-03 09:07:43,437 - contrastive_pretraining - INFO - Epoch 66 - contrastive_loss/epoch: 0.4459\n",
            "Epoch 68/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5072]2025-11-03 09:07:45,305 - contrastive_pretraining - INFO - Epoch 4824 - contrastive_loss/batch: 0.5072\n",
            "2025-11-03 09:07:45,306 - contrastive_pretraining - INFO - Epoch 4824 - learning_rate: 0.0003\n",
            "Epoch 68/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3802]2025-11-03 09:08:47,350 - contrastive_pretraining - INFO - Epoch 4874 - contrastive_loss/batch: 0.3802\n",
            "2025-11-03 09:08:47,351 - contrastive_pretraining - INFO - Epoch 4874 - learning_rate: 0.0003\n",
            "Epoch 68/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0394]\n",
            "2025-11-03 09:09:12,519 - contrastive_pretraining - INFO - Epoch 68 - Average Loss: 0.4289\n",
            "2025-11-03 09:09:12,520 - contrastive_pretraining - INFO - Epoch 67 - contrastive_loss/epoch: 0.4289\n",
            "Epoch 69/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.3208]2025-11-03 09:09:14,745 - contrastive_pretraining - INFO - Epoch 4896 - contrastive_loss/batch: 0.3208\n",
            "2025-11-03 09:09:14,746 - contrastive_pretraining - INFO - Epoch 4896 - learning_rate: 0.0003\n",
            "Epoch 69/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.4935]2025-11-03 09:10:16,747 - contrastive_pretraining - INFO - Epoch 4946 - contrastive_loss/batch: 0.4935\n",
            "2025-11-03 09:10:16,748 - contrastive_pretraining - INFO - Epoch 4946 - learning_rate: 0.0003\n",
            "Epoch 69/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0414]\n",
            "2025-11-03 09:10:41,885 - contrastive_pretraining - INFO - Epoch 69 - Average Loss: 0.4312\n",
            "2025-11-03 09:10:41,886 - contrastive_pretraining - INFO - Epoch 68 - contrastive_loss/epoch: 0.4312\n",
            "Epoch 70/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3773]2025-11-03 09:10:43,710 - contrastive_pretraining - INFO - Epoch 4968 - contrastive_loss/batch: 0.3773\n",
            "2025-11-03 09:10:43,711 - contrastive_pretraining - INFO - Epoch 4968 - learning_rate: 0.0003\n",
            "Epoch 70/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4181]2025-11-03 09:11:45,700 - contrastive_pretraining - INFO - Epoch 5018 - contrastive_loss/batch: 0.4181\n",
            "2025-11-03 09:11:45,701 - contrastive_pretraining - INFO - Epoch 5018 - learning_rate: 0.0003\n",
            "Epoch 70/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0748]\n",
            "2025-11-03 09:12:10,850 - contrastive_pretraining - INFO - Epoch 70 - Average Loss: 0.4294\n",
            "2025-11-03 09:12:10,850 - contrastive_pretraining - INFO - Epoch 69 - contrastive_loss/epoch: 0.4294\n",
            "Epoch 71/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4021]2025-11-03 09:12:12,723 - contrastive_pretraining - INFO - Epoch 5040 - contrastive_loss/batch: 0.4021\n",
            "2025-11-03 09:12:12,724 - contrastive_pretraining - INFO - Epoch 5040 - learning_rate: 0.0003\n",
            "Epoch 71/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3951]2025-11-03 09:13:14,745 - contrastive_pretraining - INFO - Epoch 5090 - contrastive_loss/batch: 0.3951\n",
            "2025-11-03 09:13:14,745 - contrastive_pretraining - INFO - Epoch 5090 - learning_rate: 0.0003\n",
            "Epoch 71/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0457]\n",
            "2025-11-03 09:13:39,875 - contrastive_pretraining - INFO - Epoch 71 - Average Loss: 0.4085\n",
            "2025-11-03 09:13:39,875 - contrastive_pretraining - INFO - Epoch 70 - contrastive_loss/epoch: 0.4085\n",
            "Epoch 72/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4597]2025-11-03 09:13:41,756 - contrastive_pretraining - INFO - Epoch 5112 - contrastive_loss/batch: 0.4597\n",
            "2025-11-03 09:13:41,756 - contrastive_pretraining - INFO - Epoch 5112 - learning_rate: 0.0003\n",
            "Epoch 72/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4253]2025-11-03 09:14:43,732 - contrastive_pretraining - INFO - Epoch 5162 - contrastive_loss/batch: 0.4253\n",
            "2025-11-03 09:14:43,733 - contrastive_pretraining - INFO - Epoch 5162 - learning_rate: 0.0003\n",
            "Epoch 72/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0783]\n",
            "2025-11-03 09:15:08,782 - contrastive_pretraining - INFO - Epoch 72 - Average Loss: 0.4123\n",
            "2025-11-03 09:15:08,783 - contrastive_pretraining - INFO - Epoch 71 - contrastive_loss/epoch: 0.4123\n",
            "Epoch 73/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4707]2025-11-03 09:15:10,649 - contrastive_pretraining - INFO - Epoch 5184 - contrastive_loss/batch: 0.4707\n",
            "2025-11-03 09:15:10,649 - contrastive_pretraining - INFO - Epoch 5184 - learning_rate: 0.0003\n",
            "Epoch 73/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3995]2025-11-03 09:16:12,702 - contrastive_pretraining - INFO - Epoch 5234 - contrastive_loss/batch: 0.3995\n",
            "2025-11-03 09:16:12,702 - contrastive_pretraining - INFO - Epoch 5234 - learning_rate: 0.0003\n",
            "Epoch 73/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0171]\n",
            "2025-11-03 09:16:37,818 - contrastive_pretraining - INFO - Epoch 73 - Average Loss: 0.4316\n",
            "2025-11-03 09:16:37,818 - contrastive_pretraining - INFO - Epoch 72 - contrastive_loss/epoch: 0.4316\n",
            "Epoch 74/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4276]2025-11-03 09:16:39,666 - contrastive_pretraining - INFO - Epoch 5256 - contrastive_loss/batch: 0.4276\n",
            "2025-11-03 09:16:39,670 - contrastive_pretraining - INFO - Epoch 5256 - learning_rate: 0.0003\n",
            "Epoch 74/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3449]2025-11-03 09:17:41,594 - contrastive_pretraining - INFO - Epoch 5306 - contrastive_loss/batch: 0.3449\n",
            "2025-11-03 09:17:41,595 - contrastive_pretraining - INFO - Epoch 5306 - learning_rate: 0.0003\n",
            "Epoch 74/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0235]\n",
            "2025-11-03 09:18:06,714 - contrastive_pretraining - INFO - Epoch 74 - Average Loss: 0.4217\n",
            "2025-11-03 09:18:06,714 - contrastive_pretraining - INFO - Epoch 73 - contrastive_loss/epoch: 0.4217\n",
            "Epoch 75/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4003]2025-11-03 09:18:09,062 - contrastive_pretraining - INFO - Epoch 5328 - contrastive_loss/batch: 0.4003\n",
            "2025-11-03 09:18:09,062 - contrastive_pretraining - INFO - Epoch 5328 - learning_rate: 0.0003\n",
            "Epoch 75/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.3779]2025-11-03 09:19:10,941 - contrastive_pretraining - INFO - Epoch 5378 - contrastive_loss/batch: 0.3779\n",
            "2025-11-03 09:19:10,942 - contrastive_pretraining - INFO - Epoch 5378 - learning_rate: 0.0003\n",
            "Epoch 75/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0238]\n",
            "2025-11-03 09:19:36,026 - contrastive_pretraining - INFO - Epoch 75 - Average Loss: 0.4111\n",
            "2025-11-03 09:19:36,026 - contrastive_pretraining - INFO - Epoch 74 - contrastive_loss/epoch: 0.4111\n",
            "Epoch 76/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3864]2025-11-03 09:19:37,862 - contrastive_pretraining - INFO - Epoch 5400 - contrastive_loss/batch: 0.3864\n",
            "2025-11-03 09:19:37,863 - contrastive_pretraining - INFO - Epoch 5400 - learning_rate: 0.0003\n",
            "Epoch 76/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3712]2025-11-03 09:20:39,818 - contrastive_pretraining - INFO - Epoch 5450 - contrastive_loss/batch: 0.3712\n",
            "2025-11-03 09:20:39,819 - contrastive_pretraining - INFO - Epoch 5450 - learning_rate: 0.0003\n",
            "Epoch 76/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.3672]\n",
            "2025-11-03 09:21:04,894 - contrastive_pretraining - INFO - Epoch 76 - Average Loss: 0.4046\n",
            "2025-11-03 09:21:04,894 - contrastive_pretraining - INFO - Epoch 75 - contrastive_loss/epoch: 0.4046\n",
            "Epoch 77/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4120]2025-11-03 09:21:06,702 - contrastive_pretraining - INFO - Epoch 5472 - contrastive_loss/batch: 0.4120\n",
            "2025-11-03 09:21:06,703 - contrastive_pretraining - INFO - Epoch 5472 - learning_rate: 0.0003\n",
            "Epoch 77/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.2431]2025-11-03 09:22:08,741 - contrastive_pretraining - INFO - Epoch 5522 - contrastive_loss/batch: 0.2431\n",
            "2025-11-03 09:22:08,742 - contrastive_pretraining - INFO - Epoch 5522 - learning_rate: 0.0003\n",
            "Epoch 77/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0144]\n",
            "2025-11-03 09:22:33,868 - contrastive_pretraining - INFO - Epoch 77 - Average Loss: 0.4139\n",
            "2025-11-03 09:22:33,869 - contrastive_pretraining - INFO - Epoch 76 - contrastive_loss/epoch: 0.4139\n",
            "Epoch 78/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4567]2025-11-03 09:22:35,691 - contrastive_pretraining - INFO - Epoch 5544 - contrastive_loss/batch: 0.4567\n",
            "2025-11-03 09:22:35,691 - contrastive_pretraining - INFO - Epoch 5544 - learning_rate: 0.0003\n",
            "Epoch 78/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4313]2025-11-03 09:23:37,746 - contrastive_pretraining - INFO - Epoch 5594 - contrastive_loss/batch: 0.4313\n",
            "2025-11-03 09:23:37,747 - contrastive_pretraining - INFO - Epoch 5594 - learning_rate: 0.0003\n",
            "Epoch 78/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0842]\n",
            "2025-11-03 09:24:02,887 - contrastive_pretraining - INFO - Epoch 78 - Average Loss: 0.4084\n",
            "2025-11-03 09:24:02,887 - contrastive_pretraining - INFO - Epoch 77 - contrastive_loss/epoch: 0.4084\n",
            "Epoch 79/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4195]2025-11-03 09:24:04,779 - contrastive_pretraining - INFO - Epoch 5616 - contrastive_loss/batch: 0.4195\n",
            "2025-11-03 09:24:04,780 - contrastive_pretraining - INFO - Epoch 5616 - learning_rate: 0.0003\n",
            "Epoch 79/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.4280]2025-11-03 09:25:06,714 - contrastive_pretraining - INFO - Epoch 5666 - contrastive_loss/batch: 0.4280\n",
            "2025-11-03 09:25:06,715 - contrastive_pretraining - INFO - Epoch 5666 - learning_rate: 0.0003\n",
            "Epoch 79/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0227]\n",
            "2025-11-03 09:25:31,754 - contrastive_pretraining - INFO - Epoch 79 - Average Loss: 0.3907\n",
            "2025-11-03 09:25:31,755 - contrastive_pretraining - INFO - Epoch 78 - contrastive_loss/epoch: 0.3907\n",
            "Epoch 80/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4470]2025-11-03 09:25:33,760 - contrastive_pretraining - INFO - Epoch 5688 - contrastive_loss/batch: 0.4470\n",
            "2025-11-03 09:25:33,763 - contrastive_pretraining - INFO - Epoch 5688 - learning_rate: 0.0003\n",
            "Epoch 80/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3934]2025-11-03 09:26:35,694 - contrastive_pretraining - INFO - Epoch 5738 - contrastive_loss/batch: 0.3934\n",
            "2025-11-03 09:26:35,695 - contrastive_pretraining - INFO - Epoch 5738 - learning_rate: 0.0003\n",
            "Epoch 80/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1164]\n",
            "2025-11-03 09:27:00,846 - contrastive_pretraining - INFO - Epoch 80 - Average Loss: 0.3795\n",
            "2025-11-03 09:27:00,846 - contrastive_pretraining - INFO - Epoch 79 - contrastive_loss/epoch: 0.3795\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:27:06,831 - contrastive_pretraining - INFO - Checkpoint saved: checkpoints/contrastive_epoch_80.pth\n",
            "Epoch 81/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4417]2025-11-03 09:27:08,697 - contrastive_pretraining - INFO - Epoch 5760 - contrastive_loss/batch: 0.4417\n",
            "2025-11-03 09:27:08,697 - contrastive_pretraining - INFO - Epoch 5760 - learning_rate: 0.0003\n",
            "Epoch 81/100:  69% 50/72 [01:03<00:27,  1.23s/it, Loss=0.4356]2025-11-03 09:28:10,825 - contrastive_pretraining - INFO - Epoch 5810 - contrastive_loss/batch: 0.4356\n",
            "2025-11-03 09:28:10,825 - contrastive_pretraining - INFO - Epoch 5810 - learning_rate: 0.0003\n",
            "Epoch 81/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0528]\n",
            "2025-11-03 09:28:35,840 - contrastive_pretraining - INFO - Epoch 81 - Average Loss: 0.3915\n",
            "2025-11-03 09:28:35,841 - contrastive_pretraining - INFO - Epoch 80 - contrastive_loss/epoch: 0.3915\n",
            "Epoch 82/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4194]2025-11-03 09:28:37,727 - contrastive_pretraining - INFO - Epoch 5832 - contrastive_loss/batch: 0.4194\n",
            "2025-11-03 09:28:37,727 - contrastive_pretraining - INFO - Epoch 5832 - learning_rate: 0.0003\n",
            "Epoch 82/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.2841]2025-11-03 09:29:39,790 - contrastive_pretraining - INFO - Epoch 5882 - contrastive_loss/batch: 0.2841\n",
            "2025-11-03 09:29:39,791 - contrastive_pretraining - INFO - Epoch 5882 - learning_rate: 0.0003\n",
            "Epoch 82/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0244]\n",
            "2025-11-03 09:30:04,919 - contrastive_pretraining - INFO - Epoch 82 - Average Loss: 0.3832\n",
            "2025-11-03 09:30:04,919 - contrastive_pretraining - INFO - Epoch 81 - contrastive_loss/epoch: 0.3832\n",
            "Epoch 83/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4165]2025-11-03 09:30:07,361 - contrastive_pretraining - INFO - Epoch 5904 - contrastive_loss/batch: 0.4165\n",
            "2025-11-03 09:30:07,363 - contrastive_pretraining - INFO - Epoch 5904 - learning_rate: 0.0003\n",
            "Epoch 83/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.3949]2025-11-03 09:31:09,323 - contrastive_pretraining - INFO - Epoch 5954 - contrastive_loss/batch: 0.3949\n",
            "2025-11-03 09:31:09,324 - contrastive_pretraining - INFO - Epoch 5954 - learning_rate: 0.0003\n",
            "Epoch 83/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0138]\n",
            "2025-11-03 09:31:34,429 - contrastive_pretraining - INFO - Epoch 83 - Average Loss: 0.3875\n",
            "2025-11-03 09:31:34,429 - contrastive_pretraining - INFO - Epoch 82 - contrastive_loss/epoch: 0.3875\n",
            "Epoch 84/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3994]2025-11-03 09:31:36,291 - contrastive_pretraining - INFO - Epoch 5976 - contrastive_loss/batch: 0.3994\n",
            "2025-11-03 09:31:36,292 - contrastive_pretraining - INFO - Epoch 5976 - learning_rate: 0.0003\n",
            "Epoch 84/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3556]2025-11-03 09:32:38,249 - contrastive_pretraining - INFO - Epoch 6026 - contrastive_loss/batch: 0.3556\n",
            "2025-11-03 09:32:38,249 - contrastive_pretraining - INFO - Epoch 6026 - learning_rate: 0.0003\n",
            "Epoch 84/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0479]\n",
            "2025-11-03 09:33:03,301 - contrastive_pretraining - INFO - Epoch 84 - Average Loss: 0.3707\n",
            "2025-11-03 09:33:03,301 - contrastive_pretraining - INFO - Epoch 83 - contrastive_loss/epoch: 0.3707\n",
            "Epoch 85/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3616]2025-11-03 09:33:05,106 - contrastive_pretraining - INFO - Epoch 6048 - contrastive_loss/batch: 0.3616\n",
            "2025-11-03 09:33:05,107 - contrastive_pretraining - INFO - Epoch 6048 - learning_rate: 0.0003\n",
            "Epoch 85/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3929]2025-11-03 09:34:07,017 - contrastive_pretraining - INFO - Epoch 6098 - contrastive_loss/batch: 0.3929\n",
            "2025-11-03 09:34:07,017 - contrastive_pretraining - INFO - Epoch 6098 - learning_rate: 0.0003\n",
            "Epoch 85/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0973]\n",
            "2025-11-03 09:34:32,113 - contrastive_pretraining - INFO - Epoch 85 - Average Loss: 0.3708\n",
            "2025-11-03 09:34:32,113 - contrastive_pretraining - INFO - Epoch 84 - contrastive_loss/epoch: 0.3708\n",
            "Epoch 86/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3914]2025-11-03 09:34:34,009 - contrastive_pretraining - INFO - Epoch 6120 - contrastive_loss/batch: 0.3914\n",
            "2025-11-03 09:34:34,010 - contrastive_pretraining - INFO - Epoch 6120 - learning_rate: 0.0003\n",
            "Epoch 86/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3688]2025-11-03 09:35:35,955 - contrastive_pretraining - INFO - Epoch 6170 - contrastive_loss/batch: 0.3688\n",
            "2025-11-03 09:35:35,955 - contrastive_pretraining - INFO - Epoch 6170 - learning_rate: 0.0003\n",
            "Epoch 86/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0415]\n",
            "2025-11-03 09:36:01,015 - contrastive_pretraining - INFO - Epoch 86 - Average Loss: 0.3695\n",
            "2025-11-03 09:36:01,015 - contrastive_pretraining - INFO - Epoch 85 - contrastive_loss/epoch: 0.3695\n",
            "Epoch 87/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3729]2025-11-03 09:36:02,851 - contrastive_pretraining - INFO - Epoch 6192 - contrastive_loss/batch: 0.3729\n",
            "2025-11-03 09:36:02,852 - contrastive_pretraining - INFO - Epoch 6192 - learning_rate: 0.0003\n",
            "Epoch 87/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3717]2025-11-03 09:37:04,896 - contrastive_pretraining - INFO - Epoch 6242 - contrastive_loss/batch: 0.3717\n",
            "2025-11-03 09:37:04,897 - contrastive_pretraining - INFO - Epoch 6242 - learning_rate: 0.0003\n",
            "Epoch 87/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.2403]\n",
            "2025-11-03 09:37:29,995 - contrastive_pretraining - INFO - Epoch 87 - Average Loss: 0.3681\n",
            "2025-11-03 09:37:29,995 - contrastive_pretraining - INFO - Epoch 86 - contrastive_loss/epoch: 0.3681\n",
            "Epoch 88/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.2936]2025-11-03 09:37:31,877 - contrastive_pretraining - INFO - Epoch 6264 - contrastive_loss/batch: 0.2936\n",
            "2025-11-03 09:37:31,877 - contrastive_pretraining - INFO - Epoch 6264 - learning_rate: 0.0003\n",
            "Epoch 88/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3181]2025-11-03 09:38:33,976 - contrastive_pretraining - INFO - Epoch 6314 - contrastive_loss/batch: 0.3181\n",
            "2025-11-03 09:38:33,977 - contrastive_pretraining - INFO - Epoch 6314 - learning_rate: 0.0003\n",
            "Epoch 88/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.1248]\n",
            "2025-11-03 09:38:59,075 - contrastive_pretraining - INFO - Epoch 88 - Average Loss: 0.3742\n",
            "2025-11-03 09:38:59,076 - contrastive_pretraining - INFO - Epoch 87 - contrastive_loss/epoch: 0.3742\n",
            "Epoch 89/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4263]2025-11-03 09:39:01,200 - contrastive_pretraining - INFO - Epoch 6336 - contrastive_loss/batch: 0.4263\n",
            "2025-11-03 09:39:01,201 - contrastive_pretraining - INFO - Epoch 6336 - learning_rate: 0.0003\n",
            "Epoch 89/100:  69% 50/72 [01:04<00:27,  1.25s/it, Loss=0.3398]2025-11-03 09:40:03,218 - contrastive_pretraining - INFO - Epoch 6386 - contrastive_loss/batch: 0.3398\n",
            "2025-11-03 09:40:03,219 - contrastive_pretraining - INFO - Epoch 6386 - learning_rate: 0.0003\n",
            "Epoch 89/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0111]\n",
            "2025-11-03 09:40:28,333 - contrastive_pretraining - INFO - Epoch 89 - Average Loss: 0.3649\n",
            "2025-11-03 09:40:28,334 - contrastive_pretraining - INFO - Epoch 88 - contrastive_loss/epoch: 0.3649\n",
            "Epoch 90/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.5238]2025-11-03 09:40:30,164 - contrastive_pretraining - INFO - Epoch 6408 - contrastive_loss/batch: 0.5238\n",
            "2025-11-03 09:40:30,165 - contrastive_pretraining - INFO - Epoch 6408 - learning_rate: 0.0003\n",
            "Epoch 90/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3482]2025-11-03 09:41:32,122 - contrastive_pretraining - INFO - Epoch 6458 - contrastive_loss/batch: 0.3482\n",
            "2025-11-03 09:41:32,123 - contrastive_pretraining - INFO - Epoch 6458 - learning_rate: 0.0003\n",
            "Epoch 90/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0631]\n",
            "2025-11-03 09:41:57,249 - contrastive_pretraining - INFO - Epoch 90 - Average Loss: 0.3621\n",
            "2025-11-03 09:41:57,249 - contrastive_pretraining - INFO - Epoch 89 - contrastive_loss/epoch: 0.3621\n",
            "Epoch 91/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3458]2025-11-03 09:41:59,101 - contrastive_pretraining - INFO - Epoch 6480 - contrastive_loss/batch: 0.3458\n",
            "2025-11-03 09:41:59,101 - contrastive_pretraining - INFO - Epoch 6480 - learning_rate: 0.0003\n",
            "Epoch 91/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3517]2025-11-03 09:43:01,105 - contrastive_pretraining - INFO - Epoch 6530 - contrastive_loss/batch: 0.3517\n",
            "2025-11-03 09:43:01,105 - contrastive_pretraining - INFO - Epoch 6530 - learning_rate: 0.0003\n",
            "Epoch 91/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0142]\n",
            "2025-11-03 09:43:26,275 - contrastive_pretraining - INFO - Epoch 91 - Average Loss: 0.3570\n",
            "2025-11-03 09:43:26,275 - contrastive_pretraining - INFO - Epoch 90 - contrastive_loss/epoch: 0.3570\n",
            "Epoch 92/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.4233]2025-11-03 09:43:28,086 - contrastive_pretraining - INFO - Epoch 6552 - contrastive_loss/batch: 0.4233\n",
            "2025-11-03 09:43:28,087 - contrastive_pretraining - INFO - Epoch 6552 - learning_rate: 0.0003\n",
            "Epoch 92/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3812]2025-11-03 09:44:29,929 - contrastive_pretraining - INFO - Epoch 6602 - contrastive_loss/batch: 0.3812\n",
            "2025-11-03 09:44:29,930 - contrastive_pretraining - INFO - Epoch 6602 - learning_rate: 0.0003\n",
            "Epoch 92/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.1894]\n",
            "2025-11-03 09:44:54,990 - contrastive_pretraining - INFO - Epoch 92 - Average Loss: 0.3492\n",
            "2025-11-03 09:44:54,991 - contrastive_pretraining - INFO - Epoch 91 - contrastive_loss/epoch: 0.3492\n",
            "Epoch 93/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3241]2025-11-03 09:44:56,837 - contrastive_pretraining - INFO - Epoch 6624 - contrastive_loss/batch: 0.3241\n",
            "2025-11-03 09:44:56,837 - contrastive_pretraining - INFO - Epoch 6624 - learning_rate: 0.0003\n",
            "Epoch 93/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3610]2025-11-03 09:45:58,921 - contrastive_pretraining - INFO - Epoch 6674 - contrastive_loss/batch: 0.3610\n",
            "2025-11-03 09:45:58,922 - contrastive_pretraining - INFO - Epoch 6674 - learning_rate: 0.0003\n",
            "Epoch 93/100: 100% 72/72 [01:28<00:00,  1.24s/it, Loss=0.0219]\n",
            "2025-11-03 09:46:23,977 - contrastive_pretraining - INFO - Epoch 93 - Average Loss: 0.3612\n",
            "2025-11-03 09:46:23,977 - contrastive_pretraining - INFO - Epoch 92 - contrastive_loss/epoch: 0.3612\n",
            "Epoch 94/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4129]2025-11-03 09:46:26,168 - contrastive_pretraining - INFO - Epoch 6696 - contrastive_loss/batch: 0.4129\n",
            "2025-11-03 09:46:26,169 - contrastive_pretraining - INFO - Epoch 6696 - learning_rate: 0.0003\n",
            "Epoch 94/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.2998]2025-11-03 09:47:28,136 - contrastive_pretraining - INFO - Epoch 6746 - contrastive_loss/batch: 0.2998\n",
            "2025-11-03 09:47:28,137 - contrastive_pretraining - INFO - Epoch 6746 - learning_rate: 0.0003\n",
            "Epoch 94/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.2328]\n",
            "2025-11-03 09:47:53,277 - contrastive_pretraining - INFO - Epoch 94 - Average Loss: 0.3519\n",
            "2025-11-03 09:47:53,278 - contrastive_pretraining - INFO - Epoch 93 - contrastive_loss/epoch: 0.3519\n",
            "Epoch 95/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3294]2025-11-03 09:47:55,146 - contrastive_pretraining - INFO - Epoch 6768 - contrastive_loss/batch: 0.3294\n",
            "2025-11-03 09:47:55,147 - contrastive_pretraining - INFO - Epoch 6768 - learning_rate: 0.0003\n",
            "Epoch 95/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3843]2025-11-03 09:48:56,996 - contrastive_pretraining - INFO - Epoch 6818 - contrastive_loss/batch: 0.3843\n",
            "2025-11-03 09:48:56,997 - contrastive_pretraining - INFO - Epoch 6818 - learning_rate: 0.0003\n",
            "Epoch 95/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0330]\n",
            "2025-11-03 09:49:22,045 - contrastive_pretraining - INFO - Epoch 95 - Average Loss: 0.3462\n",
            "2025-11-03 09:49:22,045 - contrastive_pretraining - INFO - Epoch 94 - contrastive_loss/epoch: 0.3462\n",
            "Epoch 96/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.2960]2025-11-03 09:49:23,867 - contrastive_pretraining - INFO - Epoch 6840 - contrastive_loss/batch: 0.2960\n",
            "2025-11-03 09:49:23,867 - contrastive_pretraining - INFO - Epoch 6840 - learning_rate: 0.0003\n",
            "Epoch 96/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3787]2025-11-03 09:50:25,864 - contrastive_pretraining - INFO - Epoch 6890 - contrastive_loss/batch: 0.3787\n",
            "2025-11-03 09:50:25,865 - contrastive_pretraining - INFO - Epoch 6890 - learning_rate: 0.0003\n",
            "Epoch 96/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0100]\n",
            "2025-11-03 09:50:50,963 - contrastive_pretraining - INFO - Epoch 96 - Average Loss: 0.3461\n",
            "2025-11-03 09:50:50,963 - contrastive_pretraining - INFO - Epoch 95 - contrastive_loss/epoch: 0.3461\n",
            "Epoch 97/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.2811]2025-11-03 09:50:52,753 - contrastive_pretraining - INFO - Epoch 6912 - contrastive_loss/batch: 0.2811\n",
            "2025-11-03 09:50:52,754 - contrastive_pretraining - INFO - Epoch 6912 - learning_rate: 0.0003\n",
            "Epoch 97/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3281]2025-11-03 09:51:54,663 - contrastive_pretraining - INFO - Epoch 6962 - contrastive_loss/batch: 0.3281\n",
            "2025-11-03 09:51:54,663 - contrastive_pretraining - INFO - Epoch 6962 - learning_rate: 0.0003\n",
            "Epoch 97/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0158]\n",
            "2025-11-03 09:52:19,815 - contrastive_pretraining - INFO - Epoch 97 - Average Loss: 0.3478\n",
            "2025-11-03 09:52:19,816 - contrastive_pretraining - INFO - Epoch 96 - contrastive_loss/epoch: 0.3478\n",
            "Epoch 98/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3588]2025-11-03 09:52:21,701 - contrastive_pretraining - INFO - Epoch 6984 - contrastive_loss/batch: 0.3588\n",
            "2025-11-03 09:52:21,701 - contrastive_pretraining - INFO - Epoch 6984 - learning_rate: 0.0003\n",
            "Epoch 98/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3588]2025-11-03 09:53:23,748 - contrastive_pretraining - INFO - Epoch 7034 - contrastive_loss/batch: 0.3588\n",
            "2025-11-03 09:53:23,748 - contrastive_pretraining - INFO - Epoch 7034 - learning_rate: 0.0003\n",
            "Epoch 98/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0209]\n",
            "2025-11-03 09:53:48,907 - contrastive_pretraining - INFO - Epoch 98 - Average Loss: 0.3530\n",
            "2025-11-03 09:53:48,907 - contrastive_pretraining - INFO - Epoch 97 - contrastive_loss/epoch: 0.3530\n",
            "Epoch 99/100:   0% 0/72 [00:02<?, ?it/s, Loss=0.4212]2025-11-03 09:53:51,249 - contrastive_pretraining - INFO - Epoch 7056 - contrastive_loss/batch: 0.4212\n",
            "2025-11-03 09:53:51,249 - contrastive_pretraining - INFO - Epoch 7056 - learning_rate: 0.0003\n",
            "Epoch 99/100:  69% 50/72 [01:04<00:27,  1.24s/it, Loss=0.4948]2025-11-03 09:54:53,280 - contrastive_pretraining - INFO - Epoch 7106 - contrastive_loss/batch: 0.4948\n",
            "2025-11-03 09:54:53,280 - contrastive_pretraining - INFO - Epoch 7106 - learning_rate: 0.0003\n",
            "Epoch 99/100: 100% 72/72 [01:29<00:00,  1.24s/it, Loss=0.0948]\n",
            "2025-11-03 09:55:18,404 - contrastive_pretraining - INFO - Epoch 99 - Average Loss: 0.3633\n",
            "2025-11-03 09:55:18,404 - contrastive_pretraining - INFO - Epoch 98 - contrastive_loss/epoch: 0.3633\n",
            "Epoch 100/100:   0% 0/72 [00:01<?, ?it/s, Loss=0.3392]2025-11-03 09:55:20,240 - contrastive_pretraining - INFO - Epoch 7128 - contrastive_loss/batch: 0.3392\n",
            "2025-11-03 09:55:20,241 - contrastive_pretraining - INFO - Epoch 7128 - learning_rate: 0.0003\n",
            "Epoch 100/100:  69% 50/72 [01:03<00:27,  1.24s/it, Loss=0.3410]2025-11-03 09:56:22,057 - contrastive_pretraining - INFO - Epoch 7178 - contrastive_loss/batch: 0.3410\n",
            "2025-11-03 09:56:22,057 - contrastive_pretraining - INFO - Epoch 7178 - learning_rate: 0.0003\n",
            "Epoch 100/100: 100% 72/72 [01:28<00:00,  1.23s/it, Loss=0.0791]\n",
            "2025-11-03 09:56:47,134 - contrastive_pretraining - INFO - Epoch 100 - Average Loss: 0.3457\n",
            "2025-11-03 09:56:47,134 - contrastive_pretraining - INFO - Epoch 99 - contrastive_loss/epoch: 0.3457\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:56:53,584 - contrastive_pretraining - INFO - Checkpoint saved: checkpoints/contrastive_epoch_100.pth\n",
            "2025-11-03 09:56:54,412 - contrastive_pretraining - INFO - Contrastive pre-training completed! Model saved to /content/training_output/contrastive_training/models/contrastive_pretrained.pth\n",
            "Contrastive loss plot saved: plots/contrastive_loss.png\n",
            "2025-11-03 09:56:54,965 - contrastive_pretraining - INFO - === Contrastive Pre-training Finished ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the output\n",
        "# !zip -r contrastive_training_output.zip /content/contrastive_training_output"
      ],
      "metadata": {
        "id": "YXy-l8IA38En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Training Phase 2 - Supervised Learning (5-class dataset)"
      ],
      "metadata": {
        "id": "wzbTABHGQ263"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/tselane2110/SSCLNet-Implementation"
      ],
      "metadata": {
        "id": "EVnQlQej2EpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "# !gdown --fuzzy \"https://drive.google.com/file/d/16-v8HBPN_Nnj8JnQSDRSnfq5C1YqD-8y/view?usp=drive_link\"\n",
        "# !unzip -q /content/Preprocessed-splitted-data.zip"
      ],
      "metadata": {
        "id": "NU8QtVAo2GYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/SSCLNet-Implementation/train_supervised.py\""
      ],
      "metadata": {
        "id": "vYoNIzhXQT-E",
        "outputId": "74dd3d7b-4247-4ed2-fd1d-0272183baef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-03 09:57:04.668417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762163824.688643   39845 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762163824.694845   39845 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762163824.710018   39845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762163824.710045   39845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762163824.710049   39845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762163824.710052   39845 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-03 09:57:04.714845: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ All directories created\n",
            "✓ All directories created\n",
            "✓ Random seed set to: 42\n",
            "2025-11-03 09:57:09,479 - supervised_finetuning - INFO - === Starting TWO-STAGE Supervised Fine-tuning ===\n",
            "✓ It's a model file - loading directly\n",
            "2025-11-03 09:57:10,231 - supervised_finetuning - INFO - ✓ Loaded pre-trained weights from contrastive training!\n",
            "================================================================================\n",
            "MODEL SUMMARY\n",
            "================================================================================\n",
            "Model: SSCLNet\n",
            "Total trainable parameters: 25,669,541\n",
            "Model size: 98.12 MB\n",
            "\n",
            "Layer breakdown:\n",
            "  encoder.conv1.weight: 3,136\n",
            "  encoder.bn1.weight: 64\n",
            "  encoder.bn1.bias: 64\n",
            "  encoder.layer1.0.conv1.weight: 4,096\n",
            "  encoder.layer1.0.bn1.weight: 64\n",
            "  encoder.layer1.0.bn1.bias: 64\n",
            "  encoder.layer1.0.conv2.weight: 36,864\n",
            "  encoder.layer1.0.bn2.weight: 64\n",
            "  encoder.layer1.0.bn2.bias: 64\n",
            "  encoder.layer1.0.conv3.weight: 16,384\n",
            "  encoder.layer1.0.bn3.weight: 256\n",
            "  encoder.layer1.0.bn3.bias: 256\n",
            "  encoder.layer1.0.downsample.0.weight: 16,384\n",
            "  encoder.layer1.0.downsample.1.weight: 256\n",
            "  encoder.layer1.0.downsample.1.bias: 256\n",
            "  encoder.layer1.1.conv1.weight: 16,384\n",
            "  encoder.layer1.1.bn1.weight: 64\n",
            "  encoder.layer1.1.bn1.bias: 64\n",
            "  encoder.layer1.1.conv2.weight: 36,864\n",
            "  encoder.layer1.1.bn2.weight: 64\n",
            "  encoder.layer1.1.bn2.bias: 64\n",
            "  encoder.layer1.1.conv3.weight: 16,384\n",
            "  encoder.layer1.1.bn3.weight: 256\n",
            "  encoder.layer1.1.bn3.bias: 256\n",
            "  encoder.layer1.2.conv1.weight: 16,384\n",
            "  encoder.layer1.2.bn1.weight: 64\n",
            "  encoder.layer1.2.bn1.bias: 64\n",
            "  encoder.layer1.2.conv2.weight: 36,864\n",
            "  encoder.layer1.2.bn2.weight: 64\n",
            "  encoder.layer1.2.bn2.bias: 64\n",
            "  encoder.layer1.2.conv3.weight: 16,384\n",
            "  encoder.layer1.2.bn3.weight: 256\n",
            "  encoder.layer1.2.bn3.bias: 256\n",
            "  encoder.layer2.0.conv1.weight: 32,768\n",
            "  encoder.layer2.0.bn1.weight: 128\n",
            "  encoder.layer2.0.bn1.bias: 128\n",
            "  encoder.layer2.0.conv2.weight: 147,456\n",
            "  encoder.layer2.0.bn2.weight: 128\n",
            "  encoder.layer2.0.bn2.bias: 128\n",
            "  encoder.layer2.0.conv3.weight: 65,536\n",
            "  encoder.layer2.0.bn3.weight: 512\n",
            "  encoder.layer2.0.bn3.bias: 512\n",
            "  encoder.layer2.0.downsample.0.weight: 131,072\n",
            "  encoder.layer2.0.downsample.1.weight: 512\n",
            "  encoder.layer2.0.downsample.1.bias: 512\n",
            "  encoder.layer2.1.conv1.weight: 65,536\n",
            "  encoder.layer2.1.bn1.weight: 128\n",
            "  encoder.layer2.1.bn1.bias: 128\n",
            "  encoder.layer2.1.conv2.weight: 147,456\n",
            "  encoder.layer2.1.bn2.weight: 128\n",
            "  encoder.layer2.1.bn2.bias: 128\n",
            "  encoder.layer2.1.conv3.weight: 65,536\n",
            "  encoder.layer2.1.bn3.weight: 512\n",
            "  encoder.layer2.1.bn3.bias: 512\n",
            "  encoder.layer2.2.conv1.weight: 65,536\n",
            "  encoder.layer2.2.bn1.weight: 128\n",
            "  encoder.layer2.2.bn1.bias: 128\n",
            "  encoder.layer2.2.conv2.weight: 147,456\n",
            "  encoder.layer2.2.bn2.weight: 128\n",
            "  encoder.layer2.2.bn2.bias: 128\n",
            "  encoder.layer2.2.conv3.weight: 65,536\n",
            "  encoder.layer2.2.bn3.weight: 512\n",
            "  encoder.layer2.2.bn3.bias: 512\n",
            "  encoder.layer2.3.conv1.weight: 65,536\n",
            "  encoder.layer2.3.bn1.weight: 128\n",
            "  encoder.layer2.3.bn1.bias: 128\n",
            "  encoder.layer2.3.conv2.weight: 147,456\n",
            "  encoder.layer2.3.bn2.weight: 128\n",
            "  encoder.layer2.3.bn2.bias: 128\n",
            "  encoder.layer2.3.conv3.weight: 65,536\n",
            "  encoder.layer2.3.bn3.weight: 512\n",
            "  encoder.layer2.3.bn3.bias: 512\n",
            "  encoder.layer3.0.conv1.weight: 131,072\n",
            "  encoder.layer3.0.bn1.weight: 256\n",
            "  encoder.layer3.0.bn1.bias: 256\n",
            "  encoder.layer3.0.conv2.weight: 589,824\n",
            "  encoder.layer3.0.bn2.weight: 256\n",
            "  encoder.layer3.0.bn2.bias: 256\n",
            "  encoder.layer3.0.conv3.weight: 262,144\n",
            "  encoder.layer3.0.bn3.weight: 1,024\n",
            "  encoder.layer3.0.bn3.bias: 1,024\n",
            "  encoder.layer3.0.downsample.0.weight: 524,288\n",
            "  encoder.layer3.0.downsample.1.weight: 1,024\n",
            "  encoder.layer3.0.downsample.1.bias: 1,024\n",
            "  encoder.layer3.1.conv1.weight: 262,144\n",
            "  encoder.layer3.1.bn1.weight: 256\n",
            "  encoder.layer3.1.bn1.bias: 256\n",
            "  encoder.layer3.1.conv2.weight: 589,824\n",
            "  encoder.layer3.1.bn2.weight: 256\n",
            "  encoder.layer3.1.bn2.bias: 256\n",
            "  encoder.layer3.1.conv3.weight: 262,144\n",
            "  encoder.layer3.1.bn3.weight: 1,024\n",
            "  encoder.layer3.1.bn3.bias: 1,024\n",
            "  encoder.layer3.2.conv1.weight: 262,144\n",
            "  encoder.layer3.2.bn1.weight: 256\n",
            "  encoder.layer3.2.bn1.bias: 256\n",
            "  encoder.layer3.2.conv2.weight: 589,824\n",
            "  encoder.layer3.2.bn2.weight: 256\n",
            "  encoder.layer3.2.bn2.bias: 256\n",
            "  encoder.layer3.2.conv3.weight: 262,144\n",
            "  encoder.layer3.2.bn3.weight: 1,024\n",
            "  encoder.layer3.2.bn3.bias: 1,024\n",
            "  encoder.layer3.3.conv1.weight: 262,144\n",
            "  encoder.layer3.3.bn1.weight: 256\n",
            "  encoder.layer3.3.bn1.bias: 256\n",
            "  encoder.layer3.3.conv2.weight: 589,824\n",
            "  encoder.layer3.3.bn2.weight: 256\n",
            "  encoder.layer3.3.bn2.bias: 256\n",
            "  encoder.layer3.3.conv3.weight: 262,144\n",
            "  encoder.layer3.3.bn3.weight: 1,024\n",
            "  encoder.layer3.3.bn3.bias: 1,024\n",
            "  encoder.layer3.4.conv1.weight: 262,144\n",
            "  encoder.layer3.4.bn1.weight: 256\n",
            "  encoder.layer3.4.bn1.bias: 256\n",
            "  encoder.layer3.4.conv2.weight: 589,824\n",
            "  encoder.layer3.4.bn2.weight: 256\n",
            "  encoder.layer3.4.bn2.bias: 256\n",
            "  encoder.layer3.4.conv3.weight: 262,144\n",
            "  encoder.layer3.4.bn3.weight: 1,024\n",
            "  encoder.layer3.4.bn3.bias: 1,024\n",
            "  encoder.layer3.5.conv1.weight: 262,144\n",
            "  encoder.layer3.5.bn1.weight: 256\n",
            "  encoder.layer3.5.bn1.bias: 256\n",
            "  encoder.layer3.5.conv2.weight: 589,824\n",
            "  encoder.layer3.5.bn2.weight: 256\n",
            "  encoder.layer3.5.bn2.bias: 256\n",
            "  encoder.layer3.5.conv3.weight: 262,144\n",
            "  encoder.layer3.5.bn3.weight: 1,024\n",
            "  encoder.layer3.5.bn3.bias: 1,024\n",
            "  encoder.layer4.0.conv1.weight: 524,288\n",
            "  encoder.layer4.0.bn1.weight: 512\n",
            "  encoder.layer4.0.bn1.bias: 512\n",
            "  encoder.layer4.0.conv2.weight: 2,359,296\n",
            "  encoder.layer4.0.bn2.weight: 512\n",
            "  encoder.layer4.0.bn2.bias: 512\n",
            "  encoder.layer4.0.conv3.weight: 1,048,576\n",
            "  encoder.layer4.0.bn3.weight: 2,048\n",
            "  encoder.layer4.0.bn3.bias: 2,048\n",
            "  encoder.layer4.0.downsample.0.weight: 2,097,152\n",
            "  encoder.layer4.0.downsample.1.weight: 2,048\n",
            "  encoder.layer4.0.downsample.1.bias: 2,048\n",
            "  encoder.layer4.1.conv1.weight: 1,048,576\n",
            "  encoder.layer4.1.bn1.weight: 512\n",
            "  encoder.layer4.1.bn1.bias: 512\n",
            "  encoder.layer4.1.conv2.weight: 2,359,296\n",
            "  encoder.layer4.1.bn2.weight: 512\n",
            "  encoder.layer4.1.bn2.bias: 512\n",
            "  encoder.layer4.1.conv3.weight: 1,048,576\n",
            "  encoder.layer4.1.bn3.weight: 2,048\n",
            "  encoder.layer4.1.bn3.bias: 2,048\n",
            "  encoder.layer4.2.conv1.weight: 1,048,576\n",
            "  encoder.layer4.2.bn1.weight: 512\n",
            "  encoder.layer4.2.bn1.bias: 512\n",
            "  encoder.layer4.2.conv2.weight: 2,359,296\n",
            "  encoder.layer4.2.bn2.weight: 512\n",
            "  encoder.layer4.2.bn2.bias: 512\n",
            "  encoder.layer4.2.conv3.weight: 1,048,576\n",
            "  encoder.layer4.2.bn3.weight: 2,048\n",
            "  encoder.layer4.2.bn3.bias: 2,048\n",
            "  projection_head.mlp.0.weight: 1,048,576\n",
            "  projection_head.mlp.0.bias: 512\n",
            "  projection_head.mlp.2.weight: 262,144\n",
            "  projection_head.mlp.2.bias: 512\n",
            "  projection_head.mlp.4.weight: 131,072\n",
            "  projection_head.mlp.4.bias: 256\n",
            "  projection_head.mlp.6.weight: 65,536\n",
            "  projection_head.mlp.6.bias: 256\n",
            "  projection_head.mlp.9.weight: 8,192\n",
            "  projection_head.mlp.9.bias: 32\n",
            "  classifier.classifier.0.weight: 524,288\n",
            "  classifier.classifier.0.bias: 256\n",
            "  classifier.classifier.2.weight: 65,536\n",
            "  classifier.classifier.2.bias: 256\n",
            "  classifier.classifier.4.weight: 32,768\n",
            "  classifier.classifier.4.bias: 128\n",
            "  classifier.classifier.6.weight: 16,384\n",
            "  classifier.classifier.6.bias: 128\n",
            "  classifier.classifier.8.weight: 8,192\n",
            "  classifier.classifier.8.bias: 64\n",
            "  classifier.classifier.10.weight: 2,048\n",
            "  classifier.classifier.10.bias: 32\n",
            "  classifier.classifier.12.weight: 512\n",
            "  classifier.classifier.12.bias: 16\n",
            "  classifier.classifier.14.weight: 80\n",
            "  classifier.classifier.14.bias: 5\n",
            "================================================================================\n",
            "2025-11-03 09:57:10,273 - supervised_finetuning - INFO - ✓ Encoder frozen - only classifier will be trained\n",
            "Created train DataLoader:\n",
            "  - Batch size: 64\n",
            "  - Shuffle: True\n",
            "  - Workers: 2\n",
            "  - Classes: ['Glioblastoma', 'glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
            "  - Number of samples: 1287\n",
            "==================================================\n",
            "DATASET ANALYSIS\n",
            "==================================================\n",
            "Total samples: 1287\n",
            "Class distribution:\n",
            "  pituitary_tumor: 288 (22.4%)\n",
            "  meningioma_tumor: 330 (25.6%)\n",
            "  no_tumor: 193 (15.0%)\n",
            "  Glioblastoma: 194 (15.1%)\n",
            "  glioma_tumor: 282 (21.9%)\n",
            "2025-11-03 09:57:11,705 - supervised_finetuning - INFO - Training with 1287 labeled images\n",
            "2025-11-03 09:57:11,705 - supervised_finetuning - INFO - === STAGE 1: Extracting Label Features ===\n",
            "Extracting features: 100% 21/21 [00:04<00:00,  5.22it/s]\n",
            "2025-11-03 09:57:15,743 - supervised_finetuning - INFO - ✓ Extracted 1287 label features with shape torch.Size([1287, 2048])\n",
            "2025-11-03 09:57:15,744 - supervised_finetuning - INFO - ✓ Created feature dataset for classifier training\n",
            "2025-11-03 09:57:15,744 - supervised_finetuning - INFO - === STAGE 2: Training Classifier on Label Features ===\n",
            "Classifier Epoch 1/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.6195, Acc=26.56%]2025-11-03 09:57:15,895 - supervised_finetuning - INFO - Epoch 0 - supervised_loss/batch: 1.6195\n",
            "2025-11-03 09:57:15,895 - supervised_finetuning - INFO - Epoch 0 - supervised_accuracy/batch: 26.5625\n",
            "2025-11-03 09:57:15,896 - supervised_finetuning - INFO - Epoch 0 - learning_rate: 0.0001\n",
            "Classifier Epoch 1/100:   5% 1/21 [00:00<00:03,  6.59it/s, Loss=1.5921, Acc=29.69%]2025-11-03 09:57:15,943 - supervised_finetuning - INFO - Epoch 10 - supervised_loss/batch: 1.5921\n",
            "2025-11-03 09:57:15,943 - supervised_finetuning - INFO - Epoch 10 - supervised_accuracy/batch: 29.6875\n",
            "2025-11-03 09:57:15,944 - supervised_finetuning - INFO - Epoch 10 - learning_rate: 0.0001\n",
            "Classifier Epoch 1/100:   5% 1/21 [00:00<00:03,  6.59it/s, Loss=1.6153, Acc=28.57%]2025-11-03 09:57:15,980 - supervised_finetuning - INFO - Epoch 20 - supervised_loss/batch: 1.6153\n",
            "2025-11-03 09:57:15,980 - supervised_finetuning - INFO - Epoch 20 - supervised_accuracy/batch: 28.5714\n",
            "2025-11-03 09:57:15,981 - supervised_finetuning - INFO - Epoch 20 - learning_rate: 0.0001\n",
            "Classifier Epoch 1/100: 100% 21/21 [00:00<00:00, 88.63it/s, Loss=1.6153, Acc=28.57%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:15,996 - supervised_finetuning - INFO - Epoch 1:\n",
            "2025-11-03 09:57:15,996 - supervised_finetuning - INFO -   Train Loss: 1.6224, Train Acc: 21.91%\n",
            "2025-11-03 09:57:15,996 - supervised_finetuning - INFO -   Train F1: 7.88%, Train Recall: 21.91%\n",
            "2025-11-03 09:57:15,996 - supervised_finetuning - INFO -   Train Precision: 4.80%\n",
            "2025-11-03 09:57:15,996 - supervised_finetuning - INFO - Epoch 0 - supervised_loss/epoch: 1.6224\n",
            "2025-11-03 09:57:15,996 - supervised_finetuning - INFO - Epoch 0 - supervised_accuracy/epoch: 21.9114\n",
            "2025-11-03 09:57:15,997 - supervised_finetuning - INFO - Epoch 0 - supervised_f1/epoch: 7.8764\n",
            "2025-11-03 09:57:15,997 - supervised_finetuning - INFO - Epoch 0 - supervised_recall/epoch: 21.9114\n",
            "2025-11-03 09:57:15,997 - supervised_finetuning - INFO - Epoch 0 - supervised_precision/epoch: 4.8011\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:16,384 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 21.91%\n",
            "Classifier Epoch 2/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.6274, Acc=17.19%]2025-11-03 09:57:16,389 - supervised_finetuning - INFO - Epoch 21 - supervised_loss/batch: 1.6274\n",
            "2025-11-03 09:57:16,389 - supervised_finetuning - INFO - Epoch 21 - supervised_accuracy/batch: 17.1875\n",
            "2025-11-03 09:57:16,389 - supervised_finetuning - INFO - Epoch 21 - learning_rate: 0.0001\n",
            "Classifier Epoch 2/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.5624, Acc=26.56%]2025-11-03 09:57:16,425 - supervised_finetuning - INFO - Epoch 31 - supervised_loss/batch: 1.5624\n",
            "2025-11-03 09:57:16,425 - supervised_finetuning - INFO - Epoch 31 - supervised_accuracy/batch: 26.5625\n",
            "2025-11-03 09:57:16,426 - supervised_finetuning - INFO - Epoch 31 - learning_rate: 0.0001\n",
            "Classifier Epoch 2/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.4922, Acc=42.86%]2025-11-03 09:57:16,458 - supervised_finetuning - INFO - Epoch 41 - supervised_loss/batch: 1.4922\n",
            "2025-11-03 09:57:16,459 - supervised_finetuning - INFO - Epoch 41 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:16,459 - supervised_finetuning - INFO - Epoch 41 - learning_rate: 0.0001\n",
            "Classifier Epoch 2/100: 100% 21/21 [00:00<00:00, 280.05it/s, Loss=1.4922, Acc=42.86%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:16,469 - supervised_finetuning - INFO - Epoch 2:\n",
            "2025-11-03 09:57:16,469 - supervised_finetuning - INFO -   Train Loss: 1.6056, Train Acc: 21.91%\n",
            "2025-11-03 09:57:16,469 - supervised_finetuning - INFO -   Train F1: 7.88%, Train Recall: 21.91%\n",
            "2025-11-03 09:57:16,469 - supervised_finetuning - INFO -   Train Precision: 4.80%\n",
            "2025-11-03 09:57:16,469 - supervised_finetuning - INFO - Epoch 1 - supervised_loss/epoch: 1.6056\n",
            "2025-11-03 09:57:16,470 - supervised_finetuning - INFO - Epoch 1 - supervised_accuracy/epoch: 21.9114\n",
            "2025-11-03 09:57:16,470 - supervised_finetuning - INFO - Epoch 1 - supervised_f1/epoch: 7.8764\n",
            "2025-11-03 09:57:16,470 - supervised_finetuning - INFO - Epoch 1 - supervised_recall/epoch: 21.9114\n",
            "2025-11-03 09:57:16,470 - supervised_finetuning - INFO - Epoch 1 - supervised_precision/epoch: 4.8011\n",
            "Classifier Epoch 3/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.6020, Acc=28.12%]2025-11-03 09:57:16,474 - supervised_finetuning - INFO - Epoch 42 - supervised_loss/batch: 1.6020\n",
            "2025-11-03 09:57:16,475 - supervised_finetuning - INFO - Epoch 42 - supervised_accuracy/batch: 28.1250\n",
            "2025-11-03 09:57:16,475 - supervised_finetuning - INFO - Epoch 42 - learning_rate: 0.0001\n",
            "Classifier Epoch 3/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.5918, Acc=26.56%]2025-11-03 09:57:16,511 - supervised_finetuning - INFO - Epoch 52 - supervised_loss/batch: 1.5918\n",
            "2025-11-03 09:57:16,512 - supervised_finetuning - INFO - Epoch 52 - supervised_accuracy/batch: 26.5625\n",
            "2025-11-03 09:57:16,512 - supervised_finetuning - INFO - Epoch 52 - learning_rate: 0.0001\n",
            "Classifier Epoch 3/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.6041, Acc=42.86%]2025-11-03 09:57:16,544 - supervised_finetuning - INFO - Epoch 62 - supervised_loss/batch: 1.6041\n",
            "2025-11-03 09:57:16,545 - supervised_finetuning - INFO - Epoch 62 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:16,545 - supervised_finetuning - INFO - Epoch 62 - learning_rate: 0.0001\n",
            "Classifier Epoch 3/100: 100% 21/21 [00:00<00:00, 282.41it/s, Loss=1.6041, Acc=42.86%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:16,554 - supervised_finetuning - INFO - Epoch 3:\n",
            "2025-11-03 09:57:16,554 - supervised_finetuning - INFO -   Train Loss: 1.5825, Train Acc: 29.84%\n",
            "2025-11-03 09:57:16,555 - supervised_finetuning - INFO -   Train F1: 17.98%, Train Recall: 29.84%\n",
            "2025-11-03 09:57:16,555 - supervised_finetuning - INFO -   Train Precision: 16.69%\n",
            "2025-11-03 09:57:16,555 - supervised_finetuning - INFO - Epoch 2 - supervised_loss/epoch: 1.5825\n",
            "2025-11-03 09:57:16,555 - supervised_finetuning - INFO - Epoch 2 - supervised_accuracy/epoch: 29.8368\n",
            "2025-11-03 09:57:16,555 - supervised_finetuning - INFO - Epoch 2 - supervised_f1/epoch: 17.9806\n",
            "2025-11-03 09:57:16,555 - supervised_finetuning - INFO - Epoch 2 - supervised_recall/epoch: 29.8368\n",
            "2025-11-03 09:57:16,556 - supervised_finetuning - INFO - Epoch 2 - supervised_precision/epoch: 16.6869\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:17,211 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 29.84%\n",
            "Classifier Epoch 4/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.5005, Acc=37.50%]2025-11-03 09:57:17,216 - supervised_finetuning - INFO - Epoch 63 - supervised_loss/batch: 1.5005\n",
            "2025-11-03 09:57:17,217 - supervised_finetuning - INFO - Epoch 63 - supervised_accuracy/batch: 37.5000\n",
            "2025-11-03 09:57:17,217 - supervised_finetuning - INFO - Epoch 63 - learning_rate: 0.0001\n",
            "Classifier Epoch 4/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.5446, Acc=32.81%]2025-11-03 09:57:17,251 - supervised_finetuning - INFO - Epoch 73 - supervised_loss/batch: 1.5446\n",
            "2025-11-03 09:57:17,251 - supervised_finetuning - INFO - Epoch 73 - supervised_accuracy/batch: 32.8125\n",
            "2025-11-03 09:57:17,251 - supervised_finetuning - INFO - Epoch 73 - learning_rate: 0.0001\n",
            "Classifier Epoch 4/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.6401, Acc=14.29%]2025-11-03 09:57:17,284 - supervised_finetuning - INFO - Epoch 83 - supervised_loss/batch: 1.6401\n",
            "2025-11-03 09:57:17,284 - supervised_finetuning - INFO - Epoch 83 - supervised_accuracy/batch: 14.2857\n",
            "2025-11-03 09:57:17,284 - supervised_finetuning - INFO - Epoch 83 - learning_rate: 0.0001\n",
            "Classifier Epoch 4/100: 100% 21/21 [00:00<00:00, 289.89it/s, Loss=1.6401, Acc=14.29%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:17,295 - supervised_finetuning - INFO - Epoch 4:\n",
            "2025-11-03 09:57:17,295 - supervised_finetuning - INFO -   Train Loss: 1.5212, Train Acc: 33.80%\n",
            "2025-11-03 09:57:17,295 - supervised_finetuning - INFO -   Train F1: 26.46%, Train Recall: 33.80%\n",
            "2025-11-03 09:57:17,295 - supervised_finetuning - INFO -   Train Precision: 28.40%\n",
            "2025-11-03 09:57:17,295 - supervised_finetuning - INFO - Epoch 3 - supervised_loss/epoch: 1.5212\n",
            "2025-11-03 09:57:17,295 - supervised_finetuning - INFO - Epoch 3 - supervised_accuracy/epoch: 33.7995\n",
            "2025-11-03 09:57:17,296 - supervised_finetuning - INFO - Epoch 3 - supervised_f1/epoch: 26.4570\n",
            "2025-11-03 09:57:17,296 - supervised_finetuning - INFO - Epoch 3 - supervised_recall/epoch: 33.7995\n",
            "2025-11-03 09:57:17,296 - supervised_finetuning - INFO - Epoch 3 - supervised_precision/epoch: 28.4024\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:17,879 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 33.80%\n",
            "Classifier Epoch 5/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.4757, Acc=29.69%]2025-11-03 09:57:17,884 - supervised_finetuning - INFO - Epoch 84 - supervised_loss/batch: 1.4757\n",
            "2025-11-03 09:57:17,884 - supervised_finetuning - INFO - Epoch 84 - supervised_accuracy/batch: 29.6875\n",
            "2025-11-03 09:57:17,884 - supervised_finetuning - INFO - Epoch 84 - learning_rate: 0.0001\n",
            "Classifier Epoch 5/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.4136, Acc=39.06%]2025-11-03 09:57:17,919 - supervised_finetuning - INFO - Epoch 94 - supervised_loss/batch: 1.4136\n",
            "2025-11-03 09:57:17,919 - supervised_finetuning - INFO - Epoch 94 - supervised_accuracy/batch: 39.0625\n",
            "2025-11-03 09:57:17,919 - supervised_finetuning - INFO - Epoch 94 - learning_rate: 0.0001\n",
            "Classifier Epoch 5/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.4122, Acc=57.14%]2025-11-03 09:57:17,954 - supervised_finetuning - INFO - Epoch 104 - supervised_loss/batch: 1.4122\n",
            "2025-11-03 09:57:17,955 - supervised_finetuning - INFO - Epoch 104 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:17,955 - supervised_finetuning - INFO - Epoch 104 - learning_rate: 0.0001\n",
            "Classifier Epoch 5/100: 100% 21/21 [00:00<00:00, 276.96it/s, Loss=1.4122, Acc=57.14%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:17,965 - supervised_finetuning - INFO - Epoch 5:\n",
            "2025-11-03 09:57:17,965 - supervised_finetuning - INFO -   Train Loss: 1.4175, Train Acc: 38.93%\n",
            "2025-11-03 09:57:17,965 - supervised_finetuning - INFO -   Train F1: 32.75%, Train Recall: 38.93%\n",
            "2025-11-03 09:57:17,966 - supervised_finetuning - INFO -   Train Precision: 37.03%\n",
            "2025-11-03 09:57:17,966 - supervised_finetuning - INFO - Epoch 4 - supervised_loss/epoch: 1.4175\n",
            "2025-11-03 09:57:17,966 - supervised_finetuning - INFO - Epoch 4 - supervised_accuracy/epoch: 38.9277\n",
            "2025-11-03 09:57:17,966 - supervised_finetuning - INFO - Epoch 4 - supervised_f1/epoch: 32.7453\n",
            "2025-11-03 09:57:17,966 - supervised_finetuning - INFO - Epoch 4 - supervised_recall/epoch: 38.9277\n",
            "2025-11-03 09:57:17,966 - supervised_finetuning - INFO - Epoch 4 - supervised_precision/epoch: 37.0324\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:20,470 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 38.93%\n",
            "Classifier Epoch 6/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.2665, Acc=59.38%]2025-11-03 09:57:20,487 - supervised_finetuning - INFO - Epoch 105 - supervised_loss/batch: 1.2665\n",
            "2025-11-03 09:57:20,487 - supervised_finetuning - INFO - Epoch 105 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:20,487 - supervised_finetuning - INFO - Epoch 105 - learning_rate: 0.0001\n",
            "Classifier Epoch 6/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3680, Acc=39.06%]2025-11-03 09:57:20,543 - supervised_finetuning - INFO - Epoch 115 - supervised_loss/batch: 1.3680\n",
            "2025-11-03 09:57:20,544 - supervised_finetuning - INFO - Epoch 115 - supervised_accuracy/batch: 39.0625\n",
            "2025-11-03 09:57:20,544 - supervised_finetuning - INFO - Epoch 115 - learning_rate: 0.0001\n",
            "Classifier Epoch 6/100:  81% 17/21 [00:00<00:00, 165.71it/s, Loss=1.4990, Acc=14.29%]2025-11-03 09:57:20,594 - supervised_finetuning - INFO - Epoch 125 - supervised_loss/batch: 1.4990\n",
            "2025-11-03 09:57:20,595 - supervised_finetuning - INFO - Epoch 125 - supervised_accuracy/batch: 14.2857\n",
            "2025-11-03 09:57:20,595 - supervised_finetuning - INFO - Epoch 125 - learning_rate: 0.0001\n",
            "Classifier Epoch 6/100: 100% 21/21 [00:00<00:00, 170.95it/s, Loss=1.4990, Acc=14.29%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:20,612 - supervised_finetuning - INFO - Epoch 6:\n",
            "2025-11-03 09:57:20,612 - supervised_finetuning - INFO -   Train Loss: 1.3262, Train Acc: 48.33%\n",
            "2025-11-03 09:57:20,612 - supervised_finetuning - INFO -   Train F1: 44.01%, Train Recall: 48.33%\n",
            "2025-11-03 09:57:20,612 - supervised_finetuning - INFO -   Train Precision: 41.44%\n",
            "2025-11-03 09:57:20,612 - supervised_finetuning - INFO - Epoch 5 - supervised_loss/epoch: 1.3262\n",
            "2025-11-03 09:57:20,613 - supervised_finetuning - INFO - Epoch 5 - supervised_accuracy/epoch: 48.3294\n",
            "2025-11-03 09:57:20,613 - supervised_finetuning - INFO - Epoch 5 - supervised_f1/epoch: 44.0145\n",
            "2025-11-03 09:57:20,613 - supervised_finetuning - INFO - Epoch 5 - supervised_recall/epoch: 48.3294\n",
            "2025-11-03 09:57:20,613 - supervised_finetuning - INFO - Epoch 5 - supervised_precision/epoch: 41.4406\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:21,245 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 48.33%\n",
            "Classifier Epoch 7/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.2814, Acc=46.88%]2025-11-03 09:57:21,251 - supervised_finetuning - INFO - Epoch 126 - supervised_loss/batch: 1.2814\n",
            "2025-11-03 09:57:21,251 - supervised_finetuning - INFO - Epoch 126 - supervised_accuracy/batch: 46.8750\n",
            "2025-11-03 09:57:21,251 - supervised_finetuning - INFO - Epoch 126 - learning_rate: 0.0001\n",
            "Classifier Epoch 7/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.2463, Acc=48.44%]2025-11-03 09:57:21,286 - supervised_finetuning - INFO - Epoch 136 - supervised_loss/batch: 1.2463\n",
            "2025-11-03 09:57:21,286 - supervised_finetuning - INFO - Epoch 136 - supervised_accuracy/batch: 48.4375\n",
            "2025-11-03 09:57:21,287 - supervised_finetuning - INFO - Epoch 136 - learning_rate: 0.0001\n",
            "Classifier Epoch 7/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0601, Acc=42.86%]2025-11-03 09:57:21,321 - supervised_finetuning - INFO - Epoch 146 - supervised_loss/batch: 1.0601\n",
            "2025-11-03 09:57:21,321 - supervised_finetuning - INFO - Epoch 146 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:21,321 - supervised_finetuning - INFO - Epoch 146 - learning_rate: 0.0001\n",
            "Classifier Epoch 7/100: 100% 21/21 [00:00<00:00, 277.79it/s, Loss=1.0601, Acc=42.86%]\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "2025-11-03 09:57:21,332 - supervised_finetuning - INFO - Epoch 7:\n",
            "2025-11-03 09:57:21,332 - supervised_finetuning - INFO -   Train Loss: 1.2207, Train Acc: 50.51%\n",
            "2025-11-03 09:57:21,332 - supervised_finetuning - INFO -   Train F1: 45.95%, Train Recall: 50.51%\n",
            "2025-11-03 09:57:21,332 - supervised_finetuning - INFO -   Train Precision: 42.42%\n",
            "2025-11-03 09:57:21,332 - supervised_finetuning - INFO - Epoch 6 - supervised_loss/epoch: 1.2207\n",
            "2025-11-03 09:57:21,332 - supervised_finetuning - INFO - Epoch 6 - supervised_accuracy/epoch: 50.5051\n",
            "2025-11-03 09:57:21,333 - supervised_finetuning - INFO - Epoch 6 - supervised_f1/epoch: 45.9453\n",
            "2025-11-03 09:57:21,333 - supervised_finetuning - INFO - Epoch 6 - supervised_recall/epoch: 50.5051\n",
            "2025-11-03 09:57:21,333 - supervised_finetuning - INFO - Epoch 6 - supervised_precision/epoch: 42.4181\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:22,079 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 50.51%\n",
            "Classifier Epoch 8/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1355, Acc=60.94%]2025-11-03 09:57:22,086 - supervised_finetuning - INFO - Epoch 147 - supervised_loss/batch: 1.1355\n",
            "2025-11-03 09:57:22,086 - supervised_finetuning - INFO - Epoch 147 - supervised_accuracy/batch: 60.9375\n",
            "2025-11-03 09:57:22,086 - supervised_finetuning - INFO - Epoch 147 - learning_rate: 0.0001\n",
            "Classifier Epoch 8/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0730, Acc=62.50%]2025-11-03 09:57:22,131 - supervised_finetuning - INFO - Epoch 157 - supervised_loss/batch: 1.0730\n",
            "2025-11-03 09:57:22,131 - supervised_finetuning - INFO - Epoch 157 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:22,131 - supervised_finetuning - INFO - Epoch 157 - learning_rate: 0.0001\n",
            "Classifier Epoch 8/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9218, Acc=71.43%]2025-11-03 09:57:22,169 - supervised_finetuning - INFO - Epoch 167 - supervised_loss/batch: 0.9218\n",
            "2025-11-03 09:57:22,169 - supervised_finetuning - INFO - Epoch 167 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:22,169 - supervised_finetuning - INFO - Epoch 167 - learning_rate: 0.0001\n",
            "Classifier Epoch 8/100: 100% 21/21 [00:00<00:00, 233.46it/s, Loss=0.9218, Acc=71.43%]\n",
            "2025-11-03 09:57:22,183 - supervised_finetuning - INFO - Epoch 8:\n",
            "2025-11-03 09:57:22,183 - supervised_finetuning - INFO -   Train Loss: 1.1781, Train Acc: 52.06%\n",
            "2025-11-03 09:57:22,183 - supervised_finetuning - INFO -   Train F1: 47.39%, Train Recall: 52.06%\n",
            "2025-11-03 09:57:22,183 - supervised_finetuning - INFO -   Train Precision: 58.48%\n",
            "2025-11-03 09:57:22,184 - supervised_finetuning - INFO - Epoch 7 - supervised_loss/epoch: 1.1781\n",
            "2025-11-03 09:57:22,184 - supervised_finetuning - INFO - Epoch 7 - supervised_accuracy/epoch: 52.0591\n",
            "2025-11-03 09:57:22,184 - supervised_finetuning - INFO - Epoch 7 - supervised_f1/epoch: 47.3940\n",
            "2025-11-03 09:57:22,184 - supervised_finetuning - INFO - Epoch 7 - supervised_recall/epoch: 52.0591\n",
            "2025-11-03 09:57:22,184 - supervised_finetuning - INFO - Epoch 7 - supervised_precision/epoch: 58.4807\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:22,912 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 52.06%\n",
            "Classifier Epoch 9/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1736, Acc=51.56%]2025-11-03 09:57:22,917 - supervised_finetuning - INFO - Epoch 168 - supervised_loss/batch: 1.1736\n",
            "2025-11-03 09:57:22,918 - supervised_finetuning - INFO - Epoch 168 - supervised_accuracy/batch: 51.5625\n",
            "2025-11-03 09:57:22,918 - supervised_finetuning - INFO - Epoch 168 - learning_rate: 0.0001\n",
            "Classifier Epoch 9/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3165, Acc=46.88%]2025-11-03 09:57:22,953 - supervised_finetuning - INFO - Epoch 178 - supervised_loss/batch: 1.3165\n",
            "2025-11-03 09:57:22,953 - supervised_finetuning - INFO - Epoch 178 - supervised_accuracy/batch: 46.8750\n",
            "2025-11-03 09:57:22,954 - supervised_finetuning - INFO - Epoch 178 - learning_rate: 0.0001\n",
            "Classifier Epoch 9/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1660, Acc=57.14%]2025-11-03 09:57:22,989 - supervised_finetuning - INFO - Epoch 188 - supervised_loss/batch: 1.1660\n",
            "2025-11-03 09:57:22,989 - supervised_finetuning - INFO - Epoch 188 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:22,990 - supervised_finetuning - INFO - Epoch 188 - learning_rate: 0.0001\n",
            "Classifier Epoch 9/100: 100% 21/21 [00:00<00:00, 272.63it/s, Loss=1.1660, Acc=57.14%]\n",
            "2025-11-03 09:57:23,000 - supervised_finetuning - INFO - Epoch 9:\n",
            "2025-11-03 09:57:23,000 - supervised_finetuning - INFO -   Train Loss: 1.1431, Train Acc: 53.54%\n",
            "2025-11-03 09:57:23,000 - supervised_finetuning - INFO -   Train F1: 49.43%, Train Recall: 53.54%\n",
            "2025-11-03 09:57:23,000 - supervised_finetuning - INFO -   Train Precision: 58.44%\n",
            "2025-11-03 09:57:23,000 - supervised_finetuning - INFO - Epoch 8 - supervised_loss/epoch: 1.1431\n",
            "2025-11-03 09:57:23,000 - supervised_finetuning - INFO - Epoch 8 - supervised_accuracy/epoch: 53.5354\n",
            "2025-11-03 09:57:23,001 - supervised_finetuning - INFO - Epoch 8 - supervised_f1/epoch: 49.4309\n",
            "2025-11-03 09:57:23,001 - supervised_finetuning - INFO - Epoch 8 - supervised_recall/epoch: 53.5354\n",
            "2025-11-03 09:57:23,001 - supervised_finetuning - INFO - Epoch 8 - supervised_precision/epoch: 58.4424\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:23,781 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 53.54%\n",
            "Classifier Epoch 10/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0670, Acc=54.69%]2025-11-03 09:57:23,787 - supervised_finetuning - INFO - Epoch 189 - supervised_loss/batch: 1.0670\n",
            "2025-11-03 09:57:23,787 - supervised_finetuning - INFO - Epoch 189 - supervised_accuracy/batch: 54.6875\n",
            "2025-11-03 09:57:23,787 - supervised_finetuning - INFO - Epoch 189 - learning_rate: 0.0001\n",
            "Classifier Epoch 10/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1249, Acc=53.12%]2025-11-03 09:57:23,826 - supervised_finetuning - INFO - Epoch 199 - supervised_loss/batch: 1.1249\n",
            "2025-11-03 09:57:23,826 - supervised_finetuning - INFO - Epoch 199 - supervised_accuracy/batch: 53.1250\n",
            "2025-11-03 09:57:23,827 - supervised_finetuning - INFO - Epoch 199 - learning_rate: 0.0001\n",
            "Classifier Epoch 10/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7619, Acc=71.43%]2025-11-03 09:57:23,862 - supervised_finetuning - INFO - Epoch 209 - supervised_loss/batch: 0.7619\n",
            "2025-11-03 09:57:23,862 - supervised_finetuning - INFO - Epoch 209 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:23,863 - supervised_finetuning - INFO - Epoch 209 - learning_rate: 0.0001\n",
            "Classifier Epoch 10/100: 100% 21/21 [00:00<00:00, 258.45it/s, Loss=0.7619, Acc=71.43%]\n",
            "2025-11-03 09:57:23,872 - supervised_finetuning - INFO - Epoch 10:\n",
            "2025-11-03 09:57:23,873 - supervised_finetuning - INFO -   Train Loss: 1.1002, Train Acc: 56.88%\n",
            "2025-11-03 09:57:23,873 - supervised_finetuning - INFO -   Train F1: 55.76%, Train Recall: 56.88%\n",
            "2025-11-03 09:57:23,873 - supervised_finetuning - INFO -   Train Precision: 55.85%\n",
            "2025-11-03 09:57:23,873 - supervised_finetuning - INFO - Epoch 9 - supervised_loss/epoch: 1.1002\n",
            "2025-11-03 09:57:23,873 - supervised_finetuning - INFO - Epoch 9 - supervised_accuracy/epoch: 56.8765\n",
            "2025-11-03 09:57:23,873 - supervised_finetuning - INFO - Epoch 9 - supervised_f1/epoch: 55.7620\n",
            "2025-11-03 09:57:23,874 - supervised_finetuning - INFO - Epoch 9 - supervised_recall/epoch: 56.8765\n",
            "2025-11-03 09:57:23,874 - supervised_finetuning - INFO - Epoch 9 - supervised_precision/epoch: 55.8499\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:24,609 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 56.88%\n",
            "Classifier Epoch 11/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1175, Acc=60.94%]2025-11-03 09:57:24,615 - supervised_finetuning - INFO - Epoch 210 - supervised_loss/batch: 1.1175\n",
            "2025-11-03 09:57:24,615 - supervised_finetuning - INFO - Epoch 210 - supervised_accuracy/batch: 60.9375\n",
            "2025-11-03 09:57:24,616 - supervised_finetuning - INFO - Epoch 210 - learning_rate: 0.0001\n",
            "Classifier Epoch 11/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0139, Acc=62.50%]2025-11-03 09:57:24,656 - supervised_finetuning - INFO - Epoch 220 - supervised_loss/batch: 1.0139\n",
            "2025-11-03 09:57:24,656 - supervised_finetuning - INFO - Epoch 220 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:24,657 - supervised_finetuning - INFO - Epoch 220 - learning_rate: 0.0001\n",
            "Classifier Epoch 11/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3647, Acc=42.86%]2025-11-03 09:57:24,693 - supervised_finetuning - INFO - Epoch 230 - supervised_loss/batch: 1.3647\n",
            "2025-11-03 09:57:24,693 - supervised_finetuning - INFO - Epoch 230 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:24,693 - supervised_finetuning - INFO - Epoch 230 - learning_rate: 0.0001\n",
            "Classifier Epoch 11/100: 100% 21/21 [00:00<00:00, 250.56it/s, Loss=1.3647, Acc=42.86%]\n",
            "2025-11-03 09:57:24,703 - supervised_finetuning - INFO - Epoch 11:\n",
            "2025-11-03 09:57:24,703 - supervised_finetuning - INFO -   Train Loss: 1.0948, Train Acc: 58.28%\n",
            "2025-11-03 09:57:24,703 - supervised_finetuning - INFO -   Train F1: 56.42%, Train Recall: 58.28%\n",
            "2025-11-03 09:57:24,703 - supervised_finetuning - INFO -   Train Precision: 58.77%\n",
            "2025-11-03 09:57:24,704 - supervised_finetuning - INFO - Epoch 10 - supervised_loss/epoch: 1.0948\n",
            "2025-11-03 09:57:24,704 - supervised_finetuning - INFO - Epoch 10 - supervised_accuracy/epoch: 58.2751\n",
            "2025-11-03 09:57:24,704 - supervised_finetuning - INFO - Epoch 10 - supervised_f1/epoch: 56.4180\n",
            "2025-11-03 09:57:24,704 - supervised_finetuning - INFO - Epoch 10 - supervised_recall/epoch: 58.2751\n",
            "2025-11-03 09:57:24,704 - supervised_finetuning - INFO - Epoch 10 - supervised_precision/epoch: 58.7732\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:25,436 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 58.28%\n",
            "Classifier Epoch 12/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0512, Acc=59.38%]2025-11-03 09:57:25,441 - supervised_finetuning - INFO - Epoch 231 - supervised_loss/batch: 1.0512\n",
            "2025-11-03 09:57:25,442 - supervised_finetuning - INFO - Epoch 231 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:25,442 - supervised_finetuning - INFO - Epoch 231 - learning_rate: 0.0001\n",
            "Classifier Epoch 12/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1072, Acc=50.00%]2025-11-03 09:57:25,480 - supervised_finetuning - INFO - Epoch 241 - supervised_loss/batch: 1.1072\n",
            "2025-11-03 09:57:25,480 - supervised_finetuning - INFO - Epoch 241 - supervised_accuracy/batch: 50.0000\n",
            "2025-11-03 09:57:25,480 - supervised_finetuning - INFO - Epoch 241 - learning_rate: 0.0001\n",
            "Classifier Epoch 12/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8044, Acc=71.43%]2025-11-03 09:57:25,516 - supervised_finetuning - INFO - Epoch 251 - supervised_loss/batch: 0.8044\n",
            "2025-11-03 09:57:25,516 - supervised_finetuning - INFO - Epoch 251 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:25,517 - supervised_finetuning - INFO - Epoch 251 - learning_rate: 0.0001\n",
            "Classifier Epoch 12/100: 100% 21/21 [00:00<00:00, 261.53it/s, Loss=0.8044, Acc=71.43%]\n",
            "2025-11-03 09:57:25,527 - supervised_finetuning - INFO - Epoch 12:\n",
            "2025-11-03 09:57:25,527 - supervised_finetuning - INFO -   Train Loss: 1.0547, Train Acc: 58.51%\n",
            "2025-11-03 09:57:25,527 - supervised_finetuning - INFO -   Train F1: 57.37%, Train Recall: 58.51%\n",
            "2025-11-03 09:57:25,527 - supervised_finetuning - INFO -   Train Precision: 57.62%\n",
            "2025-11-03 09:57:25,527 - supervised_finetuning - INFO - Epoch 11 - supervised_loss/epoch: 1.0547\n",
            "2025-11-03 09:57:25,527 - supervised_finetuning - INFO - Epoch 11 - supervised_accuracy/epoch: 58.5082\n",
            "2025-11-03 09:57:25,528 - supervised_finetuning - INFO - Epoch 11 - supervised_f1/epoch: 57.3653\n",
            "2025-11-03 09:57:25,528 - supervised_finetuning - INFO - Epoch 11 - supervised_recall/epoch: 58.5082\n",
            "2025-11-03 09:57:25,528 - supervised_finetuning - INFO - Epoch 11 - supervised_precision/epoch: 57.6170\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:26,303 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 58.51%\n",
            "Classifier Epoch 13/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9662, Acc=57.81%]2025-11-03 09:57:26,309 - supervised_finetuning - INFO - Epoch 252 - supervised_loss/batch: 0.9662\n",
            "2025-11-03 09:57:26,309 - supervised_finetuning - INFO - Epoch 252 - supervised_accuracy/batch: 57.8125\n",
            "2025-11-03 09:57:26,310 - supervised_finetuning - INFO - Epoch 252 - learning_rate: 0.0001\n",
            "Classifier Epoch 13/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1849, Acc=54.69%]2025-11-03 09:57:26,354 - supervised_finetuning - INFO - Epoch 262 - supervised_loss/batch: 1.1849\n",
            "2025-11-03 09:57:26,354 - supervised_finetuning - INFO - Epoch 262 - supervised_accuracy/batch: 54.6875\n",
            "2025-11-03 09:57:26,354 - supervised_finetuning - INFO - Epoch 262 - learning_rate: 0.0001\n",
            "Classifier Epoch 13/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7283, Acc=85.71%]2025-11-03 09:57:26,389 - supervised_finetuning - INFO - Epoch 272 - supervised_loss/batch: 0.7283\n",
            "2025-11-03 09:57:26,389 - supervised_finetuning - INFO - Epoch 272 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:26,389 - supervised_finetuning - INFO - Epoch 272 - learning_rate: 0.0001\n",
            "Classifier Epoch 13/100: 100% 21/21 [00:00<00:00, 244.47it/s, Loss=0.7283, Acc=85.71%]\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO - Epoch 13:\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO -   Train Loss: 1.0368, Train Acc: 58.90%\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO -   Train F1: 57.68%, Train Recall: 58.90%\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO -   Train Precision: 58.37%\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO - Epoch 12 - supervised_loss/epoch: 1.0368\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO - Epoch 12 - supervised_accuracy/epoch: 58.8967\n",
            "2025-11-03 09:57:26,400 - supervised_finetuning - INFO - Epoch 12 - supervised_f1/epoch: 57.6826\n",
            "2025-11-03 09:57:26,401 - supervised_finetuning - INFO - Epoch 12 - supervised_recall/epoch: 58.8967\n",
            "2025-11-03 09:57:26,401 - supervised_finetuning - INFO - Epoch 12 - supervised_precision/epoch: 58.3743\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:27,125 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 58.90%\n",
            "Classifier Epoch 14/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9724, Acc=68.75%]2025-11-03 09:57:27,131 - supervised_finetuning - INFO - Epoch 273 - supervised_loss/batch: 0.9724\n",
            "2025-11-03 09:57:27,131 - supervised_finetuning - INFO - Epoch 273 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:27,131 - supervised_finetuning - INFO - Epoch 273 - learning_rate: 0.0001\n",
            "Classifier Epoch 14/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0993, Acc=48.44%]2025-11-03 09:57:27,176 - supervised_finetuning - INFO - Epoch 283 - supervised_loss/batch: 1.0993\n",
            "2025-11-03 09:57:27,176 - supervised_finetuning - INFO - Epoch 283 - supervised_accuracy/batch: 48.4375\n",
            "2025-11-03 09:57:27,176 - supervised_finetuning - INFO - Epoch 283 - learning_rate: 0.0001\n",
            "Classifier Epoch 14/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0566, Acc=57.14%]2025-11-03 09:57:27,213 - supervised_finetuning - INFO - Epoch 293 - supervised_loss/batch: 1.0566\n",
            "2025-11-03 09:57:27,213 - supervised_finetuning - INFO - Epoch 293 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:27,214 - supervised_finetuning - INFO - Epoch 293 - learning_rate: 0.0001\n",
            "Classifier Epoch 14/100: 100% 21/21 [00:00<00:00, 238.54it/s, Loss=1.0566, Acc=57.14%]\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO - Epoch 14:\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO -   Train Loss: 1.0501, Train Acc: 58.04%\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO -   Train F1: 57.41%, Train Recall: 58.04%\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO -   Train Precision: 57.32%\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO - Epoch 13 - supervised_loss/epoch: 1.0501\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO - Epoch 13 - supervised_accuracy/epoch: 58.0420\n",
            "2025-11-03 09:57:27,226 - supervised_finetuning - INFO - Epoch 13 - supervised_f1/epoch: 57.4119\n",
            "2025-11-03 09:57:27,227 - supervised_finetuning - INFO - Epoch 13 - supervised_recall/epoch: 58.0420\n",
            "2025-11-03 09:57:27,227 - supervised_finetuning - INFO - Epoch 13 - supervised_precision/epoch: 57.3161\n",
            "Classifier Epoch 15/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0946, Acc=59.38%]2025-11-03 09:57:27,232 - supervised_finetuning - INFO - Epoch 294 - supervised_loss/batch: 1.0946\n",
            "2025-11-03 09:57:27,232 - supervised_finetuning - INFO - Epoch 294 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:27,232 - supervised_finetuning - INFO - Epoch 294 - learning_rate: 0.0001\n",
            "Classifier Epoch 15/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8801, Acc=70.31%]2025-11-03 09:57:27,278 - supervised_finetuning - INFO - Epoch 304 - supervised_loss/batch: 0.8801\n",
            "2025-11-03 09:57:27,278 - supervised_finetuning - INFO - Epoch 304 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:27,279 - supervised_finetuning - INFO - Epoch 304 - learning_rate: 0.0001\n",
            "Classifier Epoch 15/100:  90% 19/21 [00:00<00:00, 158.71it/s, Loss=0.7333, Acc=85.71%]2025-11-03 09:57:27,376 - supervised_finetuning - INFO - Epoch 314 - supervised_loss/batch: 0.7333\n",
            "2025-11-03 09:57:27,376 - supervised_finetuning - INFO - Epoch 314 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:27,377 - supervised_finetuning - INFO - Epoch 314 - learning_rate: 0.0001\n",
            "Classifier Epoch 15/100: 100% 21/21 [00:00<00:00, 140.45it/s, Loss=0.7333, Acc=85.71%]\n",
            "2025-11-03 09:57:27,409 - supervised_finetuning - INFO - Epoch 15:\n",
            "2025-11-03 09:57:27,409 - supervised_finetuning - INFO -   Train Loss: 1.0126, Train Acc: 59.67%\n",
            "2025-11-03 09:57:27,409 - supervised_finetuning - INFO -   Train F1: 58.61%, Train Recall: 59.67%\n",
            "2025-11-03 09:57:27,409 - supervised_finetuning - INFO -   Train Precision: 59.37%\n",
            "2025-11-03 09:57:27,410 - supervised_finetuning - INFO - Epoch 14 - supervised_loss/epoch: 1.0126\n",
            "2025-11-03 09:57:27,410 - supervised_finetuning - INFO - Epoch 14 - supervised_accuracy/epoch: 59.6737\n",
            "2025-11-03 09:57:27,410 - supervised_finetuning - INFO - Epoch 14 - supervised_f1/epoch: 58.6090\n",
            "2025-11-03 09:57:27,410 - supervised_finetuning - INFO - Epoch 14 - supervised_recall/epoch: 59.6737\n",
            "2025-11-03 09:57:27,410 - supervised_finetuning - INFO - Epoch 14 - supervised_precision/epoch: 59.3734\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:27,990 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 59.67%\n",
            "Classifier Epoch 16/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.2328, Acc=54.69%]2025-11-03 09:57:27,996 - supervised_finetuning - INFO - Epoch 315 - supervised_loss/batch: 1.2328\n",
            "2025-11-03 09:57:27,996 - supervised_finetuning - INFO - Epoch 315 - supervised_accuracy/batch: 54.6875\n",
            "2025-11-03 09:57:27,997 - supervised_finetuning - INFO - Epoch 315 - learning_rate: 0.0001\n",
            "Classifier Epoch 16/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9670, Acc=59.38%]2025-11-03 09:57:28,038 - supervised_finetuning - INFO - Epoch 325 - supervised_loss/batch: 0.9670\n",
            "2025-11-03 09:57:28,038 - supervised_finetuning - INFO - Epoch 325 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:28,038 - supervised_finetuning - INFO - Epoch 325 - learning_rate: 0.0001\n",
            "Classifier Epoch 16/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3885, Acc=42.86%]2025-11-03 09:57:28,076 - supervised_finetuning - INFO - Epoch 335 - supervised_loss/batch: 1.3885\n",
            "2025-11-03 09:57:28,076 - supervised_finetuning - INFO - Epoch 335 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:28,076 - supervised_finetuning - INFO - Epoch 335 - learning_rate: 0.0001\n",
            "Classifier Epoch 16/100: 100% 21/21 [00:00<00:00, 245.16it/s, Loss=1.3885, Acc=42.86%]\n",
            "2025-11-03 09:57:28,086 - supervised_finetuning - INFO - Epoch 16:\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO -   Train Loss: 1.0253, Train Acc: 60.61%\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO -   Train F1: 59.81%, Train Recall: 60.61%\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO -   Train Precision: 60.37%\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO - Epoch 15 - supervised_loss/epoch: 1.0253\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO - Epoch 15 - supervised_accuracy/epoch: 60.6061\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO - Epoch 15 - supervised_f1/epoch: 59.8129\n",
            "2025-11-03 09:57:28,087 - supervised_finetuning - INFO - Epoch 15 - supervised_recall/epoch: 60.6061\n",
            "2025-11-03 09:57:28,088 - supervised_finetuning - INFO - Epoch 15 - supervised_precision/epoch: 60.3664\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:28,828 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 60.61%\n",
            "Classifier Epoch 17/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0072, Acc=59.38%]2025-11-03 09:57:28,833 - supervised_finetuning - INFO - Epoch 336 - supervised_loss/batch: 1.0072\n",
            "2025-11-03 09:57:28,833 - supervised_finetuning - INFO - Epoch 336 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:28,833 - supervised_finetuning - INFO - Epoch 336 - learning_rate: 0.0001\n",
            "Classifier Epoch 17/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0338, Acc=60.94%]2025-11-03 09:57:28,870 - supervised_finetuning - INFO - Epoch 346 - supervised_loss/batch: 1.0338\n",
            "2025-11-03 09:57:28,870 - supervised_finetuning - INFO - Epoch 346 - supervised_accuracy/batch: 60.9375\n",
            "2025-11-03 09:57:28,870 - supervised_finetuning - INFO - Epoch 346 - learning_rate: 0.0001\n",
            "Classifier Epoch 17/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0884, Acc=42.86%]2025-11-03 09:57:28,905 - supervised_finetuning - INFO - Epoch 356 - supervised_loss/batch: 1.0884\n",
            "2025-11-03 09:57:28,905 - supervised_finetuning - INFO - Epoch 356 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:28,905 - supervised_finetuning - INFO - Epoch 356 - learning_rate: 0.0001\n",
            "Classifier Epoch 17/100: 100% 21/21 [00:00<00:00, 271.61it/s, Loss=1.0884, Acc=42.86%]\n",
            "2025-11-03 09:57:28,916 - supervised_finetuning - INFO - Epoch 17:\n",
            "2025-11-03 09:57:28,916 - supervised_finetuning - INFO -   Train Loss: 0.9935, Train Acc: 61.85%\n",
            "2025-11-03 09:57:28,916 - supervised_finetuning - INFO -   Train F1: 61.03%, Train Recall: 61.85%\n",
            "2025-11-03 09:57:28,916 - supervised_finetuning - INFO -   Train Precision: 61.79%\n",
            "2025-11-03 09:57:28,916 - supervised_finetuning - INFO - Epoch 16 - supervised_loss/epoch: 0.9935\n",
            "2025-11-03 09:57:28,916 - supervised_finetuning - INFO - Epoch 16 - supervised_accuracy/epoch: 61.8493\n",
            "2025-11-03 09:57:28,917 - supervised_finetuning - INFO - Epoch 16 - supervised_f1/epoch: 61.0302\n",
            "2025-11-03 09:57:28,917 - supervised_finetuning - INFO - Epoch 16 - supervised_recall/epoch: 61.8493\n",
            "2025-11-03 09:57:28,917 - supervised_finetuning - INFO - Epoch 16 - supervised_precision/epoch: 61.7886\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:29,669 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 61.85%\n",
            "Classifier Epoch 18/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9751, Acc=64.06%]2025-11-03 09:57:29,674 - supervised_finetuning - INFO - Epoch 357 - supervised_loss/batch: 0.9751\n",
            "2025-11-03 09:57:29,674 - supervised_finetuning - INFO - Epoch 357 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:29,675 - supervised_finetuning - INFO - Epoch 357 - learning_rate: 0.0001\n",
            "Classifier Epoch 18/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0003, Acc=59.38%]2025-11-03 09:57:29,713 - supervised_finetuning - INFO - Epoch 367 - supervised_loss/batch: 1.0003\n",
            "2025-11-03 09:57:29,713 - supervised_finetuning - INFO - Epoch 367 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:29,714 - supervised_finetuning - INFO - Epoch 367 - learning_rate: 0.0001\n",
            "Classifier Epoch 18/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0560, Acc=42.86%]2025-11-03 09:57:29,749 - supervised_finetuning - INFO - Epoch 377 - supervised_loss/batch: 1.0560\n",
            "2025-11-03 09:57:29,750 - supervised_finetuning - INFO - Epoch 377 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:29,750 - supervised_finetuning - INFO - Epoch 377 - learning_rate: 0.0001\n",
            "Classifier Epoch 18/100: 100% 21/21 [00:00<00:00, 260.33it/s, Loss=1.0560, Acc=42.86%]\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO - Epoch 18:\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO -   Train Loss: 0.9893, Train Acc: 61.85%\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO -   Train F1: 61.03%, Train Recall: 61.85%\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO -   Train Precision: 61.68%\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO - Epoch 17 - supervised_loss/epoch: 0.9893\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO - Epoch 17 - supervised_accuracy/epoch: 61.8493\n",
            "2025-11-03 09:57:29,760 - supervised_finetuning - INFO - Epoch 17 - supervised_f1/epoch: 61.0317\n",
            "2025-11-03 09:57:29,761 - supervised_finetuning - INFO - Epoch 17 - supervised_recall/epoch: 61.8493\n",
            "2025-11-03 09:57:29,761 - supervised_finetuning - INFO - Epoch 17 - supervised_precision/epoch: 61.6783\n",
            "Classifier Epoch 19/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0702, Acc=60.94%]2025-11-03 09:57:29,765 - supervised_finetuning - INFO - Epoch 378 - supervised_loss/batch: 1.0702\n",
            "2025-11-03 09:57:29,766 - supervised_finetuning - INFO - Epoch 378 - supervised_accuracy/batch: 60.9375\n",
            "2025-11-03 09:57:29,766 - supervised_finetuning - INFO - Epoch 378 - learning_rate: 0.0001\n",
            "Classifier Epoch 19/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8479, Acc=67.19%]2025-11-03 09:57:29,812 - supervised_finetuning - INFO - Epoch 388 - supervised_loss/batch: 0.8479\n",
            "2025-11-03 09:57:29,812 - supervised_finetuning - INFO - Epoch 388 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:29,813 - supervised_finetuning - INFO - Epoch 388 - learning_rate: 0.0001\n",
            "Classifier Epoch 19/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7755, Acc=71.43%]2025-11-03 09:57:29,847 - supervised_finetuning - INFO - Epoch 398 - supervised_loss/batch: 0.7755\n",
            "2025-11-03 09:57:29,847 - supervised_finetuning - INFO - Epoch 398 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:29,848 - supervised_finetuning - INFO - Epoch 398 - learning_rate: 0.0001\n",
            "Classifier Epoch 19/100: 100% 21/21 [00:00<00:00, 242.46it/s, Loss=0.7755, Acc=71.43%]\n",
            "2025-11-03 09:57:29,857 - supervised_finetuning - INFO - Epoch 19:\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO -   Train Loss: 0.9630, Train Acc: 62.55%\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO -   Train F1: 61.73%, Train Recall: 62.55%\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO -   Train Precision: 62.02%\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO - Epoch 18 - supervised_loss/epoch: 0.9630\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO - Epoch 18 - supervised_accuracy/epoch: 62.5486\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO - Epoch 18 - supervised_f1/epoch: 61.7253\n",
            "2025-11-03 09:57:29,858 - supervised_finetuning - INFO - Epoch 18 - supervised_recall/epoch: 62.5486\n",
            "2025-11-03 09:57:29,859 - supervised_finetuning - INFO - Epoch 18 - supervised_precision/epoch: 62.0191\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:30,506 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 62.55%\n",
            "Classifier Epoch 20/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9327, Acc=65.62%]2025-11-03 09:57:30,512 - supervised_finetuning - INFO - Epoch 399 - supervised_loss/batch: 0.9327\n",
            "2025-11-03 09:57:30,512 - supervised_finetuning - INFO - Epoch 399 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:30,512 - supervised_finetuning - INFO - Epoch 399 - learning_rate: 0.0001\n",
            "Classifier Epoch 20/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8501, Acc=65.62%]2025-11-03 09:57:30,552 - supervised_finetuning - INFO - Epoch 409 - supervised_loss/batch: 0.8501\n",
            "2025-11-03 09:57:30,552 - supervised_finetuning - INFO - Epoch 409 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:30,552 - supervised_finetuning - INFO - Epoch 409 - learning_rate: 0.0001\n",
            "Classifier Epoch 20/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7446, Acc=71.43%]2025-11-03 09:57:30,587 - supervised_finetuning - INFO - Epoch 419 - supervised_loss/batch: 0.7446\n",
            "2025-11-03 09:57:30,588 - supervised_finetuning - INFO - Epoch 419 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:30,588 - supervised_finetuning - INFO - Epoch 419 - learning_rate: 0.0001\n",
            "Classifier Epoch 20/100: 100% 21/21 [00:00<00:00, 258.66it/s, Loss=0.7446, Acc=71.43%]\n",
            "2025-11-03 09:57:30,598 - supervised_finetuning - INFO - Epoch 20:\n",
            "2025-11-03 09:57:30,599 - supervised_finetuning - INFO -   Train Loss: 0.9437, Train Acc: 63.95%\n",
            "2025-11-03 09:57:30,599 - supervised_finetuning - INFO -   Train F1: 63.07%, Train Recall: 63.95%\n",
            "2025-11-03 09:57:30,599 - supervised_finetuning - INFO -   Train Precision: 64.78%\n",
            "2025-11-03 09:57:30,599 - supervised_finetuning - INFO - Epoch 19 - supervised_loss/epoch: 0.9437\n",
            "2025-11-03 09:57:30,599 - supervised_finetuning - INFO - Epoch 19 - supervised_accuracy/epoch: 63.9472\n",
            "2025-11-03 09:57:30,600 - supervised_finetuning - INFO - Epoch 19 - supervised_f1/epoch: 63.0698\n",
            "2025-11-03 09:57:30,600 - supervised_finetuning - INFO - Epoch 19 - supervised_recall/epoch: 63.9472\n",
            "2025-11-03 09:57:30,600 - supervised_finetuning - INFO - Epoch 19 - supervised_precision/epoch: 64.7776\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:31,335 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 63.95%\n",
            "Classifier Epoch 21/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9153, Acc=68.75%]2025-11-03 09:57:31,342 - supervised_finetuning - INFO - Epoch 420 - supervised_loss/batch: 0.9153\n",
            "2025-11-03 09:57:31,342 - supervised_finetuning - INFO - Epoch 420 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:31,342 - supervised_finetuning - INFO - Epoch 420 - learning_rate: 0.0001\n",
            "Classifier Epoch 21/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8754, Acc=62.50%]2025-11-03 09:57:31,386 - supervised_finetuning - INFO - Epoch 430 - supervised_loss/batch: 0.8754\n",
            "2025-11-03 09:57:31,386 - supervised_finetuning - INFO - Epoch 430 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:31,386 - supervised_finetuning - INFO - Epoch 430 - learning_rate: 0.0001\n",
            "Classifier Epoch 21/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4736, Acc=85.71%]2025-11-03 09:57:31,439 - supervised_finetuning - INFO - Epoch 440 - supervised_loss/batch: 0.4736\n",
            "2025-11-03 09:57:31,440 - supervised_finetuning - INFO - Epoch 440 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:31,440 - supervised_finetuning - INFO - Epoch 440 - learning_rate: 0.0001\n",
            "Classifier Epoch 21/100: 100% 21/21 [00:00<00:00, 202.14it/s, Loss=0.4736, Acc=85.71%]\n",
            "2025-11-03 09:57:31,459 - supervised_finetuning - INFO - Epoch 21:\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO -   Train Loss: 0.9117, Train Acc: 64.72%\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO -   Train F1: 64.09%, Train Recall: 64.72%\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO -   Train Precision: 64.89%\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO - Epoch 20 - supervised_loss/epoch: 0.9117\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO - Epoch 20 - supervised_accuracy/epoch: 64.7242\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO - Epoch 20 - supervised_f1/epoch: 64.0948\n",
            "2025-11-03 09:57:31,460 - supervised_finetuning - INFO - Epoch 20 - supervised_recall/epoch: 64.7242\n",
            "2025-11-03 09:57:31,461 - supervised_finetuning - INFO - Epoch 20 - supervised_precision/epoch: 64.8865\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:32,179 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 64.72%\n",
            "Classifier Epoch 22/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9056, Acc=65.62%]2025-11-03 09:57:32,187 - supervised_finetuning - INFO - Epoch 441 - supervised_loss/batch: 0.9056\n",
            "2025-11-03 09:57:32,188 - supervised_finetuning - INFO - Epoch 441 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:32,188 - supervised_finetuning - INFO - Epoch 441 - learning_rate: 0.0001\n",
            "Classifier Epoch 22/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9394, Acc=64.06%]2025-11-03 09:57:32,232 - supervised_finetuning - INFO - Epoch 451 - supervised_loss/batch: 0.9394\n",
            "2025-11-03 09:57:32,232 - supervised_finetuning - INFO - Epoch 451 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:32,232 - supervised_finetuning - INFO - Epoch 451 - learning_rate: 0.0001\n",
            "Classifier Epoch 22/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0888, Acc=57.14%]2025-11-03 09:57:32,281 - supervised_finetuning - INFO - Epoch 461 - supervised_loss/batch: 1.0888\n",
            "2025-11-03 09:57:32,281 - supervised_finetuning - INFO - Epoch 461 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:32,281 - supervised_finetuning - INFO - Epoch 461 - learning_rate: 0.0001\n",
            "Classifier Epoch 22/100: 100% 21/21 [00:00<00:00, 209.02it/s, Loss=1.0888, Acc=57.14%]\n",
            "2025-11-03 09:57:32,297 - supervised_finetuning - INFO - Epoch 22:\n",
            "2025-11-03 09:57:32,297 - supervised_finetuning - INFO -   Train Loss: 0.9384, Train Acc: 63.71%\n",
            "2025-11-03 09:57:32,297 - supervised_finetuning - INFO -   Train F1: 62.88%, Train Recall: 63.71%\n",
            "2025-11-03 09:57:32,297 - supervised_finetuning - INFO -   Train Precision: 64.32%\n",
            "2025-11-03 09:57:32,297 - supervised_finetuning - INFO - Epoch 21 - supervised_loss/epoch: 0.9384\n",
            "2025-11-03 09:57:32,297 - supervised_finetuning - INFO - Epoch 21 - supervised_accuracy/epoch: 63.7141\n",
            "2025-11-03 09:57:32,298 - supervised_finetuning - INFO - Epoch 21 - supervised_f1/epoch: 62.8815\n",
            "2025-11-03 09:57:32,298 - supervised_finetuning - INFO - Epoch 21 - supervised_recall/epoch: 63.7141\n",
            "2025-11-03 09:57:32,298 - supervised_finetuning - INFO - Epoch 21 - supervised_precision/epoch: 64.3227\n",
            "Classifier Epoch 23/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0078, Acc=57.81%]2025-11-03 09:57:32,303 - supervised_finetuning - INFO - Epoch 462 - supervised_loss/batch: 1.0078\n",
            "2025-11-03 09:57:32,303 - supervised_finetuning - INFO - Epoch 462 - supervised_accuracy/batch: 57.8125\n",
            "2025-11-03 09:57:32,303 - supervised_finetuning - INFO - Epoch 462 - learning_rate: 0.0001\n",
            "Classifier Epoch 23/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8501, Acc=62.50%]2025-11-03 09:57:32,353 - supervised_finetuning - INFO - Epoch 472 - supervised_loss/batch: 0.8501\n",
            "2025-11-03 09:57:32,353 - supervised_finetuning - INFO - Epoch 472 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:32,353 - supervised_finetuning - INFO - Epoch 472 - learning_rate: 0.0001\n",
            "Classifier Epoch 23/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3083, Acc=42.86%]2025-11-03 09:57:32,399 - supervised_finetuning - INFO - Epoch 482 - supervised_loss/batch: 1.3083\n",
            "2025-11-03 09:57:32,399 - supervised_finetuning - INFO - Epoch 482 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:32,400 - supervised_finetuning - INFO - Epoch 482 - learning_rate: 0.0001\n",
            "Classifier Epoch 23/100: 100% 21/21 [00:00<00:00, 206.95it/s, Loss=1.3083, Acc=42.86%]\n",
            "2025-11-03 09:57:32,425 - supervised_finetuning - INFO - Epoch 23:\n",
            "2025-11-03 09:57:32,425 - supervised_finetuning - INFO -   Train Loss: 0.9333, Train Acc: 64.65%\n",
            "2025-11-03 09:57:32,425 - supervised_finetuning - INFO -   Train F1: 64.18%, Train Recall: 64.65%\n",
            "2025-11-03 09:57:32,425 - supervised_finetuning - INFO -   Train Precision: 64.51%\n",
            "2025-11-03 09:57:32,425 - supervised_finetuning - INFO - Epoch 22 - supervised_loss/epoch: 0.9333\n",
            "2025-11-03 09:57:32,425 - supervised_finetuning - INFO - Epoch 22 - supervised_accuracy/epoch: 64.6465\n",
            "2025-11-03 09:57:32,426 - supervised_finetuning - INFO - Epoch 22 - supervised_f1/epoch: 64.1794\n",
            "2025-11-03 09:57:32,426 - supervised_finetuning - INFO - Epoch 22 - supervised_recall/epoch: 64.6465\n",
            "2025-11-03 09:57:32,426 - supervised_finetuning - INFO - Epoch 22 - supervised_precision/epoch: 64.5059\n",
            "Classifier Epoch 24/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8530, Acc=64.06%]2025-11-03 09:57:32,432 - supervised_finetuning - INFO - Epoch 483 - supervised_loss/batch: 0.8530\n",
            "2025-11-03 09:57:32,432 - supervised_finetuning - INFO - Epoch 483 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:32,432 - supervised_finetuning - INFO - Epoch 483 - learning_rate: 0.0001\n",
            "Classifier Epoch 24/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9957, Acc=57.81%]2025-11-03 09:57:32,481 - supervised_finetuning - INFO - Epoch 493 - supervised_loss/batch: 0.9957\n",
            "2025-11-03 09:57:32,481 - supervised_finetuning - INFO - Epoch 493 - supervised_accuracy/batch: 57.8125\n",
            "2025-11-03 09:57:32,481 - supervised_finetuning - INFO - Epoch 493 - learning_rate: 0.0001\n",
            "Classifier Epoch 24/100:  95% 20/21 [00:00<00:00, 199.22it/s, Loss=0.9292, Acc=71.43%]2025-11-03 09:57:32,531 - supervised_finetuning - INFO - Epoch 503 - supervised_loss/batch: 0.9292\n",
            "2025-11-03 09:57:32,531 - supervised_finetuning - INFO - Epoch 503 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:32,531 - supervised_finetuning - INFO - Epoch 503 - learning_rate: 0.0001\n",
            "Classifier Epoch 24/100: 100% 21/21 [00:00<00:00, 200.25it/s, Loss=0.9292, Acc=71.43%]\n",
            "2025-11-03 09:57:32,547 - supervised_finetuning - INFO - Epoch 24:\n",
            "2025-11-03 09:57:32,547 - supervised_finetuning - INFO -   Train Loss: 0.9139, Train Acc: 63.09%\n",
            "2025-11-03 09:57:32,547 - supervised_finetuning - INFO -   Train F1: 62.51%, Train Recall: 63.09%\n",
            "2025-11-03 09:57:32,547 - supervised_finetuning - INFO -   Train Precision: 62.70%\n",
            "2025-11-03 09:57:32,547 - supervised_finetuning - INFO - Epoch 23 - supervised_loss/epoch: 0.9139\n",
            "2025-11-03 09:57:32,548 - supervised_finetuning - INFO - Epoch 23 - supervised_accuracy/epoch: 63.0925\n",
            "2025-11-03 09:57:32,548 - supervised_finetuning - INFO - Epoch 23 - supervised_f1/epoch: 62.5072\n",
            "2025-11-03 09:57:32,548 - supervised_finetuning - INFO - Epoch 23 - supervised_recall/epoch: 63.0925\n",
            "2025-11-03 09:57:32,548 - supervised_finetuning - INFO - Epoch 23 - supervised_precision/epoch: 62.6964\n",
            "Classifier Epoch 25/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8681, Acc=62.50%]2025-11-03 09:57:32,553 - supervised_finetuning - INFO - Epoch 504 - supervised_loss/batch: 0.8681\n",
            "2025-11-03 09:57:32,554 - supervised_finetuning - INFO - Epoch 504 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:32,554 - supervised_finetuning - INFO - Epoch 504 - learning_rate: 0.0001\n",
            "Classifier Epoch 25/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9692, Acc=64.06%]2025-11-03 09:57:32,617 - supervised_finetuning - INFO - Epoch 514 - supervised_loss/batch: 0.9692\n",
            "2025-11-03 09:57:32,617 - supervised_finetuning - INFO - Epoch 514 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:32,617 - supervised_finetuning - INFO - Epoch 514 - learning_rate: 0.0001\n",
            "Classifier Epoch 25/100:  90% 19/21 [00:00<00:00, 184.25it/s, Loss=0.7219, Acc=57.14%]2025-11-03 09:57:32,659 - supervised_finetuning - INFO - Epoch 524 - supervised_loss/batch: 0.7219\n",
            "2025-11-03 09:57:32,660 - supervised_finetuning - INFO - Epoch 524 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:32,660 - supervised_finetuning - INFO - Epoch 524 - learning_rate: 0.0001\n",
            "Classifier Epoch 25/100: 100% 21/21 [00:00<00:00, 188.14it/s, Loss=0.7219, Acc=57.14%]\n",
            "2025-11-03 09:57:32,677 - supervised_finetuning - INFO - Epoch 25:\n",
            "2025-11-03 09:57:32,677 - supervised_finetuning - INFO -   Train Loss: 0.8946, Train Acc: 65.19%\n",
            "2025-11-03 09:57:32,677 - supervised_finetuning - INFO -   Train F1: 64.73%, Train Recall: 65.19%\n",
            "2025-11-03 09:57:32,677 - supervised_finetuning - INFO -   Train Precision: 65.65%\n",
            "2025-11-03 09:57:32,677 - supervised_finetuning - INFO - Epoch 24 - supervised_loss/epoch: 0.8946\n",
            "2025-11-03 09:57:32,678 - supervised_finetuning - INFO - Epoch 24 - supervised_accuracy/epoch: 65.1904\n",
            "2025-11-03 09:57:32,678 - supervised_finetuning - INFO - Epoch 24 - supervised_f1/epoch: 64.7345\n",
            "2025-11-03 09:57:32,678 - supervised_finetuning - INFO - Epoch 24 - supervised_recall/epoch: 65.1904\n",
            "2025-11-03 09:57:32,678 - supervised_finetuning - INFO - Epoch 24 - supervised_precision/epoch: 65.6520\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:33,271 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 65.19%\n",
            "Classifier Epoch 26/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8605, Acc=65.62%]2025-11-03 09:57:33,278 - supervised_finetuning - INFO - Epoch 525 - supervised_loss/batch: 0.8605\n",
            "2025-11-03 09:57:33,279 - supervised_finetuning - INFO - Epoch 525 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:33,279 - supervised_finetuning - INFO - Epoch 525 - learning_rate: 0.0001\n",
            "Classifier Epoch 26/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1104, Acc=48.44%]2025-11-03 09:57:33,315 - supervised_finetuning - INFO - Epoch 535 - supervised_loss/batch: 1.1104\n",
            "2025-11-03 09:57:33,315 - supervised_finetuning - INFO - Epoch 535 - supervised_accuracy/batch: 48.4375\n",
            "2025-11-03 09:57:33,316 - supervised_finetuning - INFO - Epoch 535 - learning_rate: 0.0001\n",
            "Classifier Epoch 26/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7143, Acc=71.43%]2025-11-03 09:57:33,359 - supervised_finetuning - INFO - Epoch 545 - supervised_loss/batch: 0.7143\n",
            "2025-11-03 09:57:33,359 - supervised_finetuning - INFO - Epoch 545 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:33,359 - supervised_finetuning - INFO - Epoch 545 - learning_rate: 0.0001\n",
            "Classifier Epoch 26/100: 100% 21/21 [00:00<00:00, 240.57it/s, Loss=0.7143, Acc=71.43%]\n",
            "2025-11-03 09:57:33,369 - supervised_finetuning - INFO - Epoch 26:\n",
            "2025-11-03 09:57:33,369 - supervised_finetuning - INFO -   Train Loss: 0.8604, Train Acc: 65.58%\n",
            "2025-11-03 09:57:33,369 - supervised_finetuning - INFO -   Train F1: 65.05%, Train Recall: 65.58%\n",
            "2025-11-03 09:57:33,369 - supervised_finetuning - INFO -   Train Precision: 65.79%\n",
            "2025-11-03 09:57:33,370 - supervised_finetuning - INFO - Epoch 25 - supervised_loss/epoch: 0.8604\n",
            "2025-11-03 09:57:33,370 - supervised_finetuning - INFO - Epoch 25 - supervised_accuracy/epoch: 65.5789\n",
            "2025-11-03 09:57:33,370 - supervised_finetuning - INFO - Epoch 25 - supervised_f1/epoch: 65.0537\n",
            "2025-11-03 09:57:33,370 - supervised_finetuning - INFO - Epoch 25 - supervised_recall/epoch: 65.5789\n",
            "2025-11-03 09:57:33,370 - supervised_finetuning - INFO - Epoch 25 - supervised_precision/epoch: 65.7910\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:33,990 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 65.58%\n",
            "Classifier Epoch 27/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8270, Acc=60.94%]2025-11-03 09:57:33,995 - supervised_finetuning - INFO - Epoch 546 - supervised_loss/batch: 0.8270\n",
            "2025-11-03 09:57:33,996 - supervised_finetuning - INFO - Epoch 546 - supervised_accuracy/batch: 60.9375\n",
            "2025-11-03 09:57:33,996 - supervised_finetuning - INFO - Epoch 546 - learning_rate: 0.0001\n",
            "Classifier Epoch 27/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9323, Acc=62.50%]2025-11-03 09:57:34,037 - supervised_finetuning - INFO - Epoch 556 - supervised_loss/batch: 0.9323\n",
            "2025-11-03 09:57:34,038 - supervised_finetuning - INFO - Epoch 556 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:34,038 - supervised_finetuning - INFO - Epoch 556 - learning_rate: 0.0001\n",
            "Classifier Epoch 27/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3943, Acc=100.00%]2025-11-03 09:57:34,074 - supervised_finetuning - INFO - Epoch 566 - supervised_loss/batch: 0.3943\n",
            "2025-11-03 09:57:34,075 - supervised_finetuning - INFO - Epoch 566 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:34,075 - supervised_finetuning - INFO - Epoch 566 - learning_rate: 0.0001\n",
            "Classifier Epoch 27/100: 100% 21/21 [00:00<00:00, 247.48it/s, Loss=0.3943, Acc=100.00%]\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO - Epoch 27:\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO -   Train Loss: 0.8592, Train Acc: 65.19%\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO -   Train F1: 64.87%, Train Recall: 65.19%\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO -   Train Precision: 64.96%\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO - Epoch 26 - supervised_loss/epoch: 0.8592\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO - Epoch 26 - supervised_accuracy/epoch: 65.1904\n",
            "2025-11-03 09:57:34,085 - supervised_finetuning - INFO - Epoch 26 - supervised_f1/epoch: 64.8739\n",
            "2025-11-03 09:57:34,086 - supervised_finetuning - INFO - Epoch 26 - supervised_recall/epoch: 65.1904\n",
            "2025-11-03 09:57:34,086 - supervised_finetuning - INFO - Epoch 26 - supervised_precision/epoch: 64.9566\n",
            "Classifier Epoch 28/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8050, Acc=73.44%]2025-11-03 09:57:34,090 - supervised_finetuning - INFO - Epoch 567 - supervised_loss/batch: 0.8050\n",
            "2025-11-03 09:57:34,090 - supervised_finetuning - INFO - Epoch 567 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:34,090 - supervised_finetuning - INFO - Epoch 567 - learning_rate: 0.0001\n",
            "Classifier Epoch 28/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8230, Acc=68.75%]2025-11-03 09:57:34,127 - supervised_finetuning - INFO - Epoch 577 - supervised_loss/batch: 0.8230\n",
            "2025-11-03 09:57:34,127 - supervised_finetuning - INFO - Epoch 577 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:34,128 - supervised_finetuning - INFO - Epoch 577 - learning_rate: 0.0001\n",
            "Classifier Epoch 28/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7105, Acc=71.43%]2025-11-03 09:57:34,163 - supervised_finetuning - INFO - Epoch 587 - supervised_loss/batch: 0.7105\n",
            "2025-11-03 09:57:34,163 - supervised_finetuning - INFO - Epoch 587 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:34,163 - supervised_finetuning - INFO - Epoch 587 - learning_rate: 0.0001\n",
            "Classifier Epoch 28/100: 100% 21/21 [00:00<00:00, 271.15it/s, Loss=0.7105, Acc=71.43%]\n",
            "2025-11-03 09:57:34,174 - supervised_finetuning - INFO - Epoch 28:\n",
            "2025-11-03 09:57:34,174 - supervised_finetuning - INFO -   Train Loss: 0.8519, Train Acc: 66.12%\n",
            "2025-11-03 09:57:34,174 - supervised_finetuning - INFO -   Train F1: 65.61%, Train Recall: 66.12%\n",
            "2025-11-03 09:57:34,174 - supervised_finetuning - INFO -   Train Precision: 66.60%\n",
            "2025-11-03 09:57:34,174 - supervised_finetuning - INFO - Epoch 27 - supervised_loss/epoch: 0.8519\n",
            "2025-11-03 09:57:34,174 - supervised_finetuning - INFO - Epoch 27 - supervised_accuracy/epoch: 66.1228\n",
            "2025-11-03 09:57:34,175 - supervised_finetuning - INFO - Epoch 27 - supervised_f1/epoch: 65.6133\n",
            "2025-11-03 09:57:34,175 - supervised_finetuning - INFO - Epoch 27 - supervised_recall/epoch: 66.1228\n",
            "2025-11-03 09:57:34,175 - supervised_finetuning - INFO - Epoch 27 - supervised_precision/epoch: 66.5993\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:36,623 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 66.12%\n",
            "Classifier Epoch 29/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7063, Acc=75.00%]2025-11-03 09:57:36,628 - supervised_finetuning - INFO - Epoch 588 - supervised_loss/batch: 0.7063\n",
            "2025-11-03 09:57:36,629 - supervised_finetuning - INFO - Epoch 588 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:57:36,629 - supervised_finetuning - INFO - Epoch 588 - learning_rate: 0.0001\n",
            "Classifier Epoch 29/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7353, Acc=78.12%]2025-11-03 09:57:36,665 - supervised_finetuning - INFO - Epoch 598 - supervised_loss/batch: 0.7353\n",
            "2025-11-03 09:57:36,665 - supervised_finetuning - INFO - Epoch 598 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:36,665 - supervised_finetuning - INFO - Epoch 598 - learning_rate: 0.0001\n",
            "Classifier Epoch 29/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5913, Acc=85.71%]2025-11-03 09:57:36,706 - supervised_finetuning - INFO - Epoch 608 - supervised_loss/batch: 0.5913\n",
            "2025-11-03 09:57:36,706 - supervised_finetuning - INFO - Epoch 608 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:36,706 - supervised_finetuning - INFO - Epoch 608 - learning_rate: 0.0001\n",
            "Classifier Epoch 29/100: 100% 21/21 [00:00<00:00, 252.68it/s, Loss=0.5913, Acc=85.71%]\n",
            "2025-11-03 09:57:36,721 - supervised_finetuning - INFO - Epoch 29:\n",
            "2025-11-03 09:57:36,721 - supervised_finetuning - INFO -   Train Loss: 0.8393, Train Acc: 67.52%\n",
            "2025-11-03 09:57:36,721 - supervised_finetuning - INFO -   Train F1: 67.17%, Train Recall: 67.52%\n",
            "2025-11-03 09:57:36,721 - supervised_finetuning - INFO -   Train Precision: 68.05%\n",
            "2025-11-03 09:57:36,721 - supervised_finetuning - INFO - Epoch 28 - supervised_loss/epoch: 0.8393\n",
            "2025-11-03 09:57:36,721 - supervised_finetuning - INFO - Epoch 28 - supervised_accuracy/epoch: 67.5214\n",
            "2025-11-03 09:57:36,722 - supervised_finetuning - INFO - Epoch 28 - supervised_f1/epoch: 67.1715\n",
            "2025-11-03 09:57:36,722 - supervised_finetuning - INFO - Epoch 28 - supervised_recall/epoch: 67.5214\n",
            "2025-11-03 09:57:36,722 - supervised_finetuning - INFO - Epoch 28 - supervised_precision/epoch: 68.0480\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:42,719 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 67.52%\n",
            "Classifier Epoch 30/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6099, Acc=79.69%]2025-11-03 09:57:42,724 - supervised_finetuning - INFO - Epoch 609 - supervised_loss/batch: 0.6099\n",
            "2025-11-03 09:57:42,725 - supervised_finetuning - INFO - Epoch 609 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:57:42,725 - supervised_finetuning - INFO - Epoch 609 - learning_rate: 0.0001\n",
            "Classifier Epoch 30/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7967, Acc=70.31%]2025-11-03 09:57:42,760 - supervised_finetuning - INFO - Epoch 619 - supervised_loss/batch: 0.7967\n",
            "2025-11-03 09:57:42,761 - supervised_finetuning - INFO - Epoch 619 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:42,761 - supervised_finetuning - INFO - Epoch 619 - learning_rate: 0.0001\n",
            "Classifier Epoch 30/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5524, Acc=85.71%]2025-11-03 09:57:42,796 - supervised_finetuning - INFO - Epoch 629 - supervised_loss/batch: 0.5524\n",
            "2025-11-03 09:57:42,796 - supervised_finetuning - INFO - Epoch 629 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:42,797 - supervised_finetuning - INFO - Epoch 629 - learning_rate: 0.0001\n",
            "Classifier Epoch 30/100: 100% 21/21 [00:00<00:00, 272.49it/s, Loss=0.5524, Acc=85.71%]\n",
            "2025-11-03 09:57:42,806 - supervised_finetuning - INFO - Epoch 30:\n",
            "2025-11-03 09:57:42,806 - supervised_finetuning - INFO -   Train Loss: 0.8091, Train Acc: 68.22%\n",
            "2025-11-03 09:57:42,806 - supervised_finetuning - INFO -   Train F1: 67.79%, Train Recall: 68.22%\n",
            "2025-11-03 09:57:42,806 - supervised_finetuning - INFO -   Train Precision: 68.52%\n",
            "2025-11-03 09:57:42,807 - supervised_finetuning - INFO - Epoch 29 - supervised_loss/epoch: 0.8091\n",
            "2025-11-03 09:57:42,807 - supervised_finetuning - INFO - Epoch 29 - supervised_accuracy/epoch: 68.2207\n",
            "2025-11-03 09:57:42,807 - supervised_finetuning - INFO - Epoch 29 - supervised_f1/epoch: 67.7903\n",
            "2025-11-03 09:57:42,807 - supervised_finetuning - INFO - Epoch 29 - supervised_recall/epoch: 68.2207\n",
            "2025-11-03 09:57:42,807 - supervised_finetuning - INFO - Epoch 29 - supervised_precision/epoch: 68.5175\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:43,383 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 68.22%\n",
            "Classifier Epoch 31/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7686, Acc=71.88%]2025-11-03 09:57:43,391 - supervised_finetuning - INFO - Epoch 630 - supervised_loss/batch: 0.7686\n",
            "2025-11-03 09:57:43,391 - supervised_finetuning - INFO - Epoch 630 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:43,391 - supervised_finetuning - INFO - Epoch 630 - learning_rate: 0.0001\n",
            "Classifier Epoch 31/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9355, Acc=64.06%]2025-11-03 09:57:43,443 - supervised_finetuning - INFO - Epoch 640 - supervised_loss/batch: 0.9355\n",
            "2025-11-03 09:57:43,443 - supervised_finetuning - INFO - Epoch 640 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:43,444 - supervised_finetuning - INFO - Epoch 640 - learning_rate: 0.0001\n",
            "Classifier Epoch 31/100:  95% 20/21 [00:00<00:00, 195.84it/s, Loss=1.1224, Acc=57.14%]2025-11-03 09:57:43,497 - supervised_finetuning - INFO - Epoch 650 - supervised_loss/batch: 1.1224\n",
            "2025-11-03 09:57:43,497 - supervised_finetuning - INFO - Epoch 650 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:43,498 - supervised_finetuning - INFO - Epoch 650 - learning_rate: 0.0001\n",
            "Classifier Epoch 31/100: 100% 21/21 [00:00<00:00, 185.66it/s, Loss=1.1224, Acc=57.14%]\n",
            "2025-11-03 09:57:43,518 - supervised_finetuning - INFO - Epoch 31:\n",
            "2025-11-03 09:57:43,519 - supervised_finetuning - INFO -   Train Loss: 0.8374, Train Acc: 67.13%\n",
            "2025-11-03 09:57:43,519 - supervised_finetuning - INFO -   Train F1: 66.77%, Train Recall: 67.13%\n",
            "2025-11-03 09:57:43,519 - supervised_finetuning - INFO -   Train Precision: 67.21%\n",
            "2025-11-03 09:57:43,519 - supervised_finetuning - INFO - Epoch 30 - supervised_loss/epoch: 0.8374\n",
            "2025-11-03 09:57:43,521 - supervised_finetuning - INFO - Epoch 30 - supervised_accuracy/epoch: 67.1329\n",
            "2025-11-03 09:57:43,521 - supervised_finetuning - INFO - Epoch 30 - supervised_f1/epoch: 66.7741\n",
            "2025-11-03 09:57:43,522 - supervised_finetuning - INFO - Epoch 30 - supervised_recall/epoch: 67.1329\n",
            "2025-11-03 09:57:43,522 - supervised_finetuning - INFO - Epoch 30 - supervised_precision/epoch: 67.2114\n",
            "Classifier Epoch 32/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9120, Acc=59.38%]2025-11-03 09:57:43,528 - supervised_finetuning - INFO - Epoch 651 - supervised_loss/batch: 0.9120\n",
            "2025-11-03 09:57:43,528 - supervised_finetuning - INFO - Epoch 651 - supervised_accuracy/batch: 59.3750\n",
            "2025-11-03 09:57:43,528 - supervised_finetuning - INFO - Epoch 651 - learning_rate: 0.0001\n",
            "Classifier Epoch 32/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8531, Acc=65.62%]2025-11-03 09:57:43,574 - supervised_finetuning - INFO - Epoch 661 - supervised_loss/batch: 0.8531\n",
            "2025-11-03 09:57:43,574 - supervised_finetuning - INFO - Epoch 661 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:43,574 - supervised_finetuning - INFO - Epoch 661 - learning_rate: 0.0001\n",
            "Classifier Epoch 32/100:  95% 20/21 [00:00<00:00, 190.16it/s, Loss=0.9726, Acc=42.86%]2025-11-03 09:57:43,632 - supervised_finetuning - INFO - Epoch 671 - supervised_loss/batch: 0.9726\n",
            "2025-11-03 09:57:43,633 - supervised_finetuning - INFO - Epoch 671 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:43,633 - supervised_finetuning - INFO - Epoch 671 - learning_rate: 0.0001\n",
            "Classifier Epoch 32/100: 100% 21/21 [00:00<00:00, 188.53it/s, Loss=0.9726, Acc=42.86%]\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO - Epoch 32:\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO -   Train Loss: 0.8187, Train Acc: 67.37%\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO -   Train F1: 67.12%, Train Recall: 67.37%\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO -   Train Precision: 67.15%\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO - Epoch 31 - supervised_loss/epoch: 0.8187\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO - Epoch 31 - supervised_accuracy/epoch: 67.3660\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO - Epoch 31 - supervised_f1/epoch: 67.1181\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO - Epoch 31 - supervised_recall/epoch: 67.3660\n",
            "2025-11-03 09:57:43,651 - supervised_finetuning - INFO - Epoch 31 - supervised_precision/epoch: 67.1515\n",
            "Classifier Epoch 33/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7963, Acc=73.44%]2025-11-03 09:57:43,657 - supervised_finetuning - INFO - Epoch 672 - supervised_loss/batch: 0.7963\n",
            "2025-11-03 09:57:43,658 - supervised_finetuning - INFO - Epoch 672 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:43,658 - supervised_finetuning - INFO - Epoch 672 - learning_rate: 0.0001\n",
            "Classifier Epoch 33/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8908, Acc=62.50%]2025-11-03 09:57:43,702 - supervised_finetuning - INFO - Epoch 682 - supervised_loss/batch: 0.8908\n",
            "2025-11-03 09:57:43,702 - supervised_finetuning - INFO - Epoch 682 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:43,702 - supervised_finetuning - INFO - Epoch 682 - learning_rate: 0.0001\n",
            "Classifier Epoch 33/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3401, Acc=71.43%]2025-11-03 09:57:43,752 - supervised_finetuning - INFO - Epoch 692 - supervised_loss/batch: 1.3401\n",
            "2025-11-03 09:57:43,753 - supervised_finetuning - INFO - Epoch 692 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:43,753 - supervised_finetuning - INFO - Epoch 692 - learning_rate: 0.0001\n",
            "Classifier Epoch 33/100: 100% 21/21 [00:00<00:00, 207.01it/s, Loss=1.3401, Acc=71.43%]\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO - Epoch 33:\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO -   Train Loss: 0.8873, Train Acc: 65.35%\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO -   Train F1: 64.63%, Train Recall: 65.35%\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO -   Train Precision: 65.51%\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO - Epoch 32 - supervised_loss/epoch: 0.8873\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO - Epoch 32 - supervised_accuracy/epoch: 65.3458\n",
            "2025-11-03 09:57:43,769 - supervised_finetuning - INFO - Epoch 32 - supervised_f1/epoch: 64.6299\n",
            "2025-11-03 09:57:43,770 - supervised_finetuning - INFO - Epoch 32 - supervised_recall/epoch: 65.3458\n",
            "2025-11-03 09:57:43,770 - supervised_finetuning - INFO - Epoch 32 - supervised_precision/epoch: 65.5148\n",
            "Classifier Epoch 34/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7747, Acc=70.31%]2025-11-03 09:57:43,775 - supervised_finetuning - INFO - Epoch 693 - supervised_loss/batch: 0.7747\n",
            "2025-11-03 09:57:43,775 - supervised_finetuning - INFO - Epoch 693 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:43,776 - supervised_finetuning - INFO - Epoch 693 - learning_rate: 0.0001\n",
            "Classifier Epoch 34/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6887, Acc=82.81%]2025-11-03 09:57:43,821 - supervised_finetuning - INFO - Epoch 703 - supervised_loss/batch: 0.6887\n",
            "2025-11-03 09:57:43,821 - supervised_finetuning - INFO - Epoch 703 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:57:43,821 - supervised_finetuning - INFO - Epoch 703 - learning_rate: 0.0001\n",
            "Classifier Epoch 34/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9396, Acc=57.14%]2025-11-03 09:57:43,870 - supervised_finetuning - INFO - Epoch 713 - supervised_loss/batch: 0.9396\n",
            "2025-11-03 09:57:43,870 - supervised_finetuning - INFO - Epoch 713 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:43,871 - supervised_finetuning - INFO - Epoch 713 - learning_rate: 0.0001\n",
            "Classifier Epoch 34/100: 100% 21/21 [00:00<00:00, 208.67it/s, Loss=0.9396, Acc=57.14%]\n",
            "2025-11-03 09:57:43,887 - supervised_finetuning - INFO - Epoch 34:\n",
            "2025-11-03 09:57:43,887 - supervised_finetuning - INFO -   Train Loss: 0.8089, Train Acc: 69.23%\n",
            "2025-11-03 09:57:43,887 - supervised_finetuning - INFO -   Train F1: 68.82%, Train Recall: 69.23%\n",
            "2025-11-03 09:57:43,887 - supervised_finetuning - INFO -   Train Precision: 69.43%\n",
            "2025-11-03 09:57:43,888 - supervised_finetuning - INFO - Epoch 33 - supervised_loss/epoch: 0.8089\n",
            "2025-11-03 09:57:43,888 - supervised_finetuning - INFO - Epoch 33 - supervised_accuracy/epoch: 69.2308\n",
            "2025-11-03 09:57:43,888 - supervised_finetuning - INFO - Epoch 33 - supervised_f1/epoch: 68.8247\n",
            "2025-11-03 09:57:43,888 - supervised_finetuning - INFO - Epoch 33 - supervised_recall/epoch: 69.2308\n",
            "2025-11-03 09:57:43,888 - supervised_finetuning - INFO - Epoch 33 - supervised_precision/epoch: 69.4311\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:46,815 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 69.23%\n",
            "Classifier Epoch 35/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7157, Acc=71.88%]2025-11-03 09:57:46,821 - supervised_finetuning - INFO - Epoch 714 - supervised_loss/batch: 0.7157\n",
            "2025-11-03 09:57:46,821 - supervised_finetuning - INFO - Epoch 714 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:46,822 - supervised_finetuning - INFO - Epoch 714 - learning_rate: 0.0001\n",
            "Classifier Epoch 35/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7736, Acc=70.31%]2025-11-03 09:57:46,858 - supervised_finetuning - INFO - Epoch 724 - supervised_loss/batch: 0.7736\n",
            "2025-11-03 09:57:46,858 - supervised_finetuning - INFO - Epoch 724 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:46,858 - supervised_finetuning - INFO - Epoch 724 - learning_rate: 0.0001\n",
            "Classifier Epoch 35/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3140, Acc=57.14%]2025-11-03 09:57:46,893 - supervised_finetuning - INFO - Epoch 734 - supervised_loss/batch: 1.3140\n",
            "2025-11-03 09:57:46,893 - supervised_finetuning - INFO - Epoch 734 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:46,894 - supervised_finetuning - INFO - Epoch 734 - learning_rate: 0.0001\n",
            "Classifier Epoch 35/100: 100% 21/21 [00:00<00:00, 269.36it/s, Loss=1.3140, Acc=57.14%]\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO - Epoch 35:\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO -   Train Loss: 0.8305, Train Acc: 67.44%\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO -   Train F1: 67.28%, Train Recall: 67.44%\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO -   Train Precision: 67.76%\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO - Epoch 34 - supervised_loss/epoch: 0.8305\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO - Epoch 34 - supervised_accuracy/epoch: 67.4437\n",
            "2025-11-03 09:57:46,904 - supervised_finetuning - INFO - Epoch 34 - supervised_f1/epoch: 67.2752\n",
            "2025-11-03 09:57:46,905 - supervised_finetuning - INFO - Epoch 34 - supervised_recall/epoch: 67.4437\n",
            "2025-11-03 09:57:46,905 - supervised_finetuning - INFO - Epoch 34 - supervised_precision/epoch: 67.7562\n",
            "Classifier Epoch 36/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7700, Acc=70.31%]2025-11-03 09:57:46,909 - supervised_finetuning - INFO - Epoch 735 - supervised_loss/batch: 0.7700\n",
            "2025-11-03 09:57:46,909 - supervised_finetuning - INFO - Epoch 735 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:46,909 - supervised_finetuning - INFO - Epoch 735 - learning_rate: 0.0001\n",
            "Classifier Epoch 36/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7805, Acc=71.88%]2025-11-03 09:57:46,945 - supervised_finetuning - INFO - Epoch 745 - supervised_loss/batch: 0.7805\n",
            "2025-11-03 09:57:46,945 - supervised_finetuning - INFO - Epoch 745 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:46,945 - supervised_finetuning - INFO - Epoch 745 - learning_rate: 0.0001\n",
            "Classifier Epoch 36/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0451, Acc=57.14%]2025-11-03 09:57:46,981 - supervised_finetuning - INFO - Epoch 755 - supervised_loss/batch: 1.0451\n",
            "2025-11-03 09:57:46,981 - supervised_finetuning - INFO - Epoch 755 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:46,982 - supervised_finetuning - INFO - Epoch 755 - learning_rate: 0.0001\n",
            "Classifier Epoch 36/100: 100% 21/21 [00:00<00:00, 273.45it/s, Loss=1.0451, Acc=57.14%]\n",
            "2025-11-03 09:57:46,998 - supervised_finetuning - INFO - Epoch 36:\n",
            "2025-11-03 09:57:46,998 - supervised_finetuning - INFO -   Train Loss: 0.8050, Train Acc: 69.00%\n",
            "2025-11-03 09:57:46,998 - supervised_finetuning - INFO -   Train F1: 68.79%, Train Recall: 69.00%\n",
            "2025-11-03 09:57:46,999 - supervised_finetuning - INFO -   Train Precision: 69.26%\n",
            "2025-11-03 09:57:46,999 - supervised_finetuning - INFO - Epoch 35 - supervised_loss/epoch: 0.8050\n",
            "2025-11-03 09:57:46,999 - supervised_finetuning - INFO - Epoch 35 - supervised_accuracy/epoch: 68.9977\n",
            "2025-11-03 09:57:46,999 - supervised_finetuning - INFO - Epoch 35 - supervised_f1/epoch: 68.7868\n",
            "2025-11-03 09:57:46,999 - supervised_finetuning - INFO - Epoch 35 - supervised_recall/epoch: 68.9977\n",
            "2025-11-03 09:57:47,000 - supervised_finetuning - INFO - Epoch 35 - supervised_precision/epoch: 69.2573\n",
            "Classifier Epoch 37/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6716, Acc=75.00%]2025-11-03 09:57:47,006 - supervised_finetuning - INFO - Epoch 756 - supervised_loss/batch: 0.6716\n",
            "2025-11-03 09:57:47,006 - supervised_finetuning - INFO - Epoch 756 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:57:47,007 - supervised_finetuning - INFO - Epoch 756 - learning_rate: 0.0001\n",
            "Classifier Epoch 37/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8759, Acc=68.75%]2025-11-03 09:57:47,043 - supervised_finetuning - INFO - Epoch 766 - supervised_loss/batch: 0.8759\n",
            "2025-11-03 09:57:47,043 - supervised_finetuning - INFO - Epoch 766 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:47,043 - supervised_finetuning - INFO - Epoch 766 - learning_rate: 0.0001\n",
            "Classifier Epoch 37/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8837, Acc=85.71%]2025-11-03 09:57:47,078 - supervised_finetuning - INFO - Epoch 776 - supervised_loss/batch: 0.8837\n",
            "2025-11-03 09:57:47,078 - supervised_finetuning - INFO - Epoch 776 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:47,079 - supervised_finetuning - INFO - Epoch 776 - learning_rate: 0.0001\n",
            "Classifier Epoch 37/100: 100% 21/21 [00:00<00:00, 267.08it/s, Loss=0.8837, Acc=85.71%]\n",
            "2025-11-03 09:57:47,088 - supervised_finetuning - INFO - Epoch 37:\n",
            "2025-11-03 09:57:47,088 - supervised_finetuning - INFO -   Train Loss: 0.7903, Train Acc: 69.39%\n",
            "2025-11-03 09:57:47,088 - supervised_finetuning - INFO -   Train F1: 69.17%, Train Recall: 69.39%\n",
            "2025-11-03 09:57:47,088 - supervised_finetuning - INFO -   Train Precision: 69.73%\n",
            "2025-11-03 09:57:47,088 - supervised_finetuning - INFO - Epoch 36 - supervised_loss/epoch: 0.7903\n",
            "2025-11-03 09:57:47,089 - supervised_finetuning - INFO - Epoch 36 - supervised_accuracy/epoch: 69.3862\n",
            "2025-11-03 09:57:47,089 - supervised_finetuning - INFO - Epoch 36 - supervised_f1/epoch: 69.1740\n",
            "2025-11-03 09:57:47,089 - supervised_finetuning - INFO - Epoch 36 - supervised_recall/epoch: 69.3862\n",
            "2025-11-03 09:57:47,089 - supervised_finetuning - INFO - Epoch 36 - supervised_precision/epoch: 69.7333\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:47,695 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 69.39%\n",
            "Classifier Epoch 38/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7209, Acc=78.12%]2025-11-03 09:57:47,703 - supervised_finetuning - INFO - Epoch 777 - supervised_loss/batch: 0.7209\n",
            "2025-11-03 09:57:47,703 - supervised_finetuning - INFO - Epoch 777 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:47,703 - supervised_finetuning - INFO - Epoch 777 - learning_rate: 0.0001\n",
            "Classifier Epoch 38/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8232, Acc=71.88%]2025-11-03 09:57:47,744 - supervised_finetuning - INFO - Epoch 787 - supervised_loss/batch: 0.8232\n",
            "2025-11-03 09:57:47,744 - supervised_finetuning - INFO - Epoch 787 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:47,744 - supervised_finetuning - INFO - Epoch 787 - learning_rate: 0.0001\n",
            "Classifier Epoch 38/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.4043, Acc=42.86%]2025-11-03 09:57:47,781 - supervised_finetuning - INFO - Epoch 797 - supervised_loss/batch: 1.4043\n",
            "2025-11-03 09:57:47,781 - supervised_finetuning - INFO - Epoch 797 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:47,781 - supervised_finetuning - INFO - Epoch 797 - learning_rate: 0.0001\n",
            "Classifier Epoch 38/100: 100% 21/21 [00:00<00:00, 245.94it/s, Loss=1.4043, Acc=42.86%]\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO - Epoch 38:\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO -   Train Loss: 0.7918, Train Acc: 70.32%\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO -   Train F1: 70.12%, Train Recall: 70.32%\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO -   Train Precision: 70.81%\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO - Epoch 37 - supervised_loss/epoch: 0.7918\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO - Epoch 37 - supervised_accuracy/epoch: 70.3186\n",
            "2025-11-03 09:57:47,792 - supervised_finetuning - INFO - Epoch 37 - supervised_f1/epoch: 70.1210\n",
            "2025-11-03 09:57:47,793 - supervised_finetuning - INFO - Epoch 37 - supervised_recall/epoch: 70.3186\n",
            "2025-11-03 09:57:47,793 - supervised_finetuning - INFO - Epoch 37 - supervised_precision/epoch: 70.8066\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:48,505 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 70.32%\n",
            "Classifier Epoch 39/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7403, Acc=70.31%]2025-11-03 09:57:48,510 - supervised_finetuning - INFO - Epoch 798 - supervised_loss/batch: 0.7403\n",
            "2025-11-03 09:57:48,510 - supervised_finetuning - INFO - Epoch 798 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:48,511 - supervised_finetuning - INFO - Epoch 798 - learning_rate: 0.0001\n",
            "Classifier Epoch 39/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6283, Acc=78.12%]2025-11-03 09:57:48,549 - supervised_finetuning - INFO - Epoch 808 - supervised_loss/batch: 0.6283\n",
            "2025-11-03 09:57:48,550 - supervised_finetuning - INFO - Epoch 808 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:48,550 - supervised_finetuning - INFO - Epoch 808 - learning_rate: 0.0001\n",
            "Classifier Epoch 39/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8535, Acc=57.14%]2025-11-03 09:57:48,585 - supervised_finetuning - INFO - Epoch 818 - supervised_loss/batch: 0.8535\n",
            "2025-11-03 09:57:48,585 - supervised_finetuning - INFO - Epoch 818 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:48,585 - supervised_finetuning - INFO - Epoch 818 - learning_rate: 0.0001\n",
            "Classifier Epoch 39/100: 100% 21/21 [00:00<00:00, 261.81it/s, Loss=0.8535, Acc=57.14%]\n",
            "2025-11-03 09:57:48,596 - supervised_finetuning - INFO - Epoch 39:\n",
            "2025-11-03 09:57:48,596 - supervised_finetuning - INFO -   Train Loss: 0.7599, Train Acc: 70.94%\n",
            "2025-11-03 09:57:48,596 - supervised_finetuning - INFO -   Train F1: 70.79%, Train Recall: 70.94%\n",
            "2025-11-03 09:57:48,596 - supervised_finetuning - INFO -   Train Precision: 71.20%\n",
            "2025-11-03 09:57:48,597 - supervised_finetuning - INFO - Epoch 38 - supervised_loss/epoch: 0.7599\n",
            "2025-11-03 09:57:48,597 - supervised_finetuning - INFO - Epoch 38 - supervised_accuracy/epoch: 70.9402\n",
            "2025-11-03 09:57:48,597 - supervised_finetuning - INFO - Epoch 38 - supervised_f1/epoch: 70.7863\n",
            "2025-11-03 09:57:48,597 - supervised_finetuning - INFO - Epoch 38 - supervised_recall/epoch: 70.9402\n",
            "2025-11-03 09:57:48,597 - supervised_finetuning - INFO - Epoch 38 - supervised_precision/epoch: 71.1984\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:49,422 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 70.94%\n",
            "Classifier Epoch 40/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7858, Acc=71.88%]2025-11-03 09:57:49,429 - supervised_finetuning - INFO - Epoch 819 - supervised_loss/batch: 0.7858\n",
            "2025-11-03 09:57:49,429 - supervised_finetuning - INFO - Epoch 819 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:49,430 - supervised_finetuning - INFO - Epoch 819 - learning_rate: 0.0001\n",
            "Classifier Epoch 40/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8812, Acc=60.94%]2025-11-03 09:57:49,470 - supervised_finetuning - INFO - Epoch 829 - supervised_loss/batch: 0.8812\n",
            "2025-11-03 09:57:49,471 - supervised_finetuning - INFO - Epoch 829 - supervised_accuracy/batch: 60.9375\n",
            "2025-11-03 09:57:49,471 - supervised_finetuning - INFO - Epoch 829 - learning_rate: 0.0001\n",
            "Classifier Epoch 40/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.1546, Acc=42.86%]2025-11-03 09:57:49,507 - supervised_finetuning - INFO - Epoch 839 - supervised_loss/batch: 1.1546\n",
            "2025-11-03 09:57:49,507 - supervised_finetuning - INFO - Epoch 839 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:49,507 - supervised_finetuning - INFO - Epoch 839 - learning_rate: 0.0001\n",
            "Classifier Epoch 40/100: 100% 21/21 [00:00<00:00, 247.83it/s, Loss=1.1546, Acc=42.86%]\n",
            "2025-11-03 09:57:49,517 - supervised_finetuning - INFO - Epoch 40:\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO -   Train Loss: 0.7849, Train Acc: 69.46%\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO -   Train F1: 69.21%, Train Recall: 69.46%\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO -   Train Precision: 69.29%\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO - Epoch 39 - supervised_loss/epoch: 0.7849\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO - Epoch 39 - supervised_accuracy/epoch: 69.4639\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO - Epoch 39 - supervised_f1/epoch: 69.2111\n",
            "2025-11-03 09:57:49,518 - supervised_finetuning - INFO - Epoch 39 - supervised_recall/epoch: 69.4639\n",
            "2025-11-03 09:57:49,519 - supervised_finetuning - INFO - Epoch 39 - supervised_precision/epoch: 69.2856\n",
            "Classifier Epoch 41/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8466, Acc=64.06%]2025-11-03 09:57:49,523 - supervised_finetuning - INFO - Epoch 840 - supervised_loss/batch: 0.8466\n",
            "2025-11-03 09:57:49,523 - supervised_finetuning - INFO - Epoch 840 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:49,524 - supervised_finetuning - INFO - Epoch 840 - learning_rate: 0.0001\n",
            "Classifier Epoch 41/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7033, Acc=76.56%]2025-11-03 09:57:49,561 - supervised_finetuning - INFO - Epoch 850 - supervised_loss/batch: 0.7033\n",
            "2025-11-03 09:57:49,562 - supervised_finetuning - INFO - Epoch 850 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:57:49,562 - supervised_finetuning - INFO - Epoch 850 - learning_rate: 0.0001\n",
            "Classifier Epoch 41/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7062, Acc=57.14%]2025-11-03 09:57:49,600 - supervised_finetuning - INFO - Epoch 860 - supervised_loss/batch: 0.7062\n",
            "2025-11-03 09:57:49,600 - supervised_finetuning - INFO - Epoch 860 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:49,601 - supervised_finetuning - INFO - Epoch 860 - learning_rate: 0.0001\n",
            "Classifier Epoch 41/100: 100% 21/21 [00:00<00:00, 256.99it/s, Loss=0.7062, Acc=57.14%]\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO - Epoch 41:\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO -   Train Loss: 0.7606, Train Acc: 69.54%\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO -   Train F1: 69.21%, Train Recall: 69.54%\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO -   Train Precision: 69.93%\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO - Epoch 40 - supervised_loss/epoch: 0.7606\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO - Epoch 40 - supervised_accuracy/epoch: 69.5416\n",
            "2025-11-03 09:57:49,611 - supervised_finetuning - INFO - Epoch 40 - supervised_f1/epoch: 69.2073\n",
            "2025-11-03 09:57:49,612 - supervised_finetuning - INFO - Epoch 40 - supervised_recall/epoch: 69.5416\n",
            "2025-11-03 09:57:49,612 - supervised_finetuning - INFO - Epoch 40 - supervised_precision/epoch: 69.9314\n",
            "Classifier Epoch 42/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7725, Acc=65.62%]2025-11-03 09:57:49,617 - supervised_finetuning - INFO - Epoch 861 - supervised_loss/batch: 0.7725\n",
            "2025-11-03 09:57:49,618 - supervised_finetuning - INFO - Epoch 861 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:49,618 - supervised_finetuning - INFO - Epoch 861 - learning_rate: 0.0001\n",
            "Classifier Epoch 42/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7500, Acc=68.75%]2025-11-03 09:57:49,660 - supervised_finetuning - INFO - Epoch 871 - supervised_loss/batch: 0.7500\n",
            "2025-11-03 09:57:49,660 - supervised_finetuning - INFO - Epoch 871 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:49,661 - supervised_finetuning - INFO - Epoch 871 - learning_rate: 0.0001\n",
            "Classifier Epoch 42/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9561, Acc=57.14%]2025-11-03 09:57:49,697 - supervised_finetuning - INFO - Epoch 881 - supervised_loss/batch: 0.9561\n",
            "2025-11-03 09:57:49,698 - supervised_finetuning - INFO - Epoch 881 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:49,698 - supervised_finetuning - INFO - Epoch 881 - learning_rate: 0.0001\n",
            "Classifier Epoch 42/100: 100% 21/21 [00:00<00:00, 244.35it/s, Loss=0.9561, Acc=57.14%]\n",
            "2025-11-03 09:57:49,708 - supervised_finetuning - INFO - Epoch 42:\n",
            "2025-11-03 09:57:49,708 - supervised_finetuning - INFO -   Train Loss: 0.7582, Train Acc: 71.02%\n",
            "2025-11-03 09:57:49,708 - supervised_finetuning - INFO -   Train F1: 70.83%, Train Recall: 71.02%\n",
            "2025-11-03 09:57:49,708 - supervised_finetuning - INFO -   Train Precision: 70.85%\n",
            "2025-11-03 09:57:49,709 - supervised_finetuning - INFO - Epoch 41 - supervised_loss/epoch: 0.7582\n",
            "2025-11-03 09:57:49,709 - supervised_finetuning - INFO - Epoch 41 - supervised_accuracy/epoch: 71.0179\n",
            "2025-11-03 09:57:49,709 - supervised_finetuning - INFO - Epoch 41 - supervised_f1/epoch: 70.8273\n",
            "2025-11-03 09:57:49,709 - supervised_finetuning - INFO - Epoch 41 - supervised_recall/epoch: 71.0179\n",
            "2025-11-03 09:57:49,709 - supervised_finetuning - INFO - Epoch 41 - supervised_precision/epoch: 70.8505\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:50,190 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 71.02%\n",
            "Classifier Epoch 43/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8426, Acc=67.19%]2025-11-03 09:57:50,199 - supervised_finetuning - INFO - Epoch 882 - supervised_loss/batch: 0.8426\n",
            "2025-11-03 09:57:50,199 - supervised_finetuning - INFO - Epoch 882 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:50,199 - supervised_finetuning - INFO - Epoch 882 - learning_rate: 0.0001\n",
            "Classifier Epoch 43/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9342, Acc=56.25%]2025-11-03 09:57:50,238 - supervised_finetuning - INFO - Epoch 892 - supervised_loss/batch: 0.9342\n",
            "2025-11-03 09:57:50,238 - supervised_finetuning - INFO - Epoch 892 - supervised_accuracy/batch: 56.2500\n",
            "2025-11-03 09:57:50,239 - supervised_finetuning - INFO - Epoch 892 - learning_rate: 0.0001\n",
            "Classifier Epoch 43/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5235, Acc=85.71%]2025-11-03 09:57:50,278 - supervised_finetuning - INFO - Epoch 902 - supervised_loss/batch: 0.5235\n",
            "2025-11-03 09:57:50,278 - supervised_finetuning - INFO - Epoch 902 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:50,278 - supervised_finetuning - INFO - Epoch 902 - learning_rate: 0.0001\n",
            "Classifier Epoch 43/100: 100% 21/21 [00:00<00:00, 240.11it/s, Loss=0.5235, Acc=85.71%]\n",
            "2025-11-03 09:57:50,289 - supervised_finetuning - INFO - Epoch 43:\n",
            "2025-11-03 09:57:50,289 - supervised_finetuning - INFO -   Train Loss: 0.7525, Train Acc: 69.39%\n",
            "2025-11-03 09:57:50,289 - supervised_finetuning - INFO -   Train F1: 69.05%, Train Recall: 69.39%\n",
            "2025-11-03 09:57:50,290 - supervised_finetuning - INFO -   Train Precision: 69.67%\n",
            "2025-11-03 09:57:50,290 - supervised_finetuning - INFO - Epoch 42 - supervised_loss/epoch: 0.7525\n",
            "2025-11-03 09:57:50,290 - supervised_finetuning - INFO - Epoch 42 - supervised_accuracy/epoch: 69.3862\n",
            "2025-11-03 09:57:50,290 - supervised_finetuning - INFO - Epoch 42 - supervised_f1/epoch: 69.0546\n",
            "2025-11-03 09:57:50,290 - supervised_finetuning - INFO - Epoch 42 - supervised_recall/epoch: 69.3862\n",
            "2025-11-03 09:57:50,290 - supervised_finetuning - INFO - Epoch 42 - supervised_precision/epoch: 69.6689\n",
            "Classifier Epoch 44/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6592, Acc=79.69%]2025-11-03 09:57:50,296 - supervised_finetuning - INFO - Epoch 903 - supervised_loss/batch: 0.6592\n",
            "2025-11-03 09:57:50,296 - supervised_finetuning - INFO - Epoch 903 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:57:50,297 - supervised_finetuning - INFO - Epoch 903 - learning_rate: 0.0001\n",
            "Classifier Epoch 44/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7854, Acc=70.31%]2025-11-03 09:57:50,333 - supervised_finetuning - INFO - Epoch 913 - supervised_loss/batch: 0.7854\n",
            "2025-11-03 09:57:50,334 - supervised_finetuning - INFO - Epoch 913 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:50,334 - supervised_finetuning - INFO - Epoch 913 - learning_rate: 0.0001\n",
            "Classifier Epoch 44/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0558, Acc=42.86%]2025-11-03 09:57:50,371 - supervised_finetuning - INFO - Epoch 923 - supervised_loss/batch: 1.0558\n",
            "2025-11-03 09:57:50,372 - supervised_finetuning - INFO - Epoch 923 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:50,372 - supervised_finetuning - INFO - Epoch 923 - learning_rate: 0.0001\n",
            "Classifier Epoch 44/100: 100% 21/21 [00:00<00:00, 258.43it/s, Loss=1.0558, Acc=42.86%]\n",
            "2025-11-03 09:57:50,382 - supervised_finetuning - INFO - Epoch 44:\n",
            "2025-11-03 09:57:50,382 - supervised_finetuning - INFO -   Train Loss: 0.7613, Train Acc: 70.86%\n",
            "2025-11-03 09:57:50,383 - supervised_finetuning - INFO -   Train F1: 70.64%, Train Recall: 70.86%\n",
            "2025-11-03 09:57:50,383 - supervised_finetuning - INFO -   Train Precision: 71.44%\n",
            "2025-11-03 09:57:50,383 - supervised_finetuning - INFO - Epoch 43 - supervised_loss/epoch: 0.7613\n",
            "2025-11-03 09:57:50,383 - supervised_finetuning - INFO - Epoch 43 - supervised_accuracy/epoch: 70.8625\n",
            "2025-11-03 09:57:50,383 - supervised_finetuning - INFO - Epoch 43 - supervised_f1/epoch: 70.6422\n",
            "2025-11-03 09:57:50,383 - supervised_finetuning - INFO - Epoch 43 - supervised_recall/epoch: 70.8625\n",
            "2025-11-03 09:57:50,384 - supervised_finetuning - INFO - Epoch 43 - supervised_precision/epoch: 71.4352\n",
            "Classifier Epoch 45/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7020, Acc=70.31%]2025-11-03 09:57:50,388 - supervised_finetuning - INFO - Epoch 924 - supervised_loss/batch: 0.7020\n",
            "2025-11-03 09:57:50,388 - supervised_finetuning - INFO - Epoch 924 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:50,388 - supervised_finetuning - INFO - Epoch 924 - learning_rate: 0.0001\n",
            "Classifier Epoch 45/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7888, Acc=65.62%]2025-11-03 09:57:50,427 - supervised_finetuning - INFO - Epoch 934 - supervised_loss/batch: 0.7888\n",
            "2025-11-03 09:57:50,427 - supervised_finetuning - INFO - Epoch 934 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:50,427 - supervised_finetuning - INFO - Epoch 934 - learning_rate: 0.0001\n",
            "Classifier Epoch 45/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7396, Acc=85.71%]2025-11-03 09:57:50,464 - supervised_finetuning - INFO - Epoch 944 - supervised_loss/batch: 0.7396\n",
            "2025-11-03 09:57:50,464 - supervised_finetuning - INFO - Epoch 944 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:50,465 - supervised_finetuning - INFO - Epoch 944 - learning_rate: 0.0001\n",
            "Classifier Epoch 45/100: 100% 21/21 [00:00<00:00, 259.50it/s, Loss=0.7396, Acc=85.71%]\n",
            "2025-11-03 09:57:50,475 - supervised_finetuning - INFO - Epoch 45:\n",
            "2025-11-03 09:57:50,475 - supervised_finetuning - INFO -   Train Loss: 0.7431, Train Acc: 71.10%\n",
            "2025-11-03 09:57:50,475 - supervised_finetuning - INFO -   Train F1: 70.90%, Train Recall: 71.10%\n",
            "2025-11-03 09:57:50,475 - supervised_finetuning - INFO -   Train Precision: 71.41%\n",
            "2025-11-03 09:57:50,475 - supervised_finetuning - INFO - Epoch 44 - supervised_loss/epoch: 0.7431\n",
            "2025-11-03 09:57:50,476 - supervised_finetuning - INFO - Epoch 44 - supervised_accuracy/epoch: 71.0956\n",
            "2025-11-03 09:57:50,476 - supervised_finetuning - INFO - Epoch 44 - supervised_f1/epoch: 70.9015\n",
            "2025-11-03 09:57:50,476 - supervised_finetuning - INFO - Epoch 44 - supervised_recall/epoch: 71.0956\n",
            "2025-11-03 09:57:50,476 - supervised_finetuning - INFO - Epoch 44 - supervised_precision/epoch: 71.4075\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:50,992 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 71.10%\n",
            "Classifier Epoch 46/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5656, Acc=78.12%]2025-11-03 09:57:50,999 - supervised_finetuning - INFO - Epoch 945 - supervised_loss/batch: 0.5656\n",
            "2025-11-03 09:57:50,999 - supervised_finetuning - INFO - Epoch 945 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:51,000 - supervised_finetuning - INFO - Epoch 945 - learning_rate: 0.0001\n",
            "Classifier Epoch 46/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7810, Acc=70.31%]2025-11-03 09:57:51,042 - supervised_finetuning - INFO - Epoch 955 - supervised_loss/batch: 0.7810\n",
            "2025-11-03 09:57:51,042 - supervised_finetuning - INFO - Epoch 955 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:51,042 - supervised_finetuning - INFO - Epoch 955 - learning_rate: 0.0001\n",
            "Classifier Epoch 46/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5496, Acc=85.71%]2025-11-03 09:57:51,081 - supervised_finetuning - INFO - Epoch 965 - supervised_loss/batch: 0.5496\n",
            "2025-11-03 09:57:51,081 - supervised_finetuning - INFO - Epoch 965 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:51,081 - supervised_finetuning - INFO - Epoch 965 - learning_rate: 0.0001\n",
            "Classifier Epoch 46/100: 100% 21/21 [00:00<00:00, 237.49it/s, Loss=0.5496, Acc=85.71%]\n",
            "2025-11-03 09:57:51,091 - supervised_finetuning - INFO - Epoch 46:\n",
            "2025-11-03 09:57:51,091 - supervised_finetuning - INFO -   Train Loss: 0.7196, Train Acc: 72.11%\n",
            "2025-11-03 09:57:51,091 - supervised_finetuning - INFO -   Train F1: 72.04%, Train Recall: 72.11%\n",
            "2025-11-03 09:57:51,091 - supervised_finetuning - INFO -   Train Precision: 72.57%\n",
            "2025-11-03 09:57:51,091 - supervised_finetuning - INFO - Epoch 45 - supervised_loss/epoch: 0.7196\n",
            "2025-11-03 09:57:51,092 - supervised_finetuning - INFO - Epoch 45 - supervised_accuracy/epoch: 72.1057\n",
            "2025-11-03 09:57:51,092 - supervised_finetuning - INFO - Epoch 45 - supervised_f1/epoch: 72.0406\n",
            "2025-11-03 09:57:51,092 - supervised_finetuning - INFO - Epoch 45 - supervised_recall/epoch: 72.1057\n",
            "2025-11-03 09:57:51,092 - supervised_finetuning - INFO - Epoch 45 - supervised_precision/epoch: 72.5689\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:51,688 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 72.11%\n",
            "Classifier Epoch 47/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6084, Acc=76.56%]2025-11-03 09:57:51,694 - supervised_finetuning - INFO - Epoch 966 - supervised_loss/batch: 0.6084\n",
            "2025-11-03 09:57:51,694 - supervised_finetuning - INFO - Epoch 966 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:57:51,694 - supervised_finetuning - INFO - Epoch 966 - learning_rate: 0.0001\n",
            "Classifier Epoch 47/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6468, Acc=70.31%]2025-11-03 09:57:51,735 - supervised_finetuning - INFO - Epoch 976 - supervised_loss/batch: 0.6468\n",
            "2025-11-03 09:57:51,735 - supervised_finetuning - INFO - Epoch 976 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:51,736 - supervised_finetuning - INFO - Epoch 976 - learning_rate: 0.0001\n",
            "Classifier Epoch 47/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.2786, Acc=85.71%]2025-11-03 09:57:51,773 - supervised_finetuning - INFO - Epoch 986 - supervised_loss/batch: 0.2786\n",
            "2025-11-03 09:57:51,773 - supervised_finetuning - INFO - Epoch 986 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:51,773 - supervised_finetuning - INFO - Epoch 986 - learning_rate: 0.0001\n",
            "Classifier Epoch 47/100: 100% 21/21 [00:00<00:00, 248.15it/s, Loss=0.2786, Acc=85.71%]\n",
            "2025-11-03 09:57:51,783 - supervised_finetuning - INFO - Epoch 47:\n",
            "2025-11-03 09:57:51,783 - supervised_finetuning - INFO -   Train Loss: 0.7159, Train Acc: 70.86%\n",
            "2025-11-03 09:57:51,783 - supervised_finetuning - INFO -   Train F1: 70.74%, Train Recall: 70.86%\n",
            "2025-11-03 09:57:51,783 - supervised_finetuning - INFO -   Train Precision: 71.10%\n",
            "2025-11-03 09:57:51,783 - supervised_finetuning - INFO - Epoch 46 - supervised_loss/epoch: 0.7159\n",
            "2025-11-03 09:57:51,784 - supervised_finetuning - INFO - Epoch 46 - supervised_accuracy/epoch: 70.8625\n",
            "2025-11-03 09:57:51,784 - supervised_finetuning - INFO - Epoch 46 - supervised_f1/epoch: 70.7360\n",
            "2025-11-03 09:57:51,784 - supervised_finetuning - INFO - Epoch 46 - supervised_recall/epoch: 70.8625\n",
            "2025-11-03 09:57:51,786 - supervised_finetuning - INFO - Epoch 46 - supervised_precision/epoch: 71.1014\n",
            "Classifier Epoch 48/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7673, Acc=71.88%]2025-11-03 09:57:51,790 - supervised_finetuning - INFO - Epoch 987 - supervised_loss/batch: 0.7673\n",
            "2025-11-03 09:57:51,790 - supervised_finetuning - INFO - Epoch 987 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:51,790 - supervised_finetuning - INFO - Epoch 987 - learning_rate: 0.0001\n",
            "Classifier Epoch 48/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7785, Acc=67.19%]2025-11-03 09:57:51,828 - supervised_finetuning - INFO - Epoch 997 - supervised_loss/batch: 0.7785\n",
            "2025-11-03 09:57:51,828 - supervised_finetuning - INFO - Epoch 997 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:51,828 - supervised_finetuning - INFO - Epoch 997 - learning_rate: 0.0001\n",
            "Classifier Epoch 48/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3474, Acc=100.00%]2025-11-03 09:57:51,866 - supervised_finetuning - INFO - Epoch 1007 - supervised_loss/batch: 0.3474\n",
            "2025-11-03 09:57:51,866 - supervised_finetuning - INFO - Epoch 1007 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:51,866 - supervised_finetuning - INFO - Epoch 1007 - learning_rate: 0.0001\n",
            "Classifier Epoch 48/100: 100% 21/21 [00:00<00:00, 260.48it/s, Loss=0.3474, Acc=100.00%]\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO - Epoch 48:\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO -   Train Loss: 0.7224, Train Acc: 70.55%\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO -   Train F1: 70.26%, Train Recall: 70.55%\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO -   Train Precision: 71.44%\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO - Epoch 47 - supervised_loss/epoch: 0.7224\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO - Epoch 47 - supervised_accuracy/epoch: 70.5517\n",
            "2025-11-03 09:57:51,877 - supervised_finetuning - INFO - Epoch 47 - supervised_f1/epoch: 70.2587\n",
            "2025-11-03 09:57:51,878 - supervised_finetuning - INFO - Epoch 47 - supervised_recall/epoch: 70.5517\n",
            "2025-11-03 09:57:51,878 - supervised_finetuning - INFO - Epoch 47 - supervised_precision/epoch: 71.4396\n",
            "Classifier Epoch 49/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8639, Acc=68.75%]2025-11-03 09:57:51,882 - supervised_finetuning - INFO - Epoch 1008 - supervised_loss/batch: 0.8639\n",
            "2025-11-03 09:57:51,882 - supervised_finetuning - INFO - Epoch 1008 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:51,883 - supervised_finetuning - INFO - Epoch 1008 - learning_rate: 0.0001\n",
            "Classifier Epoch 49/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7098, Acc=68.75%]2025-11-03 09:57:51,919 - supervised_finetuning - INFO - Epoch 1018 - supervised_loss/batch: 0.7098\n",
            "2025-11-03 09:57:51,919 - supervised_finetuning - INFO - Epoch 1018 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:51,919 - supervised_finetuning - INFO - Epoch 1018 - learning_rate: 0.0001\n",
            "Classifier Epoch 49/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8975, Acc=71.43%]2025-11-03 09:57:51,960 - supervised_finetuning - INFO - Epoch 1028 - supervised_loss/batch: 0.8975\n",
            "2025-11-03 09:57:51,960 - supervised_finetuning - INFO - Epoch 1028 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:51,960 - supervised_finetuning - INFO - Epoch 1028 - learning_rate: 0.0001\n",
            "Classifier Epoch 49/100: 100% 21/21 [00:00<00:00, 255.88it/s, Loss=0.8975, Acc=71.43%]\n",
            "2025-11-03 09:57:51,970 - supervised_finetuning - INFO - Epoch 49:\n",
            "2025-11-03 09:57:51,970 - supervised_finetuning - INFO -   Train Loss: 0.7225, Train Acc: 71.33%\n",
            "2025-11-03 09:57:51,970 - supervised_finetuning - INFO -   Train F1: 71.18%, Train Recall: 71.33%\n",
            "2025-11-03 09:57:51,970 - supervised_finetuning - INFO -   Train Precision: 71.66%\n",
            "2025-11-03 09:57:51,971 - supervised_finetuning - INFO - Epoch 48 - supervised_loss/epoch: 0.7225\n",
            "2025-11-03 09:57:51,971 - supervised_finetuning - INFO - Epoch 48 - supervised_accuracy/epoch: 71.3287\n",
            "2025-11-03 09:57:51,971 - supervised_finetuning - INFO - Epoch 48 - supervised_f1/epoch: 71.1766\n",
            "2025-11-03 09:57:51,971 - supervised_finetuning - INFO - Epoch 48 - supervised_recall/epoch: 71.3287\n",
            "2025-11-03 09:57:51,972 - supervised_finetuning - INFO - Epoch 48 - supervised_precision/epoch: 71.6569\n",
            "Classifier Epoch 50/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6941, Acc=71.88%]2025-11-03 09:57:51,977 - supervised_finetuning - INFO - Epoch 1029 - supervised_loss/batch: 0.6941\n",
            "2025-11-03 09:57:51,977 - supervised_finetuning - INFO - Epoch 1029 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:51,977 - supervised_finetuning - INFO - Epoch 1029 - learning_rate: 0.0001\n",
            "Classifier Epoch 50/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8779, Acc=64.06%]2025-11-03 09:57:52,015 - supervised_finetuning - INFO - Epoch 1039 - supervised_loss/batch: 0.8779\n",
            "2025-11-03 09:57:52,015 - supervised_finetuning - INFO - Epoch 1039 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:52,015 - supervised_finetuning - INFO - Epoch 1039 - learning_rate: 0.0001\n",
            "Classifier Epoch 50/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3362, Acc=100.00%]2025-11-03 09:57:52,052 - supervised_finetuning - INFO - Epoch 1049 - supervised_loss/batch: 0.3362\n",
            "2025-11-03 09:57:52,052 - supervised_finetuning - INFO - Epoch 1049 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:52,052 - supervised_finetuning - INFO - Epoch 1049 - learning_rate: 0.0001\n",
            "Classifier Epoch 50/100: 100% 21/21 [00:00<00:00, 260.80it/s, Loss=0.3362, Acc=100.00%]\n",
            "2025-11-03 09:57:52,062 - supervised_finetuning - INFO - Epoch 50:\n",
            "2025-11-03 09:57:52,062 - supervised_finetuning - INFO -   Train Loss: 0.7017, Train Acc: 72.03%\n",
            "2025-11-03 09:57:52,062 - supervised_finetuning - INFO -   Train F1: 71.88%, Train Recall: 72.03%\n",
            "2025-11-03 09:57:52,062 - supervised_finetuning - INFO -   Train Precision: 72.07%\n",
            "2025-11-03 09:57:52,062 - supervised_finetuning - INFO - Epoch 49 - supervised_loss/epoch: 0.7017\n",
            "2025-11-03 09:57:52,062 - supervised_finetuning - INFO - Epoch 49 - supervised_accuracy/epoch: 72.0280\n",
            "2025-11-03 09:57:52,063 - supervised_finetuning - INFO - Epoch 49 - supervised_f1/epoch: 71.8797\n",
            "2025-11-03 09:57:52,063 - supervised_finetuning - INFO - Epoch 49 - supervised_recall/epoch: 72.0280\n",
            "2025-11-03 09:57:52,063 - supervised_finetuning - INFO - Epoch 49 - supervised_precision/epoch: 72.0670\n",
            "Classifier Epoch 51/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6292, Acc=81.25%]2025-11-03 09:57:52,068 - supervised_finetuning - INFO - Epoch 1050 - supervised_loss/batch: 0.6292\n",
            "2025-11-03 09:57:52,068 - supervised_finetuning - INFO - Epoch 1050 - supervised_accuracy/batch: 81.2500\n",
            "2025-11-03 09:57:52,068 - supervised_finetuning - INFO - Epoch 1050 - learning_rate: 0.0001\n",
            "Classifier Epoch 51/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9121, Acc=65.62%]2025-11-03 09:57:52,110 - supervised_finetuning - INFO - Epoch 1060 - supervised_loss/batch: 0.9121\n",
            "2025-11-03 09:57:52,110 - supervised_finetuning - INFO - Epoch 1060 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:52,110 - supervised_finetuning - INFO - Epoch 1060 - learning_rate: 0.0001\n",
            "Classifier Epoch 51/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3610, Acc=100.00%]2025-11-03 09:57:52,146 - supervised_finetuning - INFO - Epoch 1070 - supervised_loss/batch: 0.3610\n",
            "2025-11-03 09:57:52,147 - supervised_finetuning - INFO - Epoch 1070 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:52,147 - supervised_finetuning - INFO - Epoch 1070 - learning_rate: 0.0001\n",
            "Classifier Epoch 51/100: 100% 21/21 [00:00<00:00, 250.60it/s, Loss=0.3610, Acc=100.00%]\n",
            "2025-11-03 09:57:52,157 - supervised_finetuning - INFO - Epoch 51:\n",
            "2025-11-03 09:57:52,157 - supervised_finetuning - INFO -   Train Loss: 0.6983, Train Acc: 71.95%\n",
            "2025-11-03 09:57:52,157 - supervised_finetuning - INFO -   Train F1: 71.76%, Train Recall: 71.95%\n",
            "2025-11-03 09:57:52,157 - supervised_finetuning - INFO -   Train Precision: 72.42%\n",
            "2025-11-03 09:57:52,157 - supervised_finetuning - INFO - Epoch 50 - supervised_loss/epoch: 0.6983\n",
            "2025-11-03 09:57:52,158 - supervised_finetuning - INFO - Epoch 50 - supervised_accuracy/epoch: 71.9503\n",
            "2025-11-03 09:57:52,158 - supervised_finetuning - INFO - Epoch 50 - supervised_f1/epoch: 71.7609\n",
            "2025-11-03 09:57:52,158 - supervised_finetuning - INFO - Epoch 50 - supervised_recall/epoch: 71.9503\n",
            "2025-11-03 09:57:52,158 - supervised_finetuning - INFO - Epoch 50 - supervised_precision/epoch: 72.4202\n",
            "Classifier Epoch 52/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6872, Acc=70.31%]2025-11-03 09:57:52,163 - supervised_finetuning - INFO - Epoch 1071 - supervised_loss/batch: 0.6872\n",
            "2025-11-03 09:57:52,163 - supervised_finetuning - INFO - Epoch 1071 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:52,164 - supervised_finetuning - INFO - Epoch 1071 - learning_rate: 0.0001\n",
            "Classifier Epoch 52/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6909, Acc=73.44%]2025-11-03 09:57:52,200 - supervised_finetuning - INFO - Epoch 1081 - supervised_loss/batch: 0.6909\n",
            "2025-11-03 09:57:52,200 - supervised_finetuning - INFO - Epoch 1081 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:52,200 - supervised_finetuning - INFO - Epoch 1081 - learning_rate: 0.0001\n",
            "Classifier Epoch 52/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0548, Acc=57.14%]2025-11-03 09:57:52,257 - supervised_finetuning - INFO - Epoch 1091 - supervised_loss/batch: 1.0548\n",
            "2025-11-03 09:57:52,257 - supervised_finetuning - INFO - Epoch 1091 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:52,257 - supervised_finetuning - INFO - Epoch 1091 - learning_rate: 0.0001\n",
            "Classifier Epoch 52/100: 100% 21/21 [00:00<00:00, 213.42it/s, Loss=1.0548, Acc=57.14%]\n",
            "2025-11-03 09:57:52,272 - supervised_finetuning - INFO - Epoch 52:\n",
            "2025-11-03 09:57:52,272 - supervised_finetuning - INFO -   Train Loss: 0.7206, Train Acc: 72.11%\n",
            "2025-11-03 09:57:52,272 - supervised_finetuning - INFO -   Train F1: 71.93%, Train Recall: 72.11%\n",
            "2025-11-03 09:57:52,272 - supervised_finetuning - INFO -   Train Precision: 72.80%\n",
            "2025-11-03 09:57:52,272 - supervised_finetuning - INFO - Epoch 51 - supervised_loss/epoch: 0.7206\n",
            "2025-11-03 09:57:52,272 - supervised_finetuning - INFO - Epoch 51 - supervised_accuracy/epoch: 72.1057\n",
            "2025-11-03 09:57:52,273 - supervised_finetuning - INFO - Epoch 51 - supervised_f1/epoch: 71.9319\n",
            "2025-11-03 09:57:52,273 - supervised_finetuning - INFO - Epoch 51 - supervised_recall/epoch: 72.1057\n",
            "2025-11-03 09:57:52,273 - supervised_finetuning - INFO - Epoch 51 - supervised_precision/epoch: 72.8021\n",
            "Classifier Epoch 53/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7266, Acc=79.69%]2025-11-03 09:57:52,278 - supervised_finetuning - INFO - Epoch 1092 - supervised_loss/batch: 0.7266\n",
            "2025-11-03 09:57:52,278 - supervised_finetuning - INFO - Epoch 1092 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:57:52,278 - supervised_finetuning - INFO - Epoch 1092 - learning_rate: 0.0001\n",
            "Classifier Epoch 53/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8115, Acc=65.62%]2025-11-03 09:57:52,316 - supervised_finetuning - INFO - Epoch 1102 - supervised_loss/batch: 0.8115\n",
            "2025-11-03 09:57:52,317 - supervised_finetuning - INFO - Epoch 1102 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:52,317 - supervised_finetuning - INFO - Epoch 1102 - learning_rate: 0.0001\n",
            "Classifier Epoch 53/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4249, Acc=85.71%]2025-11-03 09:57:52,356 - supervised_finetuning - INFO - Epoch 1112 - supervised_loss/batch: 0.4249\n",
            "2025-11-03 09:57:52,356 - supervised_finetuning - INFO - Epoch 1112 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:52,357 - supervised_finetuning - INFO - Epoch 1112 - learning_rate: 0.0001\n",
            "Classifier Epoch 53/100: 100% 21/21 [00:00<00:00, 251.36it/s, Loss=0.4249, Acc=85.71%]\n",
            "2025-11-03 09:57:52,367 - supervised_finetuning - INFO - Epoch 53:\n",
            "2025-11-03 09:57:52,367 - supervised_finetuning - INFO -   Train Loss: 0.6980, Train Acc: 72.34%\n",
            "2025-11-03 09:57:52,367 - supervised_finetuning - INFO -   Train F1: 72.24%, Train Recall: 72.34%\n",
            "2025-11-03 09:57:52,367 - supervised_finetuning - INFO -   Train Precision: 72.41%\n",
            "2025-11-03 09:57:52,367 - supervised_finetuning - INFO - Epoch 52 - supervised_loss/epoch: 0.6980\n",
            "2025-11-03 09:57:52,368 - supervised_finetuning - INFO - Epoch 52 - supervised_accuracy/epoch: 72.3388\n",
            "2025-11-03 09:57:52,368 - supervised_finetuning - INFO - Epoch 52 - supervised_f1/epoch: 72.2418\n",
            "2025-11-03 09:57:52,368 - supervised_finetuning - INFO - Epoch 52 - supervised_recall/epoch: 72.3388\n",
            "2025-11-03 09:57:52,368 - supervised_finetuning - INFO - Epoch 52 - supervised_precision/epoch: 72.4137\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:52,836 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 72.34%\n",
            "Classifier Epoch 54/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9267, Acc=64.06%]2025-11-03 09:57:52,844 - supervised_finetuning - INFO - Epoch 1113 - supervised_loss/batch: 0.9267\n",
            "2025-11-03 09:57:52,844 - supervised_finetuning - INFO - Epoch 1113 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:52,844 - supervised_finetuning - INFO - Epoch 1113 - learning_rate: 0.0001\n",
            "Classifier Epoch 54/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6608, Acc=70.31%]2025-11-03 09:57:52,887 - supervised_finetuning - INFO - Epoch 1123 - supervised_loss/batch: 0.6608\n",
            "2025-11-03 09:57:52,887 - supervised_finetuning - INFO - Epoch 1123 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:52,887 - supervised_finetuning - INFO - Epoch 1123 - learning_rate: 0.0001\n",
            "Classifier Epoch 54/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5667, Acc=71.43%]2025-11-03 09:57:52,923 - supervised_finetuning - INFO - Epoch 1133 - supervised_loss/batch: 0.5667\n",
            "2025-11-03 09:57:52,923 - supervised_finetuning - INFO - Epoch 1133 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:52,924 - supervised_finetuning - INFO - Epoch 1133 - learning_rate: 0.0001\n",
            "Classifier Epoch 54/100: 100% 21/21 [00:00<00:00, 240.16it/s, Loss=0.5667, Acc=71.43%]\n",
            "2025-11-03 09:57:52,933 - supervised_finetuning - INFO - Epoch 54:\n",
            "2025-11-03 09:57:52,933 - supervised_finetuning - INFO -   Train Loss: 0.6961, Train Acc: 71.17%\n",
            "2025-11-03 09:57:52,933 - supervised_finetuning - INFO -   Train F1: 70.93%, Train Recall: 71.17%\n",
            "2025-11-03 09:57:52,934 - supervised_finetuning - INFO -   Train Precision: 71.85%\n",
            "2025-11-03 09:57:52,934 - supervised_finetuning - INFO - Epoch 53 - supervised_loss/epoch: 0.6961\n",
            "2025-11-03 09:57:52,934 - supervised_finetuning - INFO - Epoch 53 - supervised_accuracy/epoch: 71.1733\n",
            "2025-11-03 09:57:52,934 - supervised_finetuning - INFO - Epoch 53 - supervised_f1/epoch: 70.9256\n",
            "2025-11-03 09:57:52,934 - supervised_finetuning - INFO - Epoch 53 - supervised_recall/epoch: 71.1733\n",
            "2025-11-03 09:57:52,934 - supervised_finetuning - INFO - Epoch 53 - supervised_precision/epoch: 71.8464\n",
            "Classifier Epoch 55/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7987, Acc=67.19%]2025-11-03 09:57:52,939 - supervised_finetuning - INFO - Epoch 1134 - supervised_loss/batch: 0.7987\n",
            "2025-11-03 09:57:52,939 - supervised_finetuning - INFO - Epoch 1134 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:52,939 - supervised_finetuning - INFO - Epoch 1134 - learning_rate: 0.0001\n",
            "Classifier Epoch 55/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9295, Acc=62.50%]2025-11-03 09:57:52,974 - supervised_finetuning - INFO - Epoch 1144 - supervised_loss/batch: 0.9295\n",
            "2025-11-03 09:57:52,975 - supervised_finetuning - INFO - Epoch 1144 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:52,975 - supervised_finetuning - INFO - Epoch 1144 - learning_rate: 0.0001\n",
            "Classifier Epoch 55/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8747, Acc=57.14%]2025-11-03 09:57:53,011 - supervised_finetuning - INFO - Epoch 1154 - supervised_loss/batch: 0.8747\n",
            "2025-11-03 09:57:53,011 - supervised_finetuning - INFO - Epoch 1154 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:53,011 - supervised_finetuning - INFO - Epoch 1154 - learning_rate: 0.0001\n",
            "Classifier Epoch 55/100: 100% 21/21 [00:00<00:00, 273.69it/s, Loss=0.8747, Acc=57.14%]\n",
            "2025-11-03 09:57:53,021 - supervised_finetuning - INFO - Epoch 55:\n",
            "2025-11-03 09:57:53,021 - supervised_finetuning - INFO -   Train Loss: 0.7285, Train Acc: 71.64%\n",
            "2025-11-03 09:57:53,021 - supervised_finetuning - INFO -   Train F1: 71.59%, Train Recall: 71.64%\n",
            "2025-11-03 09:57:53,021 - supervised_finetuning - INFO -   Train Precision: 71.84%\n",
            "2025-11-03 09:57:53,021 - supervised_finetuning - INFO - Epoch 54 - supervised_loss/epoch: 0.7285\n",
            "2025-11-03 09:57:53,022 - supervised_finetuning - INFO - Epoch 54 - supervised_accuracy/epoch: 71.6395\n",
            "2025-11-03 09:57:53,022 - supervised_finetuning - INFO - Epoch 54 - supervised_f1/epoch: 71.5948\n",
            "2025-11-03 09:57:53,022 - supervised_finetuning - INFO - Epoch 54 - supervised_recall/epoch: 71.6395\n",
            "2025-11-03 09:57:53,022 - supervised_finetuning - INFO - Epoch 54 - supervised_precision/epoch: 71.8373\n",
            "Classifier Epoch 56/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8709, Acc=62.50%]2025-11-03 09:57:53,026 - supervised_finetuning - INFO - Epoch 1155 - supervised_loss/batch: 0.8709\n",
            "2025-11-03 09:57:53,027 - supervised_finetuning - INFO - Epoch 1155 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:53,027 - supervised_finetuning - INFO - Epoch 1155 - learning_rate: 0.0001\n",
            "Classifier Epoch 56/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6129, Acc=76.56%]2025-11-03 09:57:53,068 - supervised_finetuning - INFO - Epoch 1165 - supervised_loss/batch: 0.6129\n",
            "2025-11-03 09:57:53,068 - supervised_finetuning - INFO - Epoch 1165 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:57:53,068 - supervised_finetuning - INFO - Epoch 1165 - learning_rate: 0.0001\n",
            "Classifier Epoch 56/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.2346, Acc=42.86%]2025-11-03 09:57:53,104 - supervised_finetuning - INFO - Epoch 1175 - supervised_loss/batch: 1.2346\n",
            "2025-11-03 09:57:53,104 - supervised_finetuning - INFO - Epoch 1175 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:53,104 - supervised_finetuning - INFO - Epoch 1175 - learning_rate: 0.0001\n",
            "Classifier Epoch 56/100: 100% 21/21 [00:00<00:00, 257.14it/s, Loss=1.2346, Acc=42.86%]\n",
            "2025-11-03 09:57:53,116 - supervised_finetuning - INFO - Epoch 56:\n",
            "2025-11-03 09:57:53,116 - supervised_finetuning - INFO -   Train Loss: 0.7725, Train Acc: 70.24%\n",
            "2025-11-03 09:57:53,116 - supervised_finetuning - INFO -   Train F1: 69.83%, Train Recall: 70.24%\n",
            "2025-11-03 09:57:53,116 - supervised_finetuning - INFO -   Train Precision: 70.31%\n",
            "2025-11-03 09:57:53,116 - supervised_finetuning - INFO - Epoch 55 - supervised_loss/epoch: 0.7725\n",
            "2025-11-03 09:57:53,116 - supervised_finetuning - INFO - Epoch 55 - supervised_accuracy/epoch: 70.2409\n",
            "2025-11-03 09:57:53,117 - supervised_finetuning - INFO - Epoch 55 - supervised_f1/epoch: 69.8285\n",
            "2025-11-03 09:57:53,117 - supervised_finetuning - INFO - Epoch 55 - supervised_recall/epoch: 70.2409\n",
            "2025-11-03 09:57:53,117 - supervised_finetuning - INFO - Epoch 55 - supervised_precision/epoch: 70.3129\n",
            "Classifier Epoch 57/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7034, Acc=71.88%]2025-11-03 09:57:53,121 - supervised_finetuning - INFO - Epoch 1176 - supervised_loss/batch: 0.7034\n",
            "2025-11-03 09:57:53,121 - supervised_finetuning - INFO - Epoch 1176 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:53,122 - supervised_finetuning - INFO - Epoch 1176 - learning_rate: 0.0001\n",
            "Classifier Epoch 57/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5555, Acc=78.12%]2025-11-03 09:57:53,157 - supervised_finetuning - INFO - Epoch 1186 - supervised_loss/batch: 0.5555\n",
            "2025-11-03 09:57:53,157 - supervised_finetuning - INFO - Epoch 1186 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:53,158 - supervised_finetuning - INFO - Epoch 1186 - learning_rate: 0.0001\n",
            "Classifier Epoch 57/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5774, Acc=85.71%]2025-11-03 09:57:53,193 - supervised_finetuning - INFO - Epoch 1196 - supervised_loss/batch: 0.5774\n",
            "2025-11-03 09:57:53,193 - supervised_finetuning - INFO - Epoch 1196 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:53,194 - supervised_finetuning - INFO - Epoch 1196 - learning_rate: 0.0001\n",
            "Classifier Epoch 57/100: 100% 21/21 [00:00<00:00, 274.43it/s, Loss=0.5774, Acc=85.71%]\n",
            "2025-11-03 09:57:53,204 - supervised_finetuning - INFO - Epoch 57:\n",
            "2025-11-03 09:57:53,204 - supervised_finetuning - INFO -   Train Loss: 0.7398, Train Acc: 70.63%\n",
            "2025-11-03 09:57:53,204 - supervised_finetuning - INFO -   Train F1: 70.45%, Train Recall: 70.63%\n",
            "2025-11-03 09:57:53,205 - supervised_finetuning - INFO -   Train Precision: 71.03%\n",
            "2025-11-03 09:57:53,205 - supervised_finetuning - INFO - Epoch 56 - supervised_loss/epoch: 0.7398\n",
            "2025-11-03 09:57:53,205 - supervised_finetuning - INFO - Epoch 56 - supervised_accuracy/epoch: 70.6294\n",
            "2025-11-03 09:57:53,205 - supervised_finetuning - INFO - Epoch 56 - supervised_f1/epoch: 70.4466\n",
            "2025-11-03 09:57:53,205 - supervised_finetuning - INFO - Epoch 56 - supervised_recall/epoch: 70.6294\n",
            "2025-11-03 09:57:53,205 - supervised_finetuning - INFO - Epoch 56 - supervised_precision/epoch: 71.0302\n",
            "Classifier Epoch 58/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7342, Acc=68.75%]2025-11-03 09:57:53,210 - supervised_finetuning - INFO - Epoch 1197 - supervised_loss/batch: 0.7342\n",
            "2025-11-03 09:57:53,210 - supervised_finetuning - INFO - Epoch 1197 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:57:53,210 - supervised_finetuning - INFO - Epoch 1197 - learning_rate: 0.0001\n",
            "Classifier Epoch 58/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7139, Acc=67.19%]2025-11-03 09:57:53,254 - supervised_finetuning - INFO - Epoch 1207 - supervised_loss/batch: 0.7139\n",
            "2025-11-03 09:57:53,256 - supervised_finetuning - INFO - Epoch 1207 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:53,256 - supervised_finetuning - INFO - Epoch 1207 - learning_rate: 0.0001\n",
            "Classifier Epoch 58/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4305, Acc=100.00%]2025-11-03 09:57:53,301 - supervised_finetuning - INFO - Epoch 1217 - supervised_loss/batch: 0.4305\n",
            "2025-11-03 09:57:53,301 - supervised_finetuning - INFO - Epoch 1217 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:53,301 - supervised_finetuning - INFO - Epoch 1217 - learning_rate: 0.0001\n",
            "Classifier Epoch 58/100: 100% 21/21 [00:00<00:00, 218.06it/s, Loss=0.4305, Acc=100.00%]\n",
            "2025-11-03 09:57:53,312 - supervised_finetuning - INFO - Epoch 58:\n",
            "2025-11-03 09:57:53,312 - supervised_finetuning - INFO -   Train Loss: 0.7337, Train Acc: 70.09%\n",
            "2025-11-03 09:57:53,312 - supervised_finetuning - INFO -   Train F1: 69.71%, Train Recall: 70.09%\n",
            "2025-11-03 09:57:53,312 - supervised_finetuning - INFO -   Train Precision: 70.14%\n",
            "2025-11-03 09:57:53,312 - supervised_finetuning - INFO - Epoch 57 - supervised_loss/epoch: 0.7337\n",
            "2025-11-03 09:57:53,312 - supervised_finetuning - INFO - Epoch 57 - supervised_accuracy/epoch: 70.0855\n",
            "2025-11-03 09:57:53,313 - supervised_finetuning - INFO - Epoch 57 - supervised_f1/epoch: 69.7059\n",
            "2025-11-03 09:57:53,313 - supervised_finetuning - INFO - Epoch 57 - supervised_recall/epoch: 70.0855\n",
            "2025-11-03 09:57:53,313 - supervised_finetuning - INFO - Epoch 57 - supervised_precision/epoch: 70.1447\n",
            "Classifier Epoch 59/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6038, Acc=73.44%]2025-11-03 09:57:53,317 - supervised_finetuning - INFO - Epoch 1218 - supervised_loss/batch: 0.6038\n",
            "2025-11-03 09:57:53,318 - supervised_finetuning - INFO - Epoch 1218 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:53,318 - supervised_finetuning - INFO - Epoch 1218 - learning_rate: 0.0001\n",
            "Classifier Epoch 59/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6812, Acc=76.56%]2025-11-03 09:57:53,357 - supervised_finetuning - INFO - Epoch 1228 - supervised_loss/batch: 0.6812\n",
            "2025-11-03 09:57:53,357 - supervised_finetuning - INFO - Epoch 1228 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:57:53,357 - supervised_finetuning - INFO - Epoch 1228 - learning_rate: 0.0001\n",
            "Classifier Epoch 59/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4370, Acc=100.00%]2025-11-03 09:57:53,393 - supervised_finetuning - INFO - Epoch 1238 - supervised_loss/batch: 0.4370\n",
            "2025-11-03 09:57:53,394 - supervised_finetuning - INFO - Epoch 1238 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:53,394 - supervised_finetuning - INFO - Epoch 1238 - learning_rate: 0.0001\n",
            "Classifier Epoch 59/100: 100% 21/21 [00:00<00:00, 259.44it/s, Loss=0.4370, Acc=100.00%]\n",
            "2025-11-03 09:57:53,404 - supervised_finetuning - INFO - Epoch 59:\n",
            "2025-11-03 09:57:53,404 - supervised_finetuning - INFO -   Train Loss: 0.6796, Train Acc: 73.12%\n",
            "2025-11-03 09:57:53,404 - supervised_finetuning - INFO -   Train F1: 72.90%, Train Recall: 73.12%\n",
            "2025-11-03 09:57:53,404 - supervised_finetuning - INFO -   Train Precision: 73.36%\n",
            "2025-11-03 09:57:53,404 - supervised_finetuning - INFO - Epoch 58 - supervised_loss/epoch: 0.6796\n",
            "2025-11-03 09:57:53,404 - supervised_finetuning - INFO - Epoch 58 - supervised_accuracy/epoch: 73.1158\n",
            "2025-11-03 09:57:53,405 - supervised_finetuning - INFO - Epoch 58 - supervised_f1/epoch: 72.9011\n",
            "2025-11-03 09:57:53,405 - supervised_finetuning - INFO - Epoch 58 - supervised_recall/epoch: 73.1158\n",
            "2025-11-03 09:57:53,405 - supervised_finetuning - INFO - Epoch 58 - supervised_precision/epoch: 73.3552\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:53,834 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 73.12%\n",
            "Classifier Epoch 60/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5976, Acc=78.12%]2025-11-03 09:57:53,839 - supervised_finetuning - INFO - Epoch 1239 - supervised_loss/batch: 0.5976\n",
            "2025-11-03 09:57:53,840 - supervised_finetuning - INFO - Epoch 1239 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:53,840 - supervised_finetuning - INFO - Epoch 1239 - learning_rate: 0.0001\n",
            "Classifier Epoch 60/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5793, Acc=82.81%]2025-11-03 09:57:53,878 - supervised_finetuning - INFO - Epoch 1249 - supervised_loss/batch: 0.5793\n",
            "2025-11-03 09:57:53,879 - supervised_finetuning - INFO - Epoch 1249 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:57:53,879 - supervised_finetuning - INFO - Epoch 1249 - learning_rate: 0.0001\n",
            "Classifier Epoch 60/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.5064, Acc=42.86%]2025-11-03 09:57:53,913 - supervised_finetuning - INFO - Epoch 1259 - supervised_loss/batch: 1.5064\n",
            "2025-11-03 09:57:53,913 - supervised_finetuning - INFO - Epoch 1259 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:57:53,914 - supervised_finetuning - INFO - Epoch 1259 - learning_rate: 0.0001\n",
            "Classifier Epoch 60/100: 100% 21/21 [00:00<00:00, 264.68it/s, Loss=1.5064, Acc=42.86%]\n",
            "2025-11-03 09:57:53,924 - supervised_finetuning - INFO - Epoch 60:\n",
            "2025-11-03 09:57:53,924 - supervised_finetuning - INFO -   Train Loss: 0.7236, Train Acc: 73.12%\n",
            "2025-11-03 09:57:53,924 - supervised_finetuning - INFO -   Train F1: 72.96%, Train Recall: 73.12%\n",
            "2025-11-03 09:57:53,924 - supervised_finetuning - INFO -   Train Precision: 73.35%\n",
            "2025-11-03 09:57:53,924 - supervised_finetuning - INFO - Epoch 59 - supervised_loss/epoch: 0.7236\n",
            "2025-11-03 09:57:53,925 - supervised_finetuning - INFO - Epoch 59 - supervised_accuracy/epoch: 73.1158\n",
            "2025-11-03 09:57:53,925 - supervised_finetuning - INFO - Epoch 59 - supervised_f1/epoch: 72.9572\n",
            "2025-11-03 09:57:53,925 - supervised_finetuning - INFO - Epoch 59 - supervised_recall/epoch: 73.1158\n",
            "2025-11-03 09:57:53,925 - supervised_finetuning - INFO - Epoch 59 - supervised_precision/epoch: 73.3511\n",
            "Classifier Epoch 61/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8976, Acc=67.19%]2025-11-03 09:57:53,929 - supervised_finetuning - INFO - Epoch 1260 - supervised_loss/batch: 0.8976\n",
            "2025-11-03 09:57:53,929 - supervised_finetuning - INFO - Epoch 1260 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:53,930 - supervised_finetuning - INFO - Epoch 1260 - learning_rate: 0.0001\n",
            "Classifier Epoch 61/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6059, Acc=79.69%]2025-11-03 09:57:53,965 - supervised_finetuning - INFO - Epoch 1270 - supervised_loss/batch: 0.6059\n",
            "2025-11-03 09:57:53,965 - supervised_finetuning - INFO - Epoch 1270 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:57:53,966 - supervised_finetuning - INFO - Epoch 1270 - learning_rate: 0.0001\n",
            "Classifier Epoch 61/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.2725, Acc=85.71%]2025-11-03 09:57:54,008 - supervised_finetuning - INFO - Epoch 1280 - supervised_loss/batch: 0.2725\n",
            "2025-11-03 09:57:54,008 - supervised_finetuning - INFO - Epoch 1280 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:54,008 - supervised_finetuning - INFO - Epoch 1280 - learning_rate: 0.0001\n",
            "Classifier Epoch 61/100: 100% 21/21 [00:00<00:00, 252.39it/s, Loss=0.2725, Acc=85.71%]\n",
            "2025-11-03 09:57:54,022 - supervised_finetuning - INFO - Epoch 61:\n",
            "2025-11-03 09:57:54,022 - supervised_finetuning - INFO -   Train Loss: 0.6707, Train Acc: 72.73%\n",
            "2025-11-03 09:57:54,023 - supervised_finetuning - INFO -   Train F1: 72.53%, Train Recall: 72.73%\n",
            "2025-11-03 09:57:54,023 - supervised_finetuning - INFO -   Train Precision: 73.34%\n",
            "2025-11-03 09:57:54,023 - supervised_finetuning - INFO - Epoch 60 - supervised_loss/epoch: 0.6707\n",
            "2025-11-03 09:57:54,023 - supervised_finetuning - INFO - Epoch 60 - supervised_accuracy/epoch: 72.7273\n",
            "2025-11-03 09:57:54,023 - supervised_finetuning - INFO - Epoch 60 - supervised_f1/epoch: 72.5317\n",
            "2025-11-03 09:57:54,023 - supervised_finetuning - INFO - Epoch 60 - supervised_recall/epoch: 72.7273\n",
            "2025-11-03 09:57:54,024 - supervised_finetuning - INFO - Epoch 60 - supervised_precision/epoch: 73.3355\n",
            "Classifier Epoch 62/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6418, Acc=73.44%]2025-11-03 09:57:54,028 - supervised_finetuning - INFO - Epoch 1281 - supervised_loss/batch: 0.6418\n",
            "2025-11-03 09:57:54,028 - supervised_finetuning - INFO - Epoch 1281 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:54,029 - supervised_finetuning - INFO - Epoch 1281 - learning_rate: 0.0001\n",
            "Classifier Epoch 62/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6244, Acc=78.12%]2025-11-03 09:57:54,066 - supervised_finetuning - INFO - Epoch 1291 - supervised_loss/batch: 0.6244\n",
            "2025-11-03 09:57:54,066 - supervised_finetuning - INFO - Epoch 1291 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:54,066 - supervised_finetuning - INFO - Epoch 1291 - learning_rate: 0.0001\n",
            "Classifier Epoch 62/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.2471, Acc=85.71%]2025-11-03 09:57:54,105 - supervised_finetuning - INFO - Epoch 1301 - supervised_loss/batch: 0.2471\n",
            "2025-11-03 09:57:54,105 - supervised_finetuning - INFO - Epoch 1301 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:54,105 - supervised_finetuning - INFO - Epoch 1301 - learning_rate: 0.0001\n",
            "Classifier Epoch 62/100: 100% 21/21 [00:00<00:00, 258.11it/s, Loss=0.2471, Acc=85.71%]\n",
            "2025-11-03 09:57:54,116 - supervised_finetuning - INFO - Epoch 62:\n",
            "2025-11-03 09:57:54,116 - supervised_finetuning - INFO -   Train Loss: 0.6531, Train Acc: 73.58%\n",
            "2025-11-03 09:57:54,116 - supervised_finetuning - INFO -   Train F1: 73.56%, Train Recall: 73.58%\n",
            "2025-11-03 09:57:54,116 - supervised_finetuning - INFO -   Train Precision: 74.16%\n",
            "2025-11-03 09:57:54,116 - supervised_finetuning - INFO - Epoch 61 - supervised_loss/epoch: 0.6531\n",
            "2025-11-03 09:57:54,117 - supervised_finetuning - INFO - Epoch 61 - supervised_accuracy/epoch: 73.5820\n",
            "2025-11-03 09:57:54,117 - supervised_finetuning - INFO - Epoch 61 - supervised_f1/epoch: 73.5605\n",
            "2025-11-03 09:57:54,117 - supervised_finetuning - INFO - Epoch 61 - supervised_recall/epoch: 73.5820\n",
            "2025-11-03 09:57:54,117 - supervised_finetuning - INFO - Epoch 61 - supervised_precision/epoch: 74.1551\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:57,378 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 73.58%\n",
            "Classifier Epoch 63/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6359, Acc=73.44%]2025-11-03 09:57:57,388 - supervised_finetuning - INFO - Epoch 1302 - supervised_loss/batch: 0.6359\n",
            "2025-11-03 09:57:57,388 - supervised_finetuning - INFO - Epoch 1302 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:57,388 - supervised_finetuning - INFO - Epoch 1302 - learning_rate: 0.0001\n",
            "Classifier Epoch 63/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6548, Acc=70.31%]2025-11-03 09:57:57,430 - supervised_finetuning - INFO - Epoch 1312 - supervised_loss/batch: 0.6548\n",
            "2025-11-03 09:57:57,431 - supervised_finetuning - INFO - Epoch 1312 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:57,431 - supervised_finetuning - INFO - Epoch 1312 - learning_rate: 0.0001\n",
            "Classifier Epoch 63/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3195, Acc=100.00%]2025-11-03 09:57:57,467 - supervised_finetuning - INFO - Epoch 1322 - supervised_loss/batch: 0.3195\n",
            "2025-11-03 09:57:57,467 - supervised_finetuning - INFO - Epoch 1322 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:57,467 - supervised_finetuning - INFO - Epoch 1322 - learning_rate: 0.0001\n",
            "Classifier Epoch 63/100: 100% 21/21 [00:00<00:00, 236.99it/s, Loss=0.3195, Acc=100.00%]\n",
            "2025-11-03 09:57:57,478 - supervised_finetuning - INFO - Epoch 63:\n",
            "2025-11-03 09:57:57,478 - supervised_finetuning - INFO -   Train Loss: 0.6551, Train Acc: 73.58%\n",
            "2025-11-03 09:57:57,478 - supervised_finetuning - INFO -   Train F1: 73.37%, Train Recall: 73.58%\n",
            "2025-11-03 09:57:57,478 - supervised_finetuning - INFO -   Train Precision: 73.68%\n",
            "2025-11-03 09:57:57,478 - supervised_finetuning - INFO - Epoch 62 - supervised_loss/epoch: 0.6551\n",
            "2025-11-03 09:57:57,478 - supervised_finetuning - INFO - Epoch 62 - supervised_accuracy/epoch: 73.5820\n",
            "2025-11-03 09:57:57,479 - supervised_finetuning - INFO - Epoch 62 - supervised_f1/epoch: 73.3712\n",
            "2025-11-03 09:57:57,479 - supervised_finetuning - INFO - Epoch 62 - supervised_recall/epoch: 73.5820\n",
            "2025-11-03 09:57:57,479 - supervised_finetuning - INFO - Epoch 62 - supervised_precision/epoch: 73.6783\n",
            "Classifier Epoch 64/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5880, Acc=71.88%]2025-11-03 09:57:57,483 - supervised_finetuning - INFO - Epoch 1323 - supervised_loss/batch: 0.5880\n",
            "2025-11-03 09:57:57,484 - supervised_finetuning - INFO - Epoch 1323 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:57,484 - supervised_finetuning - INFO - Epoch 1323 - learning_rate: 0.0001\n",
            "Classifier Epoch 64/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8079, Acc=62.50%]2025-11-03 09:57:57,520 - supervised_finetuning - INFO - Epoch 1333 - supervised_loss/batch: 0.8079\n",
            "2025-11-03 09:57:57,521 - supervised_finetuning - INFO - Epoch 1333 - supervised_accuracy/batch: 62.5000\n",
            "2025-11-03 09:57:57,521 - supervised_finetuning - INFO - Epoch 1333 - learning_rate: 0.0001\n",
            "Classifier Epoch 64/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8500, Acc=71.43%]2025-11-03 09:57:57,558 - supervised_finetuning - INFO - Epoch 1343 - supervised_loss/batch: 0.8500\n",
            "2025-11-03 09:57:57,558 - supervised_finetuning - INFO - Epoch 1343 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:57,558 - supervised_finetuning - INFO - Epoch 1343 - learning_rate: 0.0001\n",
            "Classifier Epoch 64/100: 100% 21/21 [00:00<00:00, 265.29it/s, Loss=0.8500, Acc=71.43%]\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO - Epoch 64:\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO -   Train Loss: 0.6812, Train Acc: 73.12%\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO -   Train F1: 72.96%, Train Recall: 73.12%\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO -   Train Precision: 73.48%\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO - Epoch 63 - supervised_loss/epoch: 0.6812\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO - Epoch 63 - supervised_accuracy/epoch: 73.1158\n",
            "2025-11-03 09:57:57,569 - supervised_finetuning - INFO - Epoch 63 - supervised_f1/epoch: 72.9580\n",
            "2025-11-03 09:57:57,570 - supervised_finetuning - INFO - Epoch 63 - supervised_recall/epoch: 73.1158\n",
            "2025-11-03 09:57:57,570 - supervised_finetuning - INFO - Epoch 63 - supervised_precision/epoch: 73.4794\n",
            "Classifier Epoch 65/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6228, Acc=73.44%]2025-11-03 09:57:57,575 - supervised_finetuning - INFO - Epoch 1344 - supervised_loss/batch: 0.6228\n",
            "2025-11-03 09:57:57,575 - supervised_finetuning - INFO - Epoch 1344 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:57,575 - supervised_finetuning - INFO - Epoch 1344 - learning_rate: 0.0001\n",
            "Classifier Epoch 65/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7781, Acc=64.06%]2025-11-03 09:57:57,611 - supervised_finetuning - INFO - Epoch 1354 - supervised_loss/batch: 0.7781\n",
            "2025-11-03 09:57:57,611 - supervised_finetuning - INFO - Epoch 1354 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:57,612 - supervised_finetuning - INFO - Epoch 1354 - learning_rate: 0.0001\n",
            "Classifier Epoch 65/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.9342, Acc=57.14%]2025-11-03 09:57:57,648 - supervised_finetuning - INFO - Epoch 1364 - supervised_loss/batch: 0.9342\n",
            "2025-11-03 09:57:57,648 - supervised_finetuning - INFO - Epoch 1364 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:57,649 - supervised_finetuning - INFO - Epoch 1364 - learning_rate: 0.0001\n",
            "Classifier Epoch 65/100: 100% 21/21 [00:00<00:00, 267.19it/s, Loss=0.9342, Acc=57.14%]\n",
            "2025-11-03 09:57:57,659 - supervised_finetuning - INFO - Epoch 65:\n",
            "2025-11-03 09:57:57,659 - supervised_finetuning - INFO -   Train Loss: 0.6867, Train Acc: 74.05%\n",
            "2025-11-03 09:57:57,659 - supervised_finetuning - INFO -   Train F1: 73.86%, Train Recall: 74.05%\n",
            "2025-11-03 09:57:57,659 - supervised_finetuning - INFO -   Train Precision: 74.46%\n",
            "2025-11-03 09:57:57,660 - supervised_finetuning - INFO - Epoch 64 - supervised_loss/epoch: 0.6867\n",
            "2025-11-03 09:57:57,660 - supervised_finetuning - INFO - Epoch 64 - supervised_accuracy/epoch: 74.0482\n",
            "2025-11-03 09:57:57,660 - supervised_finetuning - INFO - Epoch 64 - supervised_f1/epoch: 73.8629\n",
            "2025-11-03 09:57:57,660 - supervised_finetuning - INFO - Epoch 64 - supervised_recall/epoch: 74.0482\n",
            "2025-11-03 09:57:57,660 - supervised_finetuning - INFO - Epoch 64 - supervised_precision/epoch: 74.4593\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:58,090 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 74.05%\n",
            "Classifier Epoch 66/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8815, Acc=64.06%]2025-11-03 09:57:58,097 - supervised_finetuning - INFO - Epoch 1365 - supervised_loss/batch: 0.8815\n",
            "2025-11-03 09:57:58,098 - supervised_finetuning - INFO - Epoch 1365 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:57:58,098 - supervised_finetuning - INFO - Epoch 1365 - learning_rate: 0.0001\n",
            "Classifier Epoch 66/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4620, Acc=84.38%]2025-11-03 09:57:58,135 - supervised_finetuning - INFO - Epoch 1375 - supervised_loss/batch: 0.4620\n",
            "2025-11-03 09:57:58,135 - supervised_finetuning - INFO - Epoch 1375 - supervised_accuracy/batch: 84.3750\n",
            "2025-11-03 09:57:58,135 - supervised_finetuning - INFO - Epoch 1375 - learning_rate: 0.0001\n",
            "Classifier Epoch 66/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6962, Acc=71.43%]2025-11-03 09:57:58,172 - supervised_finetuning - INFO - Epoch 1385 - supervised_loss/batch: 0.6962\n",
            "2025-11-03 09:57:58,172 - supervised_finetuning - INFO - Epoch 1385 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:58,173 - supervised_finetuning - INFO - Epoch 1385 - learning_rate: 0.0001\n",
            "Classifier Epoch 66/100: 100% 21/21 [00:00<00:00, 254.88it/s, Loss=0.6962, Acc=71.43%]\n",
            "2025-11-03 09:57:58,183 - supervised_finetuning - INFO - Epoch 66:\n",
            "2025-11-03 09:57:58,183 - supervised_finetuning - INFO -   Train Loss: 0.7033, Train Acc: 71.95%\n",
            "2025-11-03 09:57:58,183 - supervised_finetuning - INFO -   Train F1: 71.87%, Train Recall: 71.95%\n",
            "2025-11-03 09:57:58,183 - supervised_finetuning - INFO -   Train Precision: 72.46%\n",
            "2025-11-03 09:57:58,184 - supervised_finetuning - INFO - Epoch 65 - supervised_loss/epoch: 0.7033\n",
            "2025-11-03 09:57:58,184 - supervised_finetuning - INFO - Epoch 65 - supervised_accuracy/epoch: 71.9503\n",
            "2025-11-03 09:57:58,184 - supervised_finetuning - INFO - Epoch 65 - supervised_f1/epoch: 71.8683\n",
            "2025-11-03 09:57:58,184 - supervised_finetuning - INFO - Epoch 65 - supervised_recall/epoch: 71.9503\n",
            "2025-11-03 09:57:58,184 - supervised_finetuning - INFO - Epoch 65 - supervised_precision/epoch: 72.4623\n",
            "Classifier Epoch 67/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6681, Acc=71.88%]2025-11-03 09:57:58,189 - supervised_finetuning - INFO - Epoch 1386 - supervised_loss/batch: 0.6681\n",
            "2025-11-03 09:57:58,189 - supervised_finetuning - INFO - Epoch 1386 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:58,189 - supervised_finetuning - INFO - Epoch 1386 - learning_rate: 0.0001\n",
            "Classifier Epoch 67/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8389, Acc=65.62%]2025-11-03 09:57:58,227 - supervised_finetuning - INFO - Epoch 1396 - supervised_loss/batch: 0.8389\n",
            "2025-11-03 09:57:58,227 - supervised_finetuning - INFO - Epoch 1396 - supervised_accuracy/batch: 65.6250\n",
            "2025-11-03 09:57:58,227 - supervised_finetuning - INFO - Epoch 1396 - learning_rate: 0.0001\n",
            "Classifier Epoch 67/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7853, Acc=85.71%]2025-11-03 09:57:58,264 - supervised_finetuning - INFO - Epoch 1406 - supervised_loss/batch: 0.7853\n",
            "2025-11-03 09:57:58,264 - supervised_finetuning - INFO - Epoch 1406 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:58,264 - supervised_finetuning - INFO - Epoch 1406 - learning_rate: 0.0001\n",
            "Classifier Epoch 67/100: 100% 21/21 [00:00<00:00, 262.81it/s, Loss=0.7853, Acc=85.71%]\n",
            "2025-11-03 09:57:58,274 - supervised_finetuning - INFO - Epoch 67:\n",
            "2025-11-03 09:57:58,274 - supervised_finetuning - INFO -   Train Loss: 0.6865, Train Acc: 72.18%\n",
            "2025-11-03 09:57:58,274 - supervised_finetuning - INFO -   Train F1: 71.88%, Train Recall: 72.18%\n",
            "2025-11-03 09:57:58,274 - supervised_finetuning - INFO -   Train Precision: 72.23%\n",
            "2025-11-03 09:57:58,274 - supervised_finetuning - INFO - Epoch 66 - supervised_loss/epoch: 0.6865\n",
            "2025-11-03 09:57:58,275 - supervised_finetuning - INFO - Epoch 66 - supervised_accuracy/epoch: 72.1834\n",
            "2025-11-03 09:57:58,275 - supervised_finetuning - INFO - Epoch 66 - supervised_f1/epoch: 71.8808\n",
            "2025-11-03 09:57:58,275 - supervised_finetuning - INFO - Epoch 66 - supervised_recall/epoch: 72.1834\n",
            "2025-11-03 09:57:58,275 - supervised_finetuning - INFO - Epoch 66 - supervised_precision/epoch: 72.2284\n",
            "Classifier Epoch 68/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4780, Acc=82.81%]2025-11-03 09:57:58,280 - supervised_finetuning - INFO - Epoch 1407 - supervised_loss/batch: 0.4780\n",
            "2025-11-03 09:57:58,280 - supervised_finetuning - INFO - Epoch 1407 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:57:58,280 - supervised_finetuning - INFO - Epoch 1407 - learning_rate: 0.0001\n",
            "Classifier Epoch 68/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6232, Acc=71.88%]2025-11-03 09:57:58,317 - supervised_finetuning - INFO - Epoch 1417 - supervised_loss/batch: 0.6232\n",
            "2025-11-03 09:57:58,317 - supervised_finetuning - INFO - Epoch 1417 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:58,317 - supervised_finetuning - INFO - Epoch 1417 - learning_rate: 0.0001\n",
            "Classifier Epoch 68/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4303, Acc=100.00%]2025-11-03 09:57:58,354 - supervised_finetuning - INFO - Epoch 1427 - supervised_loss/batch: 0.4303\n",
            "2025-11-03 09:57:58,355 - supervised_finetuning - INFO - Epoch 1427 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:58,355 - supervised_finetuning - INFO - Epoch 1427 - learning_rate: 0.0001\n",
            "Classifier Epoch 68/100: 100% 21/21 [00:00<00:00, 264.17it/s, Loss=0.4303, Acc=100.00%]\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO - Epoch 68:\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO -   Train Loss: 0.6721, Train Acc: 72.73%\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO -   Train F1: 72.73%, Train Recall: 72.73%\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO -   Train Precision: 73.16%\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO - Epoch 67 - supervised_loss/epoch: 0.6721\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO - Epoch 67 - supervised_accuracy/epoch: 72.7273\n",
            "2025-11-03 09:57:58,365 - supervised_finetuning - INFO - Epoch 67 - supervised_f1/epoch: 72.7252\n",
            "2025-11-03 09:57:58,366 - supervised_finetuning - INFO - Epoch 67 - supervised_recall/epoch: 72.7273\n",
            "2025-11-03 09:57:58,366 - supervised_finetuning - INFO - Epoch 67 - supervised_precision/epoch: 73.1621\n",
            "Classifier Epoch 69/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7261, Acc=67.19%]2025-11-03 09:57:58,370 - supervised_finetuning - INFO - Epoch 1428 - supervised_loss/batch: 0.7261\n",
            "2025-11-03 09:57:58,370 - supervised_finetuning - INFO - Epoch 1428 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:58,370 - supervised_finetuning - INFO - Epoch 1428 - learning_rate: 0.0001\n",
            "Classifier Epoch 69/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7213, Acc=70.31%]2025-11-03 09:57:58,438 - supervised_finetuning - INFO - Epoch 1438 - supervised_loss/batch: 0.7213\n",
            "2025-11-03 09:57:58,438 - supervised_finetuning - INFO - Epoch 1438 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:58,438 - supervised_finetuning - INFO - Epoch 1438 - learning_rate: 0.0001\n",
            "Classifier Epoch 69/100:  90% 19/21 [00:00<00:00, 185.72it/s, Loss=0.3367, Acc=85.71%]2025-11-03 09:57:58,476 - supervised_finetuning - INFO - Epoch 1448 - supervised_loss/batch: 0.3367\n",
            "2025-11-03 09:57:58,476 - supervised_finetuning - INFO - Epoch 1448 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:58,476 - supervised_finetuning - INFO - Epoch 1448 - learning_rate: 0.0001\n",
            "Classifier Epoch 69/100: 100% 21/21 [00:00<00:00, 190.20it/s, Loss=0.3367, Acc=85.71%]\n",
            "2025-11-03 09:57:58,487 - supervised_finetuning - INFO - Epoch 69:\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO -   Train Loss: 0.6823, Train Acc: 72.26%\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO -   Train F1: 71.93%, Train Recall: 72.26%\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO -   Train Precision: 72.84%\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO - Epoch 68 - supervised_loss/epoch: 0.6823\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO - Epoch 68 - supervised_accuracy/epoch: 72.2611\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO - Epoch 68 - supervised_f1/epoch: 71.9270\n",
            "2025-11-03 09:57:58,488 - supervised_finetuning - INFO - Epoch 68 - supervised_recall/epoch: 72.2611\n",
            "2025-11-03 09:57:58,489 - supervised_finetuning - INFO - Epoch 68 - supervised_precision/epoch: 72.8430\n",
            "Classifier Epoch 70/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8784, Acc=67.19%]2025-11-03 09:57:58,493 - supervised_finetuning - INFO - Epoch 1449 - supervised_loss/batch: 0.8784\n",
            "2025-11-03 09:57:58,493 - supervised_finetuning - INFO - Epoch 1449 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:57:58,494 - supervised_finetuning - INFO - Epoch 1449 - learning_rate: 0.0001\n",
            "Classifier Epoch 70/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6388, Acc=71.88%]2025-11-03 09:57:58,532 - supervised_finetuning - INFO - Epoch 1459 - supervised_loss/batch: 0.6388\n",
            "2025-11-03 09:57:58,532 - supervised_finetuning - INFO - Epoch 1459 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:58,532 - supervised_finetuning - INFO - Epoch 1459 - learning_rate: 0.0001\n",
            "Classifier Epoch 70/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0133, Acc=71.43%]2025-11-03 09:57:58,568 - supervised_finetuning - INFO - Epoch 1469 - supervised_loss/batch: 1.0133\n",
            "2025-11-03 09:57:58,568 - supervised_finetuning - INFO - Epoch 1469 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:57:58,569 - supervised_finetuning - INFO - Epoch 1469 - learning_rate: 0.0001\n",
            "Classifier Epoch 70/100: 100% 21/21 [00:00<00:00, 263.41it/s, Loss=1.0133, Acc=71.43%]\n",
            "2025-11-03 09:57:58,579 - supervised_finetuning - INFO - Epoch 70:\n",
            "2025-11-03 09:57:58,579 - supervised_finetuning - INFO -   Train Loss: 0.6842, Train Acc: 73.04%\n",
            "2025-11-03 09:57:58,579 - supervised_finetuning - INFO -   Train F1: 72.92%, Train Recall: 73.04%\n",
            "2025-11-03 09:57:58,579 - supervised_finetuning - INFO -   Train Precision: 73.28%\n",
            "2025-11-03 09:57:58,579 - supervised_finetuning - INFO - Epoch 69 - supervised_loss/epoch: 0.6842\n",
            "2025-11-03 09:57:58,579 - supervised_finetuning - INFO - Epoch 69 - supervised_accuracy/epoch: 73.0381\n",
            "2025-11-03 09:57:58,580 - supervised_finetuning - INFO - Epoch 69 - supervised_f1/epoch: 72.9162\n",
            "2025-11-03 09:57:58,580 - supervised_finetuning - INFO - Epoch 69 - supervised_recall/epoch: 73.0381\n",
            "2025-11-03 09:57:58,580 - supervised_finetuning - INFO - Epoch 69 - supervised_precision/epoch: 73.2792\n",
            "Classifier Epoch 71/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7356, Acc=71.88%]2025-11-03 09:57:58,584 - supervised_finetuning - INFO - Epoch 1470 - supervised_loss/batch: 0.7356\n",
            "2025-11-03 09:57:58,585 - supervised_finetuning - INFO - Epoch 1470 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:57:58,585 - supervised_finetuning - INFO - Epoch 1470 - learning_rate: 0.0001\n",
            "Classifier Epoch 71/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6824, Acc=76.56%]2025-11-03 09:57:58,624 - supervised_finetuning - INFO - Epoch 1480 - supervised_loss/batch: 0.6824\n",
            "2025-11-03 09:57:58,624 - supervised_finetuning - INFO - Epoch 1480 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:57:58,624 - supervised_finetuning - INFO - Epoch 1480 - learning_rate: 0.0001\n",
            "Classifier Epoch 71/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.1906, Acc=100.00%]2025-11-03 09:57:58,660 - supervised_finetuning - INFO - Epoch 1490 - supervised_loss/batch: 0.1906\n",
            "2025-11-03 09:57:58,660 - supervised_finetuning - INFO - Epoch 1490 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:57:58,661 - supervised_finetuning - INFO - Epoch 1490 - learning_rate: 0.0001\n",
            "Classifier Epoch 71/100: 100% 21/21 [00:00<00:00, 260.44it/s, Loss=0.1906, Acc=100.00%]\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO - Epoch 71:\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO -   Train Loss: 0.6453, Train Acc: 73.74%\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO -   Train F1: 73.58%, Train Recall: 73.74%\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO -   Train Precision: 74.22%\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO - Epoch 70 - supervised_loss/epoch: 0.6453\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO - Epoch 70 - supervised_accuracy/epoch: 73.7374\n",
            "2025-11-03 09:57:58,671 - supervised_finetuning - INFO - Epoch 70 - supervised_f1/epoch: 73.5843\n",
            "2025-11-03 09:57:58,672 - supervised_finetuning - INFO - Epoch 70 - supervised_recall/epoch: 73.7374\n",
            "2025-11-03 09:57:58,672 - supervised_finetuning - INFO - Epoch 70 - supervised_precision/epoch: 74.2189\n",
            "Classifier Epoch 72/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6878, Acc=78.12%]2025-11-03 09:57:58,677 - supervised_finetuning - INFO - Epoch 1491 - supervised_loss/batch: 0.6878\n",
            "2025-11-03 09:57:58,677 - supervised_finetuning - INFO - Epoch 1491 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:58,677 - supervised_finetuning - INFO - Epoch 1491 - learning_rate: 0.0001\n",
            "Classifier Epoch 72/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6397, Acc=70.31%]2025-11-03 09:57:58,725 - supervised_finetuning - INFO - Epoch 1501 - supervised_loss/batch: 0.6397\n",
            "2025-11-03 09:57:58,725 - supervised_finetuning - INFO - Epoch 1501 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:57:58,725 - supervised_finetuning - INFO - Epoch 1501 - learning_rate: 0.0001\n",
            "Classifier Epoch 72/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4681, Acc=85.71%]2025-11-03 09:57:58,763 - supervised_finetuning - INFO - Epoch 1511 - supervised_loss/batch: 0.4681\n",
            "2025-11-03 09:57:58,763 - supervised_finetuning - INFO - Epoch 1511 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:58,764 - supervised_finetuning - INFO - Epoch 1511 - learning_rate: 0.0001\n",
            "Classifier Epoch 72/100: 100% 21/21 [00:00<00:00, 228.90it/s, Loss=0.4681, Acc=85.71%]\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO - Epoch 72:\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO -   Train Loss: 0.6474, Train Acc: 74.28%\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO -   Train F1: 74.13%, Train Recall: 74.28%\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO -   Train Precision: 74.31%\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO - Epoch 71 - supervised_loss/epoch: 0.6474\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO - Epoch 71 - supervised_accuracy/epoch: 74.2813\n",
            "2025-11-03 09:57:58,774 - supervised_finetuning - INFO - Epoch 71 - supervised_f1/epoch: 74.1347\n",
            "2025-11-03 09:57:58,775 - supervised_finetuning - INFO - Epoch 71 - supervised_recall/epoch: 74.2813\n",
            "2025-11-03 09:57:58,775 - supervised_finetuning - INFO - Epoch 71 - supervised_precision/epoch: 74.3079\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:57:59,304 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 74.28%\n",
            "Classifier Epoch 73/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5359, Acc=76.56%]2025-11-03 09:57:59,310 - supervised_finetuning - INFO - Epoch 1512 - supervised_loss/batch: 0.5359\n",
            "2025-11-03 09:57:59,311 - supervised_finetuning - INFO - Epoch 1512 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:57:59,313 - supervised_finetuning - INFO - Epoch 1512 - learning_rate: 0.0001\n",
            "Classifier Epoch 73/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4857, Acc=82.81%]2025-11-03 09:57:59,354 - supervised_finetuning - INFO - Epoch 1522 - supervised_loss/batch: 0.4857\n",
            "2025-11-03 09:57:59,355 - supervised_finetuning - INFO - Epoch 1522 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:57:59,355 - supervised_finetuning - INFO - Epoch 1522 - learning_rate: 0.0001\n",
            "Classifier Epoch 73/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4550, Acc=85.71%]2025-11-03 09:57:59,391 - supervised_finetuning - INFO - Epoch 1532 - supervised_loss/batch: 0.4550\n",
            "2025-11-03 09:57:59,391 - supervised_finetuning - INFO - Epoch 1532 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:59,391 - supervised_finetuning - INFO - Epoch 1532 - learning_rate: 0.0001\n",
            "Classifier Epoch 73/100: 100% 21/21 [00:00<00:00, 242.85it/s, Loss=0.4550, Acc=85.71%]\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO - Epoch 73:\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO -   Train Loss: 0.6470, Train Acc: 73.66%\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO -   Train F1: 73.45%, Train Recall: 73.66%\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO -   Train Precision: 74.12%\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO - Epoch 72 - supervised_loss/epoch: 0.6470\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO - Epoch 72 - supervised_accuracy/epoch: 73.6597\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO - Epoch 72 - supervised_f1/epoch: 73.4542\n",
            "2025-11-03 09:57:59,403 - supervised_finetuning - INFO - Epoch 72 - supervised_recall/epoch: 73.6597\n",
            "2025-11-03 09:57:59,404 - supervised_finetuning - INFO - Epoch 72 - supervised_precision/epoch: 74.1223\n",
            "Classifier Epoch 74/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4704, Acc=82.81%]2025-11-03 09:57:59,409 - supervised_finetuning - INFO - Epoch 1533 - supervised_loss/batch: 0.4704\n",
            "2025-11-03 09:57:59,411 - supervised_finetuning - INFO - Epoch 1533 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:57:59,415 - supervised_finetuning - INFO - Epoch 1533 - learning_rate: 0.0001\n",
            "Classifier Epoch 74/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5573, Acc=81.25%]2025-11-03 09:57:59,458 - supervised_finetuning - INFO - Epoch 1543 - supervised_loss/batch: 0.5573\n",
            "2025-11-03 09:57:59,458 - supervised_finetuning - INFO - Epoch 1543 - supervised_accuracy/batch: 81.2500\n",
            "2025-11-03 09:57:59,458 - supervised_finetuning - INFO - Epoch 1543 - learning_rate: 0.0001\n",
            "Classifier Epoch 74/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.0979, Acc=57.14%]2025-11-03 09:57:59,499 - supervised_finetuning - INFO - Epoch 1553 - supervised_loss/batch: 1.0979\n",
            "2025-11-03 09:57:59,500 - supervised_finetuning - INFO - Epoch 1553 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:57:59,500 - supervised_finetuning - INFO - Epoch 1553 - learning_rate: 0.0001\n",
            "Classifier Epoch 74/100: 100% 21/21 [00:00<00:00, 221.21it/s, Loss=1.0979, Acc=57.14%]\n",
            "2025-11-03 09:57:59,510 - supervised_finetuning - INFO - Epoch 74:\n",
            "2025-11-03 09:57:59,510 - supervised_finetuning - INFO -   Train Loss: 0.6737, Train Acc: 73.82%\n",
            "2025-11-03 09:57:59,510 - supervised_finetuning - INFO -   Train F1: 73.63%, Train Recall: 73.82%\n",
            "2025-11-03 09:57:59,510 - supervised_finetuning - INFO -   Train Precision: 73.73%\n",
            "2025-11-03 09:57:59,510 - supervised_finetuning - INFO - Epoch 73 - supervised_loss/epoch: 0.6737\n",
            "2025-11-03 09:57:59,511 - supervised_finetuning - INFO - Epoch 73 - supervised_accuracy/epoch: 73.8151\n",
            "2025-11-03 09:57:59,511 - supervised_finetuning - INFO - Epoch 73 - supervised_f1/epoch: 73.6340\n",
            "2025-11-03 09:57:59,511 - supervised_finetuning - INFO - Epoch 73 - supervised_recall/epoch: 73.8151\n",
            "2025-11-03 09:57:59,511 - supervised_finetuning - INFO - Epoch 73 - supervised_precision/epoch: 73.7303\n",
            "Classifier Epoch 75/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5931, Acc=78.12%]2025-11-03 09:57:59,516 - supervised_finetuning - INFO - Epoch 1554 - supervised_loss/batch: 0.5931\n",
            "2025-11-03 09:57:59,516 - supervised_finetuning - INFO - Epoch 1554 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:57:59,516 - supervised_finetuning - INFO - Epoch 1554 - learning_rate: 0.0001\n",
            "Classifier Epoch 75/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7055, Acc=73.44%]2025-11-03 09:57:59,553 - supervised_finetuning - INFO - Epoch 1564 - supervised_loss/batch: 0.7055\n",
            "2025-11-03 09:57:59,553 - supervised_finetuning - INFO - Epoch 1564 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:57:59,553 - supervised_finetuning - INFO - Epoch 1564 - learning_rate: 0.0001\n",
            "Classifier Epoch 75/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.2433, Acc=85.71%]2025-11-03 09:57:59,591 - supervised_finetuning - INFO - Epoch 1574 - supervised_loss/batch: 0.2433\n",
            "2025-11-03 09:57:59,591 - supervised_finetuning - INFO - Epoch 1574 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:57:59,592 - supervised_finetuning - INFO - Epoch 1574 - learning_rate: 0.0001\n",
            "Classifier Epoch 75/100: 100% 21/21 [00:00<00:00, 260.94it/s, Loss=0.2433, Acc=85.71%]\n",
            "2025-11-03 09:57:59,608 - supervised_finetuning - INFO - Epoch 75:\n",
            "2025-11-03 09:57:59,609 - supervised_finetuning - INFO -   Train Loss: 0.6338, Train Acc: 74.36%\n",
            "2025-11-03 09:57:59,609 - supervised_finetuning - INFO -   Train F1: 74.09%, Train Recall: 74.36%\n",
            "2025-11-03 09:57:59,609 - supervised_finetuning - INFO -   Train Precision: 74.31%\n",
            "2025-11-03 09:57:59,609 - supervised_finetuning - INFO - Epoch 74 - supervised_loss/epoch: 0.6338\n",
            "2025-11-03 09:57:59,609 - supervised_finetuning - INFO - Epoch 74 - supervised_accuracy/epoch: 74.3590\n",
            "2025-11-03 09:57:59,610 - supervised_finetuning - INFO - Epoch 74 - supervised_f1/epoch: 74.0852\n",
            "2025-11-03 09:57:59,610 - supervised_finetuning - INFO - Epoch 74 - supervised_recall/epoch: 74.3590\n",
            "2025-11-03 09:57:59,610 - supervised_finetuning - INFO - Epoch 74 - supervised_precision/epoch: 74.3127\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:58:01,661 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 74.36%\n",
            "Classifier Epoch 76/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6595, Acc=75.00%]2025-11-03 09:58:01,666 - supervised_finetuning - INFO - Epoch 1575 - supervised_loss/batch: 0.6595\n",
            "2025-11-03 09:58:01,667 - supervised_finetuning - INFO - Epoch 1575 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:58:01,667 - supervised_finetuning - INFO - Epoch 1575 - learning_rate: 0.0001\n",
            "Classifier Epoch 76/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6218, Acc=79.69%]2025-11-03 09:58:01,708 - supervised_finetuning - INFO - Epoch 1585 - supervised_loss/batch: 0.6218\n",
            "2025-11-03 09:58:01,708 - supervised_finetuning - INFO - Epoch 1585 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:58:01,708 - supervised_finetuning - INFO - Epoch 1585 - learning_rate: 0.0001\n",
            "Classifier Epoch 76/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5341, Acc=71.43%]2025-11-03 09:58:01,745 - supervised_finetuning - INFO - Epoch 1595 - supervised_loss/batch: 0.5341\n",
            "2025-11-03 09:58:01,746 - supervised_finetuning - INFO - Epoch 1595 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:01,746 - supervised_finetuning - INFO - Epoch 1595 - learning_rate: 0.0001\n",
            "Classifier Epoch 76/100: 100% 21/21 [00:00<00:00, 247.70it/s, Loss=0.5341, Acc=71.43%]\n",
            "2025-11-03 09:58:01,756 - supervised_finetuning - INFO - Epoch 76:\n",
            "2025-11-03 09:58:01,756 - supervised_finetuning - INFO -   Train Loss: 0.6432, Train Acc: 75.06%\n",
            "2025-11-03 09:58:01,756 - supervised_finetuning - INFO -   Train F1: 74.92%, Train Recall: 75.06%\n",
            "2025-11-03 09:58:01,756 - supervised_finetuning - INFO -   Train Precision: 75.49%\n",
            "2025-11-03 09:58:01,756 - supervised_finetuning - INFO - Epoch 75 - supervised_loss/epoch: 0.6432\n",
            "2025-11-03 09:58:01,756 - supervised_finetuning - INFO - Epoch 75 - supervised_accuracy/epoch: 75.0583\n",
            "2025-11-03 09:58:01,757 - supervised_finetuning - INFO - Epoch 75 - supervised_f1/epoch: 74.9182\n",
            "2025-11-03 09:58:01,757 - supervised_finetuning - INFO - Epoch 75 - supervised_recall/epoch: 75.0583\n",
            "2025-11-03 09:58:01,757 - supervised_finetuning - INFO - Epoch 75 - supervised_precision/epoch: 75.4868\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:58:03,042 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 75.06%\n",
            "Classifier Epoch 77/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6581, Acc=70.31%]2025-11-03 09:58:03,048 - supervised_finetuning - INFO - Epoch 1596 - supervised_loss/batch: 0.6581\n",
            "2025-11-03 09:58:03,048 - supervised_finetuning - INFO - Epoch 1596 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:58:03,048 - supervised_finetuning - INFO - Epoch 1596 - learning_rate: 0.0001\n",
            "Classifier Epoch 77/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7829, Acc=64.06%]2025-11-03 09:58:03,089 - supervised_finetuning - INFO - Epoch 1606 - supervised_loss/batch: 0.7829\n",
            "2025-11-03 09:58:03,089 - supervised_finetuning - INFO - Epoch 1606 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:58:03,090 - supervised_finetuning - INFO - Epoch 1606 - learning_rate: 0.0001\n",
            "Classifier Epoch 77/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3905, Acc=85.71%]2025-11-03 09:58:03,126 - supervised_finetuning - INFO - Epoch 1616 - supervised_loss/batch: 0.3905\n",
            "2025-11-03 09:58:03,126 - supervised_finetuning - INFO - Epoch 1616 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:03,126 - supervised_finetuning - INFO - Epoch 1616 - learning_rate: 0.0001\n",
            "Classifier Epoch 77/100: 100% 21/21 [00:00<00:00, 251.19it/s, Loss=0.3905, Acc=85.71%]\n",
            "2025-11-03 09:58:03,136 - supervised_finetuning - INFO - Epoch 77:\n",
            "2025-11-03 09:58:03,136 - supervised_finetuning - INFO -   Train Loss: 0.6503, Train Acc: 72.49%\n",
            "2025-11-03 09:58:03,136 - supervised_finetuning - INFO -   Train F1: 72.24%, Train Recall: 72.49%\n",
            "2025-11-03 09:58:03,136 - supervised_finetuning - INFO -   Train Precision: 72.87%\n",
            "2025-11-03 09:58:03,137 - supervised_finetuning - INFO - Epoch 76 - supervised_loss/epoch: 0.6503\n",
            "2025-11-03 09:58:03,137 - supervised_finetuning - INFO - Epoch 76 - supervised_accuracy/epoch: 72.4942\n",
            "2025-11-03 09:58:03,137 - supervised_finetuning - INFO - Epoch 76 - supervised_f1/epoch: 72.2438\n",
            "2025-11-03 09:58:03,137 - supervised_finetuning - INFO - Epoch 76 - supervised_recall/epoch: 72.4942\n",
            "2025-11-03 09:58:03,137 - supervised_finetuning - INFO - Epoch 76 - supervised_precision/epoch: 72.8739\n",
            "Classifier Epoch 78/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6543, Acc=70.31%]2025-11-03 09:58:03,142 - supervised_finetuning - INFO - Epoch 1617 - supervised_loss/batch: 0.6543\n",
            "2025-11-03 09:58:03,142 - supervised_finetuning - INFO - Epoch 1617 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:58:03,143 - supervised_finetuning - INFO - Epoch 1617 - learning_rate: 0.0001\n",
            "Classifier Epoch 78/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6330, Acc=73.44%]2025-11-03 09:58:03,179 - supervised_finetuning - INFO - Epoch 1627 - supervised_loss/batch: 0.6330\n",
            "2025-11-03 09:58:03,180 - supervised_finetuning - INFO - Epoch 1627 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:58:03,180 - supervised_finetuning - INFO - Epoch 1627 - learning_rate: 0.0001\n",
            "Classifier Epoch 78/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4513, Acc=71.43%]2025-11-03 09:58:03,217 - supervised_finetuning - INFO - Epoch 1637 - supervised_loss/batch: 0.4513\n",
            "2025-11-03 09:58:03,218 - supervised_finetuning - INFO - Epoch 1637 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:03,218 - supervised_finetuning - INFO - Epoch 1637 - learning_rate: 0.0001\n",
            "Classifier Epoch 78/100: 100% 21/21 [00:00<00:00, 260.27it/s, Loss=0.4513, Acc=71.43%]\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO - Epoch 78:\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO -   Train Loss: 0.6344, Train Acc: 74.20%\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO -   Train F1: 74.05%, Train Recall: 74.20%\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO -   Train Precision: 74.36%\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO - Epoch 77 - supervised_loss/epoch: 0.6344\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO - Epoch 77 - supervised_accuracy/epoch: 74.2036\n",
            "2025-11-03 09:58:03,229 - supervised_finetuning - INFO - Epoch 77 - supervised_f1/epoch: 74.0486\n",
            "2025-11-03 09:58:03,230 - supervised_finetuning - INFO - Epoch 77 - supervised_recall/epoch: 74.2036\n",
            "2025-11-03 09:58:03,230 - supervised_finetuning - INFO - Epoch 77 - supervised_precision/epoch: 74.3562\n",
            "Classifier Epoch 79/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6889, Acc=68.75%]2025-11-03 09:58:03,234 - supervised_finetuning - INFO - Epoch 1638 - supervised_loss/batch: 0.6889\n",
            "2025-11-03 09:58:03,234 - supervised_finetuning - INFO - Epoch 1638 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:58:03,235 - supervised_finetuning - INFO - Epoch 1638 - learning_rate: 0.0001\n",
            "Classifier Epoch 79/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5942, Acc=78.12%]2025-11-03 09:58:03,269 - supervised_finetuning - INFO - Epoch 1648 - supervised_loss/batch: 0.5942\n",
            "2025-11-03 09:58:03,269 - supervised_finetuning - INFO - Epoch 1648 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:58:03,269 - supervised_finetuning - INFO - Epoch 1648 - learning_rate: 0.0001\n",
            "Classifier Epoch 79/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5635, Acc=71.43%]2025-11-03 09:58:03,307 - supervised_finetuning - INFO - Epoch 1658 - supervised_loss/batch: 0.5635\n",
            "2025-11-03 09:58:03,307 - supervised_finetuning - INFO - Epoch 1658 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:03,307 - supervised_finetuning - INFO - Epoch 1658 - learning_rate: 0.0001\n",
            "Classifier Epoch 79/100: 100% 21/21 [00:00<00:00, 273.49it/s, Loss=0.5635, Acc=71.43%]\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO - Epoch 79:\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO -   Train Loss: 0.6342, Train Acc: 74.59%\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO -   Train F1: 74.36%, Train Recall: 74.59%\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO -   Train Precision: 74.49%\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO - Epoch 78 - supervised_loss/epoch: 0.6342\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO - Epoch 78 - supervised_accuracy/epoch: 74.5921\n",
            "2025-11-03 09:58:03,324 - supervised_finetuning - INFO - Epoch 78 - supervised_f1/epoch: 74.3616\n",
            "2025-11-03 09:58:03,325 - supervised_finetuning - INFO - Epoch 78 - supervised_recall/epoch: 74.5921\n",
            "2025-11-03 09:58:03,325 - supervised_finetuning - INFO - Epoch 78 - supervised_precision/epoch: 74.4921\n",
            "Classifier Epoch 80/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7952, Acc=67.19%]2025-11-03 09:58:03,331 - supervised_finetuning - INFO - Epoch 1659 - supervised_loss/batch: 0.7952\n",
            "2025-11-03 09:58:03,331 - supervised_finetuning - INFO - Epoch 1659 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:58:03,332 - supervised_finetuning - INFO - Epoch 1659 - learning_rate: 0.0001\n",
            "Classifier Epoch 80/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6312, Acc=73.44%]2025-11-03 09:58:03,370 - supervised_finetuning - INFO - Epoch 1669 - supervised_loss/batch: 0.6312\n",
            "2025-11-03 09:58:03,370 - supervised_finetuning - INFO - Epoch 1669 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:58:03,370 - supervised_finetuning - INFO - Epoch 1669 - learning_rate: 0.0001\n",
            "Classifier Epoch 80/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5347, Acc=71.43%]2025-11-03 09:58:03,405 - supervised_finetuning - INFO - Epoch 1679 - supervised_loss/batch: 0.5347\n",
            "2025-11-03 09:58:03,405 - supervised_finetuning - INFO - Epoch 1679 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:03,405 - supervised_finetuning - INFO - Epoch 1679 - learning_rate: 0.0001\n",
            "Classifier Epoch 80/100: 100% 21/21 [00:00<00:00, 261.02it/s, Loss=0.5347, Acc=71.43%]\n",
            "2025-11-03 09:58:03,415 - supervised_finetuning - INFO - Epoch 80:\n",
            "2025-11-03 09:58:03,415 - supervised_finetuning - INFO -   Train Loss: 0.6356, Train Acc: 74.51%\n",
            "2025-11-03 09:58:03,415 - supervised_finetuning - INFO -   Train F1: 74.30%, Train Recall: 74.51%\n",
            "2025-11-03 09:58:03,416 - supervised_finetuning - INFO -   Train Precision: 74.87%\n",
            "2025-11-03 09:58:03,416 - supervised_finetuning - INFO - Epoch 79 - supervised_loss/epoch: 0.6356\n",
            "2025-11-03 09:58:03,416 - supervised_finetuning - INFO - Epoch 79 - supervised_accuracy/epoch: 74.5144\n",
            "2025-11-03 09:58:03,416 - supervised_finetuning - INFO - Epoch 79 - supervised_f1/epoch: 74.2977\n",
            "2025-11-03 09:58:03,416 - supervised_finetuning - INFO - Epoch 79 - supervised_recall/epoch: 74.5144\n",
            "2025-11-03 09:58:03,417 - supervised_finetuning - INFO - Epoch 79 - supervised_precision/epoch: 74.8686\n",
            "Classifier Epoch 81/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3752, Acc=84.38%]2025-11-03 09:58:03,421 - supervised_finetuning - INFO - Epoch 1680 - supervised_loss/batch: 0.3752\n",
            "2025-11-03 09:58:03,422 - supervised_finetuning - INFO - Epoch 1680 - supervised_accuracy/batch: 84.3750\n",
            "2025-11-03 09:58:03,422 - supervised_finetuning - INFO - Epoch 1680 - learning_rate: 0.0001\n",
            "Classifier Epoch 81/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6612, Acc=64.06%]2025-11-03 09:58:03,457 - supervised_finetuning - INFO - Epoch 1690 - supervised_loss/batch: 0.6612\n",
            "2025-11-03 09:58:03,457 - supervised_finetuning - INFO - Epoch 1690 - supervised_accuracy/batch: 64.0625\n",
            "2025-11-03 09:58:03,457 - supervised_finetuning - INFO - Epoch 1690 - learning_rate: 0.0001\n",
            "Classifier Epoch 81/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.2180, Acc=100.00%]2025-11-03 09:58:03,492 - supervised_finetuning - INFO - Epoch 1700 - supervised_loss/batch: 0.2180\n",
            "2025-11-03 09:58:03,492 - supervised_finetuning - INFO - Epoch 1700 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:58:03,492 - supervised_finetuning - INFO - Epoch 1700 - learning_rate: 0.0001\n",
            "Classifier Epoch 81/100: 100% 21/21 [00:00<00:00, 277.43it/s, Loss=0.2180, Acc=100.00%]\n",
            "2025-11-03 09:58:03,505 - supervised_finetuning - INFO - Epoch 81:\n",
            "2025-11-03 09:58:03,505 - supervised_finetuning - INFO -   Train Loss: 0.6211, Train Acc: 74.59%\n",
            "2025-11-03 09:58:03,505 - supervised_finetuning - INFO -   Train F1: 74.36%, Train Recall: 74.59%\n",
            "2025-11-03 09:58:03,505 - supervised_finetuning - INFO -   Train Precision: 74.67%\n",
            "2025-11-03 09:58:03,505 - supervised_finetuning - INFO - Epoch 80 - supervised_loss/epoch: 0.6211\n",
            "2025-11-03 09:58:03,505 - supervised_finetuning - INFO - Epoch 80 - supervised_accuracy/epoch: 74.5921\n",
            "2025-11-03 09:58:03,506 - supervised_finetuning - INFO - Epoch 80 - supervised_f1/epoch: 74.3638\n",
            "2025-11-03 09:58:03,506 - supervised_finetuning - INFO - Epoch 80 - supervised_recall/epoch: 74.5921\n",
            "2025-11-03 09:58:03,506 - supervised_finetuning - INFO - Epoch 80 - supervised_precision/epoch: 74.6715\n",
            "Classifier Epoch 82/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7234, Acc=71.88%]2025-11-03 09:58:03,511 - supervised_finetuning - INFO - Epoch 1701 - supervised_loss/batch: 0.7234\n",
            "2025-11-03 09:58:03,512 - supervised_finetuning - INFO - Epoch 1701 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:58:03,512 - supervised_finetuning - INFO - Epoch 1701 - learning_rate: 0.0001\n",
            "Classifier Epoch 82/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7146, Acc=71.88%]2025-11-03 09:58:03,551 - supervised_finetuning - INFO - Epoch 1711 - supervised_loss/batch: 0.7146\n",
            "2025-11-03 09:58:03,551 - supervised_finetuning - INFO - Epoch 1711 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:58:03,551 - supervised_finetuning - INFO - Epoch 1711 - learning_rate: 0.0001\n",
            "Classifier Epoch 82/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6400, Acc=71.43%]2025-11-03 09:58:03,597 - supervised_finetuning - INFO - Epoch 1721 - supervised_loss/batch: 0.6400\n",
            "2025-11-03 09:58:03,597 - supervised_finetuning - INFO - Epoch 1721 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:03,598 - supervised_finetuning - INFO - Epoch 1721 - learning_rate: 0.0001\n",
            "Classifier Epoch 82/100: 100% 21/21 [00:00<00:00, 228.89it/s, Loss=0.6400, Acc=71.43%]\n",
            "2025-11-03 09:58:03,609 - supervised_finetuning - INFO - Epoch 82:\n",
            "2025-11-03 09:58:03,609 - supervised_finetuning - INFO -   Train Loss: 0.6544, Train Acc: 74.05%\n",
            "2025-11-03 09:58:03,609 - supervised_finetuning - INFO -   Train F1: 73.83%, Train Recall: 74.05%\n",
            "2025-11-03 09:58:03,609 - supervised_finetuning - INFO -   Train Precision: 74.71%\n",
            "2025-11-03 09:58:03,610 - supervised_finetuning - INFO - Epoch 81 - supervised_loss/epoch: 0.6544\n",
            "2025-11-03 09:58:03,610 - supervised_finetuning - INFO - Epoch 81 - supervised_accuracy/epoch: 74.0482\n",
            "2025-11-03 09:58:03,610 - supervised_finetuning - INFO - Epoch 81 - supervised_f1/epoch: 73.8316\n",
            "2025-11-03 09:58:03,610 - supervised_finetuning - INFO - Epoch 81 - supervised_recall/epoch: 74.0482\n",
            "2025-11-03 09:58:03,610 - supervised_finetuning - INFO - Epoch 81 - supervised_precision/epoch: 74.7095\n",
            "Classifier Epoch 83/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7904, Acc=68.75%]2025-11-03 09:58:03,615 - supervised_finetuning - INFO - Epoch 1722 - supervised_loss/batch: 0.7904\n",
            "2025-11-03 09:58:03,615 - supervised_finetuning - INFO - Epoch 1722 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:58:03,616 - supervised_finetuning - INFO - Epoch 1722 - learning_rate: 0.0001\n",
            "Classifier Epoch 83/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7483, Acc=71.88%]2025-11-03 09:58:03,651 - supervised_finetuning - INFO - Epoch 1732 - supervised_loss/batch: 0.7483\n",
            "2025-11-03 09:58:03,651 - supervised_finetuning - INFO - Epoch 1732 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:58:03,652 - supervised_finetuning - INFO - Epoch 1732 - learning_rate: 0.0001\n",
            "Classifier Epoch 83/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6809, Acc=71.43%]2025-11-03 09:58:03,687 - supervised_finetuning - INFO - Epoch 1742 - supervised_loss/batch: 0.6809\n",
            "2025-11-03 09:58:03,687 - supervised_finetuning - INFO - Epoch 1742 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:03,687 - supervised_finetuning - INFO - Epoch 1742 - learning_rate: 0.0001\n",
            "Classifier Epoch 83/100: 100% 21/21 [00:00<00:00, 274.08it/s, Loss=0.6809, Acc=71.43%]\n",
            "2025-11-03 09:58:03,697 - supervised_finetuning - INFO - Epoch 83:\n",
            "2025-11-03 09:58:03,697 - supervised_finetuning - INFO -   Train Loss: 0.6444, Train Acc: 73.74%\n",
            "2025-11-03 09:58:03,697 - supervised_finetuning - INFO -   Train F1: 73.60%, Train Recall: 73.74%\n",
            "2025-11-03 09:58:03,697 - supervised_finetuning - INFO -   Train Precision: 73.74%\n",
            "2025-11-03 09:58:03,697 - supervised_finetuning - INFO - Epoch 82 - supervised_loss/epoch: 0.6444\n",
            "2025-11-03 09:58:03,698 - supervised_finetuning - INFO - Epoch 82 - supervised_accuracy/epoch: 73.7374\n",
            "2025-11-03 09:58:03,698 - supervised_finetuning - INFO - Epoch 82 - supervised_f1/epoch: 73.6042\n",
            "2025-11-03 09:58:03,698 - supervised_finetuning - INFO - Epoch 82 - supervised_recall/epoch: 73.7374\n",
            "2025-11-03 09:58:03,698 - supervised_finetuning - INFO - Epoch 82 - supervised_precision/epoch: 73.7400\n",
            "Classifier Epoch 84/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6187, Acc=75.00%]2025-11-03 09:58:03,703 - supervised_finetuning - INFO - Epoch 1743 - supervised_loss/batch: 0.6187\n",
            "2025-11-03 09:58:03,703 - supervised_finetuning - INFO - Epoch 1743 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:58:03,703 - supervised_finetuning - INFO - Epoch 1743 - learning_rate: 0.0001\n",
            "Classifier Epoch 84/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5757, Acc=71.88%]2025-11-03 09:58:03,741 - supervised_finetuning - INFO - Epoch 1753 - supervised_loss/batch: 0.5757\n",
            "2025-11-03 09:58:03,741 - supervised_finetuning - INFO - Epoch 1753 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:58:03,741 - supervised_finetuning - INFO - Epoch 1753 - learning_rate: 0.0001\n",
            "Classifier Epoch 84/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6792, Acc=71.43%]2025-11-03 09:58:03,776 - supervised_finetuning - INFO - Epoch 1763 - supervised_loss/batch: 0.6792\n",
            "2025-11-03 09:58:03,776 - supervised_finetuning - INFO - Epoch 1763 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:03,777 - supervised_finetuning - INFO - Epoch 1763 - learning_rate: 0.0001\n",
            "Classifier Epoch 84/100: 100% 21/21 [00:00<00:00, 268.28it/s, Loss=0.6792, Acc=71.43%]\n",
            "2025-11-03 09:58:03,786 - supervised_finetuning - INFO - Epoch 84:\n",
            "2025-11-03 09:58:03,786 - supervised_finetuning - INFO -   Train Loss: 0.6465, Train Acc: 73.97%\n",
            "2025-11-03 09:58:03,786 - supervised_finetuning - INFO -   Train F1: 73.75%, Train Recall: 73.97%\n",
            "2025-11-03 09:58:03,786 - supervised_finetuning - INFO -   Train Precision: 74.33%\n",
            "2025-11-03 09:58:03,787 - supervised_finetuning - INFO - Epoch 83 - supervised_loss/epoch: 0.6465\n",
            "2025-11-03 09:58:03,787 - supervised_finetuning - INFO - Epoch 83 - supervised_accuracy/epoch: 73.9705\n",
            "2025-11-03 09:58:03,787 - supervised_finetuning - INFO - Epoch 83 - supervised_f1/epoch: 73.7522\n",
            "2025-11-03 09:58:03,787 - supervised_finetuning - INFO - Epoch 83 - supervised_recall/epoch: 73.9705\n",
            "2025-11-03 09:58:03,787 - supervised_finetuning - INFO - Epoch 83 - supervised_precision/epoch: 74.3281\n",
            "Classifier Epoch 85/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7282, Acc=81.25%]2025-11-03 09:58:03,792 - supervised_finetuning - INFO - Epoch 1764 - supervised_loss/batch: 0.7282\n",
            "2025-11-03 09:58:03,792 - supervised_finetuning - INFO - Epoch 1764 - supervised_accuracy/batch: 81.2500\n",
            "2025-11-03 09:58:03,792 - supervised_finetuning - INFO - Epoch 1764 - learning_rate: 0.0001\n",
            "Classifier Epoch 85/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5228, Acc=87.50%]2025-11-03 09:58:03,834 - supervised_finetuning - INFO - Epoch 1774 - supervised_loss/batch: 0.5228\n",
            "2025-11-03 09:58:03,835 - supervised_finetuning - INFO - Epoch 1774 - supervised_accuracy/batch: 87.5000\n",
            "2025-11-03 09:58:03,835 - supervised_finetuning - INFO - Epoch 1774 - learning_rate: 0.0001\n",
            "Classifier Epoch 85/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5598, Acc=85.71%]2025-11-03 09:58:03,869 - supervised_finetuning - INFO - Epoch 1784 - supervised_loss/batch: 0.5598\n",
            "2025-11-03 09:58:03,870 - supervised_finetuning - INFO - Epoch 1784 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:03,870 - supervised_finetuning - INFO - Epoch 1784 - learning_rate: 0.0001\n",
            "Classifier Epoch 85/100: 100% 21/21 [00:00<00:00, 254.57it/s, Loss=0.5598, Acc=85.71%]\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO - Epoch 85:\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO -   Train Loss: 0.6238, Train Acc: 75.14%\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO -   Train F1: 74.92%, Train Recall: 75.14%\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO -   Train Precision: 75.61%\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO - Epoch 84 - supervised_loss/epoch: 0.6238\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO - Epoch 84 - supervised_accuracy/epoch: 75.1360\n",
            "2025-11-03 09:58:03,880 - supervised_finetuning - INFO - Epoch 84 - supervised_f1/epoch: 74.9180\n",
            "2025-11-03 09:58:03,881 - supervised_finetuning - INFO - Epoch 84 - supervised_recall/epoch: 75.1360\n",
            "2025-11-03 09:58:03,881 - supervised_finetuning - INFO - Epoch 84 - supervised_precision/epoch: 75.6066\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:58:04,289 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 75.14%\n",
            "Classifier Epoch 86/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5856, Acc=78.12%]2025-11-03 09:58:04,295 - supervised_finetuning - INFO - Epoch 1785 - supervised_loss/batch: 0.5856\n",
            "2025-11-03 09:58:04,295 - supervised_finetuning - INFO - Epoch 1785 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:58:04,295 - supervised_finetuning - INFO - Epoch 1785 - learning_rate: 0.0001\n",
            "Classifier Epoch 86/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6982, Acc=68.75%]2025-11-03 09:58:04,341 - supervised_finetuning - INFO - Epoch 1795 - supervised_loss/batch: 0.6982\n",
            "2025-11-03 09:58:04,341 - supervised_finetuning - INFO - Epoch 1795 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:58:04,341 - supervised_finetuning - INFO - Epoch 1795 - learning_rate: 0.0001\n",
            "Classifier Epoch 86/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3922, Acc=85.71%]2025-11-03 09:58:04,377 - supervised_finetuning - INFO - Epoch 1805 - supervised_loss/batch: 0.3922\n",
            "2025-11-03 09:58:04,378 - supervised_finetuning - INFO - Epoch 1805 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:04,378 - supervised_finetuning - INFO - Epoch 1805 - learning_rate: 0.0001\n",
            "Classifier Epoch 86/100: 100% 21/21 [00:00<00:00, 238.01it/s, Loss=0.3922, Acc=85.71%]\n",
            "2025-11-03 09:58:04,388 - supervised_finetuning - INFO - Epoch 86:\n",
            "2025-11-03 09:58:04,388 - supervised_finetuning - INFO -   Train Loss: 0.6259, Train Acc: 74.51%\n",
            "2025-11-03 09:58:04,388 - supervised_finetuning - INFO -   Train F1: 74.32%, Train Recall: 74.51%\n",
            "2025-11-03 09:58:04,388 - supervised_finetuning - INFO -   Train Precision: 74.79%\n",
            "2025-11-03 09:58:04,388 - supervised_finetuning - INFO - Epoch 85 - supervised_loss/epoch: 0.6259\n",
            "2025-11-03 09:58:04,389 - supervised_finetuning - INFO - Epoch 85 - supervised_accuracy/epoch: 74.5144\n",
            "2025-11-03 09:58:04,389 - supervised_finetuning - INFO - Epoch 85 - supervised_f1/epoch: 74.3242\n",
            "2025-11-03 09:58:04,389 - supervised_finetuning - INFO - Epoch 85 - supervised_recall/epoch: 74.5144\n",
            "2025-11-03 09:58:04,389 - supervised_finetuning - INFO - Epoch 85 - supervised_precision/epoch: 74.7864\n",
            "Classifier Epoch 87/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5778, Acc=78.12%]2025-11-03 09:58:04,393 - supervised_finetuning - INFO - Epoch 1806 - supervised_loss/batch: 0.5778\n",
            "2025-11-03 09:58:04,394 - supervised_finetuning - INFO - Epoch 1806 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:58:04,394 - supervised_finetuning - INFO - Epoch 1806 - learning_rate: 0.0001\n",
            "Classifier Epoch 87/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5812, Acc=76.56%]2025-11-03 09:58:04,432 - supervised_finetuning - INFO - Epoch 1816 - supervised_loss/batch: 0.5812\n",
            "2025-11-03 09:58:04,432 - supervised_finetuning - INFO - Epoch 1816 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:58:04,432 - supervised_finetuning - INFO - Epoch 1816 - learning_rate: 0.0001\n",
            "Classifier Epoch 87/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5186, Acc=71.43%]2025-11-03 09:58:04,468 - supervised_finetuning - INFO - Epoch 1826 - supervised_loss/batch: 0.5186\n",
            "2025-11-03 09:58:04,469 - supervised_finetuning - INFO - Epoch 1826 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:04,469 - supervised_finetuning - INFO - Epoch 1826 - learning_rate: 0.0001\n",
            "Classifier Epoch 87/100: 100% 21/21 [00:00<00:00, 264.42it/s, Loss=0.5186, Acc=71.43%]\n",
            "2025-11-03 09:58:04,479 - supervised_finetuning - INFO - Epoch 87:\n",
            "2025-11-03 09:58:04,479 - supervised_finetuning - INFO -   Train Loss: 0.6265, Train Acc: 75.60%\n",
            "2025-11-03 09:58:04,479 - supervised_finetuning - INFO -   Train F1: 75.35%, Train Recall: 75.60%\n",
            "2025-11-03 09:58:04,479 - supervised_finetuning - INFO -   Train Precision: 75.69%\n",
            "2025-11-03 09:58:04,480 - supervised_finetuning - INFO - Epoch 86 - supervised_loss/epoch: 0.6265\n",
            "2025-11-03 09:58:04,480 - supervised_finetuning - INFO - Epoch 86 - supervised_accuracy/epoch: 75.6022\n",
            "2025-11-03 09:58:04,480 - supervised_finetuning - INFO - Epoch 86 - supervised_f1/epoch: 75.3461\n",
            "2025-11-03 09:58:04,480 - supervised_finetuning - INFO - Epoch 86 - supervised_recall/epoch: 75.6022\n",
            "2025-11-03 09:58:04,480 - supervised_finetuning - INFO - Epoch 86 - supervised_precision/epoch: 75.6853\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:58:04,984 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 75.60%\n",
            "Classifier Epoch 88/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5196, Acc=79.69%]2025-11-03 09:58:04,989 - supervised_finetuning - INFO - Epoch 1827 - supervised_loss/batch: 0.5196\n",
            "2025-11-03 09:58:04,989 - supervised_finetuning - INFO - Epoch 1827 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:58:04,990 - supervised_finetuning - INFO - Epoch 1827 - learning_rate: 0.0001\n",
            "Classifier Epoch 88/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5278, Acc=81.25%]2025-11-03 09:58:05,029 - supervised_finetuning - INFO - Epoch 1837 - supervised_loss/batch: 0.5278\n",
            "2025-11-03 09:58:05,029 - supervised_finetuning - INFO - Epoch 1837 - supervised_accuracy/batch: 81.2500\n",
            "2025-11-03 09:58:05,029 - supervised_finetuning - INFO - Epoch 1837 - learning_rate: 0.0001\n",
            "Classifier Epoch 88/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.4760, Acc=85.71%]2025-11-03 09:58:05,066 - supervised_finetuning - INFO - Epoch 1847 - supervised_loss/batch: 0.4760\n",
            "2025-11-03 09:58:05,066 - supervised_finetuning - INFO - Epoch 1847 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:05,066 - supervised_finetuning - INFO - Epoch 1847 - learning_rate: 0.0001\n",
            "Classifier Epoch 88/100: 100% 21/21 [00:00<00:00, 254.93it/s, Loss=0.4760, Acc=85.71%]\n",
            "2025-11-03 09:58:05,078 - supervised_finetuning - INFO - Epoch 88:\n",
            "2025-11-03 09:58:05,078 - supervised_finetuning - INFO -   Train Loss: 0.6121, Train Acc: 75.37%\n",
            "2025-11-03 09:58:05,078 - supervised_finetuning - INFO -   Train F1: 75.24%, Train Recall: 75.37%\n",
            "2025-11-03 09:58:05,078 - supervised_finetuning - INFO -   Train Precision: 76.12%\n",
            "2025-11-03 09:58:05,079 - supervised_finetuning - INFO - Epoch 87 - supervised_loss/epoch: 0.6121\n",
            "2025-11-03 09:58:05,079 - supervised_finetuning - INFO - Epoch 87 - supervised_accuracy/epoch: 75.3691\n",
            "2025-11-03 09:58:05,079 - supervised_finetuning - INFO - Epoch 87 - supervised_f1/epoch: 75.2442\n",
            "2025-11-03 09:58:05,079 - supervised_finetuning - INFO - Epoch 87 - supervised_recall/epoch: 75.3691\n",
            "2025-11-03 09:58:05,079 - supervised_finetuning - INFO - Epoch 87 - supervised_precision/epoch: 76.1198\n",
            "Classifier Epoch 89/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6801, Acc=76.56%]2025-11-03 09:58:05,084 - supervised_finetuning - INFO - Epoch 1848 - supervised_loss/batch: 0.6801\n",
            "2025-11-03 09:58:05,084 - supervised_finetuning - INFO - Epoch 1848 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:58:05,084 - supervised_finetuning - INFO - Epoch 1848 - learning_rate: 0.0001\n",
            "Classifier Epoch 89/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7760, Acc=67.19%]2025-11-03 09:58:05,122 - supervised_finetuning - INFO - Epoch 1858 - supervised_loss/batch: 0.7760\n",
            "2025-11-03 09:58:05,122 - supervised_finetuning - INFO - Epoch 1858 - supervised_accuracy/batch: 67.1875\n",
            "2025-11-03 09:58:05,123 - supervised_finetuning - INFO - Epoch 1858 - learning_rate: 0.0001\n",
            "Classifier Epoch 89/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5076, Acc=85.71%]2025-11-03 09:58:05,158 - supervised_finetuning - INFO - Epoch 1868 - supervised_loss/batch: 0.5076\n",
            "2025-11-03 09:58:05,159 - supervised_finetuning - INFO - Epoch 1868 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:05,159 - supervised_finetuning - INFO - Epoch 1868 - learning_rate: 0.0001\n",
            "Classifier Epoch 89/100: 100% 21/21 [00:00<00:00, 264.75it/s, Loss=0.5076, Acc=85.71%]\n",
            "2025-11-03 09:58:05,170 - supervised_finetuning - INFO - Epoch 89:\n",
            "2025-11-03 09:58:05,170 - supervised_finetuning - INFO -   Train Loss: 0.6202, Train Acc: 75.68%\n",
            "2025-11-03 09:58:05,170 - supervised_finetuning - INFO -   Train F1: 75.41%, Train Recall: 75.68%\n",
            "2025-11-03 09:58:05,170 - supervised_finetuning - INFO -   Train Precision: 75.73%\n",
            "2025-11-03 09:58:05,170 - supervised_finetuning - INFO - Epoch 88 - supervised_loss/epoch: 0.6202\n",
            "2025-11-03 09:58:05,170 - supervised_finetuning - INFO - Epoch 88 - supervised_accuracy/epoch: 75.6799\n",
            "2025-11-03 09:58:05,171 - supervised_finetuning - INFO - Epoch 88 - supervised_f1/epoch: 75.4072\n",
            "2025-11-03 09:58:05,171 - supervised_finetuning - INFO - Epoch 88 - supervised_recall/epoch: 75.6799\n",
            "2025-11-03 09:58:05,171 - supervised_finetuning - INFO - Epoch 88 - supervised_precision/epoch: 75.7330\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "2025-11-03 09:58:05,833 - supervised_finetuning - INFO -   ✓ New best model saved! Train Acc: 75.68%\n",
            "Classifier Epoch 90/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6849, Acc=68.75%]2025-11-03 09:58:05,843 - supervised_finetuning - INFO - Epoch 1869 - supervised_loss/batch: 0.6849\n",
            "2025-11-03 09:58:05,843 - supervised_finetuning - INFO - Epoch 1869 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:58:05,843 - supervised_finetuning - INFO - Epoch 1869 - learning_rate: 0.0001\n",
            "Classifier Epoch 90/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6149, Acc=76.56%]2025-11-03 09:58:05,881 - supervised_finetuning - INFO - Epoch 1879 - supervised_loss/batch: 0.6149\n",
            "2025-11-03 09:58:05,881 - supervised_finetuning - INFO - Epoch 1879 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:58:05,881 - supervised_finetuning - INFO - Epoch 1879 - learning_rate: 0.0001\n",
            "Classifier Epoch 90/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6197, Acc=85.71%]2025-11-03 09:58:05,918 - supervised_finetuning - INFO - Epoch 1889 - supervised_loss/batch: 0.6197\n",
            "2025-11-03 09:58:05,918 - supervised_finetuning - INFO - Epoch 1889 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:05,918 - supervised_finetuning - INFO - Epoch 1889 - learning_rate: 0.0001\n",
            "Classifier Epoch 90/100: 100% 21/21 [00:00<00:00, 247.38it/s, Loss=0.6197, Acc=85.71%]\n",
            "2025-11-03 09:58:05,929 - supervised_finetuning - INFO - Epoch 90:\n",
            "2025-11-03 09:58:05,929 - supervised_finetuning - INFO -   Train Loss: 0.6220, Train Acc: 75.68%\n",
            "2025-11-03 09:58:05,929 - supervised_finetuning - INFO -   Train F1: 75.54%, Train Recall: 75.68%\n",
            "2025-11-03 09:58:05,929 - supervised_finetuning - INFO -   Train Precision: 75.98%\n",
            "2025-11-03 09:58:05,929 - supervised_finetuning - INFO - Epoch 89 - supervised_loss/epoch: 0.6220\n",
            "2025-11-03 09:58:05,929 - supervised_finetuning - INFO - Epoch 89 - supervised_accuracy/epoch: 75.6799\n",
            "2025-11-03 09:58:05,930 - supervised_finetuning - INFO - Epoch 89 - supervised_f1/epoch: 75.5448\n",
            "2025-11-03 09:58:05,930 - supervised_finetuning - INFO - Epoch 89 - supervised_recall/epoch: 75.6799\n",
            "2025-11-03 09:58:05,930 - supervised_finetuning - INFO - Epoch 89 - supervised_precision/epoch: 75.9765\n",
            "Classifier Epoch 91/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6554, Acc=75.00%]2025-11-03 09:58:05,934 - supervised_finetuning - INFO - Epoch 1890 - supervised_loss/batch: 0.6554\n",
            "2025-11-03 09:58:05,934 - supervised_finetuning - INFO - Epoch 1890 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:58:05,935 - supervised_finetuning - INFO - Epoch 1890 - learning_rate: 0.0001\n",
            "Classifier Epoch 91/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5000, Acc=79.69%]2025-11-03 09:58:05,976 - supervised_finetuning - INFO - Epoch 1900 - supervised_loss/batch: 0.5000\n",
            "2025-11-03 09:58:05,976 - supervised_finetuning - INFO - Epoch 1900 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:58:05,976 - supervised_finetuning - INFO - Epoch 1900 - learning_rate: 0.0001\n",
            "Classifier Epoch 91/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.2046, Acc=100.00%]2025-11-03 09:58:06,012 - supervised_finetuning - INFO - Epoch 1910 - supervised_loss/batch: 0.2046\n",
            "2025-11-03 09:58:06,012 - supervised_finetuning - INFO - Epoch 1910 - supervised_accuracy/batch: 100.0000\n",
            "2025-11-03 09:58:06,012 - supervised_finetuning - INFO - Epoch 1910 - learning_rate: 0.0001\n",
            "Classifier Epoch 91/100: 100% 21/21 [00:00<00:00, 255.18it/s, Loss=0.2046, Acc=100.00%]\n",
            "2025-11-03 09:58:06,022 - supervised_finetuning - INFO - Epoch 91:\n",
            "2025-11-03 09:58:06,022 - supervised_finetuning - INFO -   Train Loss: 0.6038, Train Acc: 75.29%\n",
            "2025-11-03 09:58:06,023 - supervised_finetuning - INFO -   Train F1: 75.20%, Train Recall: 75.29%\n",
            "2025-11-03 09:58:06,023 - supervised_finetuning - INFO -   Train Precision: 75.49%\n",
            "2025-11-03 09:58:06,023 - supervised_finetuning - INFO - Epoch 90 - supervised_loss/epoch: 0.6038\n",
            "2025-11-03 09:58:06,023 - supervised_finetuning - INFO - Epoch 90 - supervised_accuracy/epoch: 75.2914\n",
            "2025-11-03 09:58:06,023 - supervised_finetuning - INFO - Epoch 90 - supervised_f1/epoch: 75.1967\n",
            "2025-11-03 09:58:06,023 - supervised_finetuning - INFO - Epoch 90 - supervised_recall/epoch: 75.2914\n",
            "2025-11-03 09:58:06,024 - supervised_finetuning - INFO - Epoch 90 - supervised_precision/epoch: 75.4868\n",
            "Classifier Epoch 92/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6303, Acc=70.31%]2025-11-03 09:58:06,028 - supervised_finetuning - INFO - Epoch 1911 - supervised_loss/batch: 0.6303\n",
            "2025-11-03 09:58:06,028 - supervised_finetuning - INFO - Epoch 1911 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:58:06,028 - supervised_finetuning - INFO - Epoch 1911 - learning_rate: 0.0001\n",
            "Classifier Epoch 92/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7348, Acc=71.88%]2025-11-03 09:58:06,066 - supervised_finetuning - INFO - Epoch 1921 - supervised_loss/batch: 0.7348\n",
            "2025-11-03 09:58:06,066 - supervised_finetuning - INFO - Epoch 1921 - supervised_accuracy/batch: 71.8750\n",
            "2025-11-03 09:58:06,066 - supervised_finetuning - INFO - Epoch 1921 - learning_rate: 0.0001\n",
            "Classifier Epoch 92/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8132, Acc=71.43%]2025-11-03 09:58:06,106 - supervised_finetuning - INFO - Epoch 1931 - supervised_loss/batch: 0.8132\n",
            "2025-11-03 09:58:06,106 - supervised_finetuning - INFO - Epoch 1931 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:06,106 - supervised_finetuning - INFO - Epoch 1931 - learning_rate: 0.0001\n",
            "Classifier Epoch 92/100: 100% 21/21 [00:00<00:00, 254.85it/s, Loss=0.8132, Acc=71.43%]\n",
            "2025-11-03 09:58:06,118 - supervised_finetuning - INFO - Epoch 92:\n",
            "2025-11-03 09:58:06,118 - supervised_finetuning - INFO -   Train Loss: 0.6215, Train Acc: 74.67%\n",
            "2025-11-03 09:58:06,118 - supervised_finetuning - INFO -   Train F1: 74.49%, Train Recall: 74.67%\n",
            "2025-11-03 09:58:06,118 - supervised_finetuning - INFO -   Train Precision: 74.79%\n",
            "2025-11-03 09:58:06,118 - supervised_finetuning - INFO - Epoch 91 - supervised_loss/epoch: 0.6215\n",
            "2025-11-03 09:58:06,119 - supervised_finetuning - INFO - Epoch 91 - supervised_accuracy/epoch: 74.6698\n",
            "2025-11-03 09:58:06,119 - supervised_finetuning - INFO - Epoch 91 - supervised_f1/epoch: 74.4945\n",
            "2025-11-03 09:58:06,119 - supervised_finetuning - INFO - Epoch 91 - supervised_recall/epoch: 74.6698\n",
            "2025-11-03 09:58:06,119 - supervised_finetuning - INFO - Epoch 91 - supervised_precision/epoch: 74.7886\n",
            "Classifier Epoch 93/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7799, Acc=70.31%]2025-11-03 09:58:06,126 - supervised_finetuning - INFO - Epoch 1932 - supervised_loss/batch: 0.7799\n",
            "2025-11-03 09:58:06,128 - supervised_finetuning - INFO - Epoch 1932 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:58:06,130 - supervised_finetuning - INFO - Epoch 1932 - learning_rate: 0.0001\n",
            "Classifier Epoch 93/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7498, Acc=68.75%]2025-11-03 09:58:06,174 - supervised_finetuning - INFO - Epoch 1942 - supervised_loss/batch: 0.7498\n",
            "2025-11-03 09:58:06,174 - supervised_finetuning - INFO - Epoch 1942 - supervised_accuracy/batch: 68.7500\n",
            "2025-11-03 09:58:06,174 - supervised_finetuning - INFO - Epoch 1942 - learning_rate: 0.0001\n",
            "Classifier Epoch 93/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.3534, Acc=42.86%]2025-11-03 09:58:06,218 - supervised_finetuning - INFO - Epoch 1952 - supervised_loss/batch: 1.3534\n",
            "2025-11-03 09:58:06,218 - supervised_finetuning - INFO - Epoch 1952 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:58:06,219 - supervised_finetuning - INFO - Epoch 1952 - learning_rate: 0.0001\n",
            "Classifier Epoch 93/100: 100% 21/21 [00:00<00:00, 211.28it/s, Loss=1.3534, Acc=42.86%]\n",
            "2025-11-03 09:58:06,229 - supervised_finetuning - INFO - Epoch 93:\n",
            "2025-11-03 09:58:06,229 - supervised_finetuning - INFO -   Train Loss: 0.6592, Train Acc: 74.36%\n",
            "2025-11-03 09:58:06,229 - supervised_finetuning - INFO -   Train F1: 74.20%, Train Recall: 74.36%\n",
            "2025-11-03 09:58:06,229 - supervised_finetuning - INFO -   Train Precision: 74.58%\n",
            "2025-11-03 09:58:06,229 - supervised_finetuning - INFO - Epoch 92 - supervised_loss/epoch: 0.6592\n",
            "2025-11-03 09:58:06,230 - supervised_finetuning - INFO - Epoch 92 - supervised_accuracy/epoch: 74.3590\n",
            "2025-11-03 09:58:06,230 - supervised_finetuning - INFO - Epoch 92 - supervised_f1/epoch: 74.2005\n",
            "2025-11-03 09:58:06,230 - supervised_finetuning - INFO - Epoch 92 - supervised_recall/epoch: 74.3590\n",
            "2025-11-03 09:58:06,230 - supervised_finetuning - INFO - Epoch 92 - supervised_precision/epoch: 74.5848\n",
            "Classifier Epoch 94/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7236, Acc=70.31%]2025-11-03 09:58:06,235 - supervised_finetuning - INFO - Epoch 1953 - supervised_loss/batch: 0.7236\n",
            "2025-11-03 09:58:06,235 - supervised_finetuning - INFO - Epoch 1953 - supervised_accuracy/batch: 70.3125\n",
            "2025-11-03 09:58:06,235 - supervised_finetuning - INFO - Epoch 1953 - learning_rate: 0.0001\n",
            "Classifier Epoch 94/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6098, Acc=78.12%]2025-11-03 09:58:06,271 - supervised_finetuning - INFO - Epoch 1963 - supervised_loss/batch: 0.6098\n",
            "2025-11-03 09:58:06,271 - supervised_finetuning - INFO - Epoch 1963 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:58:06,272 - supervised_finetuning - INFO - Epoch 1963 - learning_rate: 0.0001\n",
            "Classifier Epoch 94/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6823, Acc=71.43%]2025-11-03 09:58:06,307 - supervised_finetuning - INFO - Epoch 1973 - supervised_loss/batch: 0.6823\n",
            "2025-11-03 09:58:06,308 - supervised_finetuning - INFO - Epoch 1973 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:06,308 - supervised_finetuning - INFO - Epoch 1973 - learning_rate: 0.0001\n",
            "Classifier Epoch 94/100: 100% 21/21 [00:00<00:00, 270.15it/s, Loss=0.6823, Acc=71.43%]\n",
            "2025-11-03 09:58:06,318 - supervised_finetuning - INFO - Epoch 94:\n",
            "2025-11-03 09:58:06,318 - supervised_finetuning - INFO -   Train Loss: 0.6270, Train Acc: 75.45%\n",
            "2025-11-03 09:58:06,318 - supervised_finetuning - INFO -   Train F1: 75.14%, Train Recall: 75.45%\n",
            "2025-11-03 09:58:06,318 - supervised_finetuning - INFO -   Train Precision: 76.11%\n",
            "2025-11-03 09:58:06,319 - supervised_finetuning - INFO - Epoch 93 - supervised_loss/epoch: 0.6270\n",
            "2025-11-03 09:58:06,319 - supervised_finetuning - INFO - Epoch 93 - supervised_accuracy/epoch: 75.4468\n",
            "2025-11-03 09:58:06,319 - supervised_finetuning - INFO - Epoch 93 - supervised_f1/epoch: 75.1389\n",
            "2025-11-03 09:58:06,319 - supervised_finetuning - INFO - Epoch 93 - supervised_recall/epoch: 75.4468\n",
            "2025-11-03 09:58:06,319 - supervised_finetuning - INFO - Epoch 93 - supervised_precision/epoch: 76.1063\n",
            "Classifier Epoch 95/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5040, Acc=81.25%]2025-11-03 09:58:06,325 - supervised_finetuning - INFO - Epoch 1974 - supervised_loss/batch: 0.5040\n",
            "2025-11-03 09:58:06,325 - supervised_finetuning - INFO - Epoch 1974 - supervised_accuracy/batch: 81.2500\n",
            "2025-11-03 09:58:06,325 - supervised_finetuning - INFO - Epoch 1974 - learning_rate: 0.0001\n",
            "Classifier Epoch 95/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6936, Acc=73.44%]2025-11-03 09:58:06,371 - supervised_finetuning - INFO - Epoch 1984 - supervised_loss/batch: 0.6936\n",
            "2025-11-03 09:58:06,371 - supervised_finetuning - INFO - Epoch 1984 - supervised_accuracy/batch: 73.4375\n",
            "2025-11-03 09:58:06,372 - supervised_finetuning - INFO - Epoch 1984 - learning_rate: 0.0001\n",
            "Classifier Epoch 95/100:   0% 0/21 [00:00<?, ?it/s, Loss=1.7842, Acc=42.86%]2025-11-03 09:58:06,409 - supervised_finetuning - INFO - Epoch 1994 - supervised_loss/batch: 1.7842\n",
            "2025-11-03 09:58:06,409 - supervised_finetuning - INFO - Epoch 1994 - supervised_accuracy/batch: 42.8571\n",
            "2025-11-03 09:58:06,409 - supervised_finetuning - INFO - Epoch 1994 - learning_rate: 0.0001\n",
            "Classifier Epoch 95/100: 100% 21/21 [00:00<00:00, 234.07it/s, Loss=1.7842, Acc=42.86%]\n",
            "2025-11-03 09:58:06,419 - supervised_finetuning - INFO - Epoch 95:\n",
            "2025-11-03 09:58:06,420 - supervised_finetuning - INFO -   Train Loss: 0.6821, Train Acc: 73.97%\n",
            "2025-11-03 09:58:06,420 - supervised_finetuning - INFO -   Train F1: 73.89%, Train Recall: 73.97%\n",
            "2025-11-03 09:58:06,420 - supervised_finetuning - INFO -   Train Precision: 74.04%\n",
            "2025-11-03 09:58:06,420 - supervised_finetuning - INFO - Epoch 94 - supervised_loss/epoch: 0.6821\n",
            "2025-11-03 09:58:06,420 - supervised_finetuning - INFO - Epoch 94 - supervised_accuracy/epoch: 73.9705\n",
            "2025-11-03 09:58:06,420 - supervised_finetuning - INFO - Epoch 94 - supervised_f1/epoch: 73.8888\n",
            "2025-11-03 09:58:06,421 - supervised_finetuning - INFO - Epoch 94 - supervised_recall/epoch: 73.9705\n",
            "2025-11-03 09:58:06,421 - supervised_finetuning - INFO - Epoch 94 - supervised_precision/epoch: 74.0405\n",
            "Classifier Epoch 96/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5505, Acc=82.81%]2025-11-03 09:58:06,425 - supervised_finetuning - INFO - Epoch 1995 - supervised_loss/batch: 0.5505\n",
            "2025-11-03 09:58:06,426 - supervised_finetuning - INFO - Epoch 1995 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:58:06,426 - supervised_finetuning - INFO - Epoch 1995 - learning_rate: 0.0001\n",
            "Classifier Epoch 96/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5385, Acc=79.69%]2025-11-03 09:58:06,464 - supervised_finetuning - INFO - Epoch 2005 - supervised_loss/batch: 0.5385\n",
            "2025-11-03 09:58:06,464 - supervised_finetuning - INFO - Epoch 2005 - supervised_accuracy/batch: 79.6875\n",
            "2025-11-03 09:58:06,464 - supervised_finetuning - INFO - Epoch 2005 - learning_rate: 0.0001\n",
            "Classifier Epoch 96/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8154, Acc=57.14%]2025-11-03 09:58:06,502 - supervised_finetuning - INFO - Epoch 2015 - supervised_loss/batch: 0.8154\n",
            "2025-11-03 09:58:06,502 - supervised_finetuning - INFO - Epoch 2015 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:58:06,503 - supervised_finetuning - INFO - Epoch 2015 - learning_rate: 0.0001\n",
            "Classifier Epoch 96/100: 100% 21/21 [00:00<00:00, 257.47it/s, Loss=0.8154, Acc=57.14%]\n",
            "2025-11-03 09:58:06,515 - supervised_finetuning - INFO - Epoch 96:\n",
            "2025-11-03 09:58:06,515 - supervised_finetuning - INFO -   Train Loss: 0.6433, Train Acc: 73.66%\n",
            "2025-11-03 09:58:06,515 - supervised_finetuning - INFO -   Train F1: 73.36%, Train Recall: 73.66%\n",
            "2025-11-03 09:58:06,515 - supervised_finetuning - INFO -   Train Precision: 73.69%\n",
            "2025-11-03 09:58:06,515 - supervised_finetuning - INFO - Epoch 95 - supervised_loss/epoch: 0.6433\n",
            "2025-11-03 09:58:06,515 - supervised_finetuning - INFO - Epoch 95 - supervised_accuracy/epoch: 73.6597\n",
            "2025-11-03 09:58:06,516 - supervised_finetuning - INFO - Epoch 95 - supervised_f1/epoch: 73.3635\n",
            "2025-11-03 09:58:06,516 - supervised_finetuning - INFO - Epoch 95 - supervised_recall/epoch: 73.6597\n",
            "2025-11-03 09:58:06,516 - supervised_finetuning - INFO - Epoch 95 - supervised_precision/epoch: 73.6931\n",
            "Classifier Epoch 97/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6109, Acc=75.00%]2025-11-03 09:58:06,521 - supervised_finetuning - INFO - Epoch 2016 - supervised_loss/batch: 0.6109\n",
            "2025-11-03 09:58:06,521 - supervised_finetuning - INFO - Epoch 2016 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:58:06,521 - supervised_finetuning - INFO - Epoch 2016 - learning_rate: 0.0001\n",
            "Classifier Epoch 97/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5170, Acc=81.25%]2025-11-03 09:58:06,566 - supervised_finetuning - INFO - Epoch 2026 - supervised_loss/batch: 0.5170\n",
            "2025-11-03 09:58:06,566 - supervised_finetuning - INFO - Epoch 2026 - supervised_accuracy/batch: 81.2500\n",
            "2025-11-03 09:58:06,566 - supervised_finetuning - INFO - Epoch 2026 - learning_rate: 0.0001\n",
            "Classifier Epoch 97/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.8638, Acc=57.14%]2025-11-03 09:58:06,606 - supervised_finetuning - INFO - Epoch 2036 - supervised_loss/batch: 0.8638\n",
            "2025-11-03 09:58:06,606 - supervised_finetuning - INFO - Epoch 2036 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:58:06,606 - supervised_finetuning - INFO - Epoch 2036 - learning_rate: 0.0001\n",
            "Classifier Epoch 97/100: 100% 21/21 [00:00<00:00, 233.61it/s, Loss=0.8638, Acc=57.14%]\n",
            "2025-11-03 09:58:06,626 - supervised_finetuning - INFO - Epoch 97:\n",
            "2025-11-03 09:58:06,626 - supervised_finetuning - INFO -   Train Loss: 0.6231, Train Acc: 75.29%\n",
            "2025-11-03 09:58:06,626 - supervised_finetuning - INFO -   Train F1: 75.01%, Train Recall: 75.29%\n",
            "2025-11-03 09:58:06,626 - supervised_finetuning - INFO -   Train Precision: 76.23%\n",
            "2025-11-03 09:58:06,626 - supervised_finetuning - INFO - Epoch 96 - supervised_loss/epoch: 0.6231\n",
            "2025-11-03 09:58:06,627 - supervised_finetuning - INFO - Epoch 96 - supervised_accuracy/epoch: 75.2914\n",
            "2025-11-03 09:58:06,627 - supervised_finetuning - INFO - Epoch 96 - supervised_f1/epoch: 75.0127\n",
            "2025-11-03 09:58:06,627 - supervised_finetuning - INFO - Epoch 96 - supervised_recall/epoch: 75.2914\n",
            "2025-11-03 09:58:06,627 - supervised_finetuning - INFO - Epoch 96 - supervised_precision/epoch: 76.2314\n",
            "Classifier Epoch 98/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5692, Acc=76.56%]2025-11-03 09:58:06,634 - supervised_finetuning - INFO - Epoch 2037 - supervised_loss/batch: 0.5692\n",
            "2025-11-03 09:58:06,634 - supervised_finetuning - INFO - Epoch 2037 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:58:06,634 - supervised_finetuning - INFO - Epoch 2037 - learning_rate: 0.0001\n",
            "Classifier Epoch 98/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5289, Acc=82.81%]2025-11-03 09:58:06,688 - supervised_finetuning - INFO - Epoch 2047 - supervised_loss/batch: 0.5289\n",
            "2025-11-03 09:58:06,688 - supervised_finetuning - INFO - Epoch 2047 - supervised_accuracy/batch: 82.8125\n",
            "2025-11-03 09:58:06,688 - supervised_finetuning - INFO - Epoch 2047 - learning_rate: 0.0001\n",
            "Classifier Epoch 98/100:  86% 18/21 [00:00<00:00, 177.62it/s, Loss=0.8194, Acc=71.43%]2025-11-03 09:58:06,744 - supervised_finetuning - INFO - Epoch 2057 - supervised_loss/batch: 0.8194\n",
            "2025-11-03 09:58:06,745 - supervised_finetuning - INFO - Epoch 2057 - supervised_accuracy/batch: 71.4286\n",
            "2025-11-03 09:58:06,745 - supervised_finetuning - INFO - Epoch 2057 - learning_rate: 0.0001\n",
            "Classifier Epoch 98/100: 100% 21/21 [00:00<00:00, 177.69it/s, Loss=0.8194, Acc=71.43%]\n",
            "2025-11-03 09:58:06,770 - supervised_finetuning - INFO - Epoch 98:\n",
            "2025-11-03 09:58:06,770 - supervised_finetuning - INFO -   Train Loss: 0.6352, Train Acc: 74.44%\n",
            "2025-11-03 09:58:06,770 - supervised_finetuning - INFO -   Train F1: 74.14%, Train Recall: 74.44%\n",
            "2025-11-03 09:58:06,770 - supervised_finetuning - INFO -   Train Precision: 74.42%\n",
            "2025-11-03 09:58:06,770 - supervised_finetuning - INFO - Epoch 97 - supervised_loss/epoch: 0.6352\n",
            "2025-11-03 09:58:06,771 - supervised_finetuning - INFO - Epoch 97 - supervised_accuracy/epoch: 74.4367\n",
            "2025-11-03 09:58:06,771 - supervised_finetuning - INFO - Epoch 97 - supervised_f1/epoch: 74.1412\n",
            "2025-11-03 09:58:06,771 - supervised_finetuning - INFO - Epoch 97 - supervised_recall/epoch: 74.4367\n",
            "2025-11-03 09:58:06,771 - supervised_finetuning - INFO - Epoch 97 - supervised_precision/epoch: 74.4244\n",
            "Classifier Epoch 99/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.5865, Acc=78.12%]2025-11-03 09:58:06,779 - supervised_finetuning - INFO - Epoch 2058 - supervised_loss/batch: 0.5865\n",
            "2025-11-03 09:58:06,780 - supervised_finetuning - INFO - Epoch 2058 - supervised_accuracy/batch: 78.1250\n",
            "2025-11-03 09:58:06,780 - supervised_finetuning - INFO - Epoch 2058 - learning_rate: 0.0001\n",
            "Classifier Epoch 99/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6599, Acc=75.00%]2025-11-03 09:58:06,830 - supervised_finetuning - INFO - Epoch 2068 - supervised_loss/batch: 0.6599\n",
            "2025-11-03 09:58:06,830 - supervised_finetuning - INFO - Epoch 2068 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:58:06,830 - supervised_finetuning - INFO - Epoch 2068 - learning_rate: 0.0001\n",
            "Classifier Epoch 99/100:  90% 19/21 [00:00<00:00, 187.96it/s, Loss=0.9408, Acc=57.14%]2025-11-03 09:58:06,882 - supervised_finetuning - INFO - Epoch 2078 - supervised_loss/batch: 0.9408\n",
            "2025-11-03 09:58:06,882 - supervised_finetuning - INFO - Epoch 2078 - supervised_accuracy/batch: 57.1429\n",
            "2025-11-03 09:58:06,882 - supervised_finetuning - INFO - Epoch 2078 - learning_rate: 0.0001\n",
            "Classifier Epoch 99/100: 100% 21/21 [00:00<00:00, 189.40it/s, Loss=0.9408, Acc=57.14%]\n",
            "2025-11-03 09:58:06,900 - supervised_finetuning - INFO - Epoch 99:\n",
            "2025-11-03 09:58:06,902 - supervised_finetuning - INFO -   Train Loss: 0.6423, Train Acc: 73.97%\n",
            "2025-11-03 09:58:06,902 - supervised_finetuning - INFO -   Train F1: 73.81%, Train Recall: 73.97%\n",
            "2025-11-03 09:58:06,902 - supervised_finetuning - INFO -   Train Precision: 74.53%\n",
            "2025-11-03 09:58:06,902 - supervised_finetuning - INFO - Epoch 98 - supervised_loss/epoch: 0.6423\n",
            "2025-11-03 09:58:06,902 - supervised_finetuning - INFO - Epoch 98 - supervised_accuracy/epoch: 73.9705\n",
            "2025-11-03 09:58:06,902 - supervised_finetuning - INFO - Epoch 98 - supervised_f1/epoch: 73.8119\n",
            "2025-11-03 09:58:06,903 - supervised_finetuning - INFO - Epoch 98 - supervised_recall/epoch: 73.9705\n",
            "2025-11-03 09:58:06,903 - supervised_finetuning - INFO - Epoch 98 - supervised_precision/epoch: 74.5330\n",
            "Classifier Epoch 100/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.6808, Acc=75.00%]2025-11-03 09:58:06,909 - supervised_finetuning - INFO - Epoch 2079 - supervised_loss/batch: 0.6808\n",
            "2025-11-03 09:58:06,909 - supervised_finetuning - INFO - Epoch 2079 - supervised_accuracy/batch: 75.0000\n",
            "2025-11-03 09:58:06,909 - supervised_finetuning - INFO - Epoch 2079 - learning_rate: 0.0001\n",
            "Classifier Epoch 100/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.7025, Acc=76.56%]2025-11-03 09:58:06,959 - supervised_finetuning - INFO - Epoch 2089 - supervised_loss/batch: 0.7025\n",
            "2025-11-03 09:58:06,959 - supervised_finetuning - INFO - Epoch 2089 - supervised_accuracy/batch: 76.5625\n",
            "2025-11-03 09:58:06,960 - supervised_finetuning - INFO - Epoch 2089 - learning_rate: 0.0001\n",
            "Classifier Epoch 100/100:   0% 0/21 [00:00<?, ?it/s, Loss=0.3417, Acc=85.71%]2025-11-03 09:58:07,006 - supervised_finetuning - INFO - Epoch 2099 - supervised_loss/batch: 0.3417\n",
            "2025-11-03 09:58:07,006 - supervised_finetuning - INFO - Epoch 2099 - supervised_accuracy/batch: 85.7143\n",
            "2025-11-03 09:58:07,006 - supervised_finetuning - INFO - Epoch 2099 - learning_rate: 0.0001\n",
            "Classifier Epoch 100/100: 100% 21/21 [00:00<00:00, 204.09it/s, Loss=0.3417, Acc=85.71%]\n",
            "2025-11-03 09:58:07,025 - supervised_finetuning - INFO - Epoch 100:\n",
            "2025-11-03 09:58:07,025 - supervised_finetuning - INFO -   Train Loss: 0.6161, Train Acc: 74.36%\n",
            "2025-11-03 09:58:07,025 - supervised_finetuning - INFO -   Train F1: 74.30%, Train Recall: 74.36%\n",
            "2025-11-03 09:58:07,025 - supervised_finetuning - INFO -   Train Precision: 75.06%\n",
            "2025-11-03 09:58:07,025 - supervised_finetuning - INFO - Epoch 99 - supervised_loss/epoch: 0.6161\n",
            "2025-11-03 09:58:07,025 - supervised_finetuning - INFO - Epoch 99 - supervised_accuracy/epoch: 74.3590\n",
            "2025-11-03 09:58:07,026 - supervised_finetuning - INFO - Epoch 99 - supervised_f1/epoch: 74.3023\n",
            "2025-11-03 09:58:07,026 - supervised_finetuning - INFO - Epoch 99 - supervised_recall/epoch: 74.3590\n",
            "2025-11-03 09:58:07,026 - supervised_finetuning - INFO - Epoch 99 - supervised_precision/epoch: 75.0649\n",
            "2025-11-03 09:58:08,785 - supervised_finetuning - INFO - Supervised fine-tuning completed! Best Train Acc: 75.68%\n",
            "2025-11-03 09:58:08,785 - supervised_finetuning - INFO - ✓ Encoder: FROZEN (contrastive features)\n",
            "2025-11-03 09:58:08,785 - supervised_finetuning - INFO - ✓ Classifier: TRAINED (on label features)\n",
            "2025-11-03 09:58:08,785 - supervised_finetuning - INFO - === TWO-STAGE Supervised Fine-tuning Finished ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Evaluation (5-class dataset)"
      ],
      "metadata": {
        "id": "eLS_xJ6dRy8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing / model evaluation:\n",
        "!python \"/content/SSCLNet-Implementation/eval.py\""
      ],
      "metadata": {
        "id": "c9GFNgJXRHML",
        "outputId": "5e3a32de-ebf6-4ea6-afb5-dc5c8fdbccfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-03 09:58:19.894738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762163899.926076   40230 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762163899.935869   40230 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762163899.958441   40230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762163899.958497   40230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762163899.958505   40230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762163899.958512   40230 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-03 09:58:19.965007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ All directories created\n",
            "✓ All directories created\n",
            "2025-11-03 09:58:24,291 - model_evaluation - INFO - === Model Evaluation on Test Set ===\n",
            "================================================================================\n",
            "MODEL SUMMARY\n",
            "================================================================================\n",
            "Model: SSCLNet\n",
            "Total trainable parameters: 25,669,541\n",
            "Model size: 98.12 MB\n",
            "\n",
            "Layer breakdown:\n",
            "  encoder.conv1.weight: 3,136\n",
            "  encoder.bn1.weight: 64\n",
            "  encoder.bn1.bias: 64\n",
            "  encoder.layer1.0.conv1.weight: 4,096\n",
            "  encoder.layer1.0.bn1.weight: 64\n",
            "  encoder.layer1.0.bn1.bias: 64\n",
            "  encoder.layer1.0.conv2.weight: 36,864\n",
            "  encoder.layer1.0.bn2.weight: 64\n",
            "  encoder.layer1.0.bn2.bias: 64\n",
            "  encoder.layer1.0.conv3.weight: 16,384\n",
            "  encoder.layer1.0.bn3.weight: 256\n",
            "  encoder.layer1.0.bn3.bias: 256\n",
            "  encoder.layer1.0.downsample.0.weight: 16,384\n",
            "  encoder.layer1.0.downsample.1.weight: 256\n",
            "  encoder.layer1.0.downsample.1.bias: 256\n",
            "  encoder.layer1.1.conv1.weight: 16,384\n",
            "  encoder.layer1.1.bn1.weight: 64\n",
            "  encoder.layer1.1.bn1.bias: 64\n",
            "  encoder.layer1.1.conv2.weight: 36,864\n",
            "  encoder.layer1.1.bn2.weight: 64\n",
            "  encoder.layer1.1.bn2.bias: 64\n",
            "  encoder.layer1.1.conv3.weight: 16,384\n",
            "  encoder.layer1.1.bn3.weight: 256\n",
            "  encoder.layer1.1.bn3.bias: 256\n",
            "  encoder.layer1.2.conv1.weight: 16,384\n",
            "  encoder.layer1.2.bn1.weight: 64\n",
            "  encoder.layer1.2.bn1.bias: 64\n",
            "  encoder.layer1.2.conv2.weight: 36,864\n",
            "  encoder.layer1.2.bn2.weight: 64\n",
            "  encoder.layer1.2.bn2.bias: 64\n",
            "  encoder.layer1.2.conv3.weight: 16,384\n",
            "  encoder.layer1.2.bn3.weight: 256\n",
            "  encoder.layer1.2.bn3.bias: 256\n",
            "  encoder.layer2.0.conv1.weight: 32,768\n",
            "  encoder.layer2.0.bn1.weight: 128\n",
            "  encoder.layer2.0.bn1.bias: 128\n",
            "  encoder.layer2.0.conv2.weight: 147,456\n",
            "  encoder.layer2.0.bn2.weight: 128\n",
            "  encoder.layer2.0.bn2.bias: 128\n",
            "  encoder.layer2.0.conv3.weight: 65,536\n",
            "  encoder.layer2.0.bn3.weight: 512\n",
            "  encoder.layer2.0.bn3.bias: 512\n",
            "  encoder.layer2.0.downsample.0.weight: 131,072\n",
            "  encoder.layer2.0.downsample.1.weight: 512\n",
            "  encoder.layer2.0.downsample.1.bias: 512\n",
            "  encoder.layer2.1.conv1.weight: 65,536\n",
            "  encoder.layer2.1.bn1.weight: 128\n",
            "  encoder.layer2.1.bn1.bias: 128\n",
            "  encoder.layer2.1.conv2.weight: 147,456\n",
            "  encoder.layer2.1.bn2.weight: 128\n",
            "  encoder.layer2.1.bn2.bias: 128\n",
            "  encoder.layer2.1.conv3.weight: 65,536\n",
            "  encoder.layer2.1.bn3.weight: 512\n",
            "  encoder.layer2.1.bn3.bias: 512\n",
            "  encoder.layer2.2.conv1.weight: 65,536\n",
            "  encoder.layer2.2.bn1.weight: 128\n",
            "  encoder.layer2.2.bn1.bias: 128\n",
            "  encoder.layer2.2.conv2.weight: 147,456\n",
            "  encoder.layer2.2.bn2.weight: 128\n",
            "  encoder.layer2.2.bn2.bias: 128\n",
            "  encoder.layer2.2.conv3.weight: 65,536\n",
            "  encoder.layer2.2.bn3.weight: 512\n",
            "  encoder.layer2.2.bn3.bias: 512\n",
            "  encoder.layer2.3.conv1.weight: 65,536\n",
            "  encoder.layer2.3.bn1.weight: 128\n",
            "  encoder.layer2.3.bn1.bias: 128\n",
            "  encoder.layer2.3.conv2.weight: 147,456\n",
            "  encoder.layer2.3.bn2.weight: 128\n",
            "  encoder.layer2.3.bn2.bias: 128\n",
            "  encoder.layer2.3.conv3.weight: 65,536\n",
            "  encoder.layer2.3.bn3.weight: 512\n",
            "  encoder.layer2.3.bn3.bias: 512\n",
            "  encoder.layer3.0.conv1.weight: 131,072\n",
            "  encoder.layer3.0.bn1.weight: 256\n",
            "  encoder.layer3.0.bn1.bias: 256\n",
            "  encoder.layer3.0.conv2.weight: 589,824\n",
            "  encoder.layer3.0.bn2.weight: 256\n",
            "  encoder.layer3.0.bn2.bias: 256\n",
            "  encoder.layer3.0.conv3.weight: 262,144\n",
            "  encoder.layer3.0.bn3.weight: 1,024\n",
            "  encoder.layer3.0.bn3.bias: 1,024\n",
            "  encoder.layer3.0.downsample.0.weight: 524,288\n",
            "  encoder.layer3.0.downsample.1.weight: 1,024\n",
            "  encoder.layer3.0.downsample.1.bias: 1,024\n",
            "  encoder.layer3.1.conv1.weight: 262,144\n",
            "  encoder.layer3.1.bn1.weight: 256\n",
            "  encoder.layer3.1.bn1.bias: 256\n",
            "  encoder.layer3.1.conv2.weight: 589,824\n",
            "  encoder.layer3.1.bn2.weight: 256\n",
            "  encoder.layer3.1.bn2.bias: 256\n",
            "  encoder.layer3.1.conv3.weight: 262,144\n",
            "  encoder.layer3.1.bn3.weight: 1,024\n",
            "  encoder.layer3.1.bn3.bias: 1,024\n",
            "  encoder.layer3.2.conv1.weight: 262,144\n",
            "  encoder.layer3.2.bn1.weight: 256\n",
            "  encoder.layer3.2.bn1.bias: 256\n",
            "  encoder.layer3.2.conv2.weight: 589,824\n",
            "  encoder.layer3.2.bn2.weight: 256\n",
            "  encoder.layer3.2.bn2.bias: 256\n",
            "  encoder.layer3.2.conv3.weight: 262,144\n",
            "  encoder.layer3.2.bn3.weight: 1,024\n",
            "  encoder.layer3.2.bn3.bias: 1,024\n",
            "  encoder.layer3.3.conv1.weight: 262,144\n",
            "  encoder.layer3.3.bn1.weight: 256\n",
            "  encoder.layer3.3.bn1.bias: 256\n",
            "  encoder.layer3.3.conv2.weight: 589,824\n",
            "  encoder.layer3.3.bn2.weight: 256\n",
            "  encoder.layer3.3.bn2.bias: 256\n",
            "  encoder.layer3.3.conv3.weight: 262,144\n",
            "  encoder.layer3.3.bn3.weight: 1,024\n",
            "  encoder.layer3.3.bn3.bias: 1,024\n",
            "  encoder.layer3.4.conv1.weight: 262,144\n",
            "  encoder.layer3.4.bn1.weight: 256\n",
            "  encoder.layer3.4.bn1.bias: 256\n",
            "  encoder.layer3.4.conv2.weight: 589,824\n",
            "  encoder.layer3.4.bn2.weight: 256\n",
            "  encoder.layer3.4.bn2.bias: 256\n",
            "  encoder.layer3.4.conv3.weight: 262,144\n",
            "  encoder.layer3.4.bn3.weight: 1,024\n",
            "  encoder.layer3.4.bn3.bias: 1,024\n",
            "  encoder.layer3.5.conv1.weight: 262,144\n",
            "  encoder.layer3.5.bn1.weight: 256\n",
            "  encoder.layer3.5.bn1.bias: 256\n",
            "  encoder.layer3.5.conv2.weight: 589,824\n",
            "  encoder.layer3.5.bn2.weight: 256\n",
            "  encoder.layer3.5.bn2.bias: 256\n",
            "  encoder.layer3.5.conv3.weight: 262,144\n",
            "  encoder.layer3.5.bn3.weight: 1,024\n",
            "  encoder.layer3.5.bn3.bias: 1,024\n",
            "  encoder.layer4.0.conv1.weight: 524,288\n",
            "  encoder.layer4.0.bn1.weight: 512\n",
            "  encoder.layer4.0.bn1.bias: 512\n",
            "  encoder.layer4.0.conv2.weight: 2,359,296\n",
            "  encoder.layer4.0.bn2.weight: 512\n",
            "  encoder.layer4.0.bn2.bias: 512\n",
            "  encoder.layer4.0.conv3.weight: 1,048,576\n",
            "  encoder.layer4.0.bn3.weight: 2,048\n",
            "  encoder.layer4.0.bn3.bias: 2,048\n",
            "  encoder.layer4.0.downsample.0.weight: 2,097,152\n",
            "  encoder.layer4.0.downsample.1.weight: 2,048\n",
            "  encoder.layer4.0.downsample.1.bias: 2,048\n",
            "  encoder.layer4.1.conv1.weight: 1,048,576\n",
            "  encoder.layer4.1.bn1.weight: 512\n",
            "  encoder.layer4.1.bn1.bias: 512\n",
            "  encoder.layer4.1.conv2.weight: 2,359,296\n",
            "  encoder.layer4.1.bn2.weight: 512\n",
            "  encoder.layer4.1.bn2.bias: 512\n",
            "  encoder.layer4.1.conv3.weight: 1,048,576\n",
            "  encoder.layer4.1.bn3.weight: 2,048\n",
            "  encoder.layer4.1.bn3.bias: 2,048\n",
            "  encoder.layer4.2.conv1.weight: 1,048,576\n",
            "  encoder.layer4.2.bn1.weight: 512\n",
            "  encoder.layer4.2.bn1.bias: 512\n",
            "  encoder.layer4.2.conv2.weight: 2,359,296\n",
            "  encoder.layer4.2.bn2.weight: 512\n",
            "  encoder.layer4.2.bn2.bias: 512\n",
            "  encoder.layer4.2.conv3.weight: 1,048,576\n",
            "  encoder.layer4.2.bn3.weight: 2,048\n",
            "  encoder.layer4.2.bn3.bias: 2,048\n",
            "  projection_head.mlp.0.weight: 1,048,576\n",
            "  projection_head.mlp.0.bias: 512\n",
            "  projection_head.mlp.2.weight: 262,144\n",
            "  projection_head.mlp.2.bias: 512\n",
            "  projection_head.mlp.4.weight: 131,072\n",
            "  projection_head.mlp.4.bias: 256\n",
            "  projection_head.mlp.6.weight: 65,536\n",
            "  projection_head.mlp.6.bias: 256\n",
            "  projection_head.mlp.9.weight: 8,192\n",
            "  projection_head.mlp.9.bias: 32\n",
            "  classifier.classifier.0.weight: 524,288\n",
            "  classifier.classifier.0.bias: 256\n",
            "  classifier.classifier.2.weight: 65,536\n",
            "  classifier.classifier.2.bias: 256\n",
            "  classifier.classifier.4.weight: 32,768\n",
            "  classifier.classifier.4.bias: 128\n",
            "  classifier.classifier.6.weight: 16,384\n",
            "  classifier.classifier.6.bias: 128\n",
            "  classifier.classifier.8.weight: 8,192\n",
            "  classifier.classifier.8.bias: 64\n",
            "  classifier.classifier.10.weight: 2,048\n",
            "  classifier.classifier.10.bias: 32\n",
            "  classifier.classifier.12.weight: 512\n",
            "  classifier.classifier.12.bias: 16\n",
            "  classifier.classifier.14.weight: 80\n",
            "  classifier.classifier.14.bias: 5\n",
            "================================================================================\n",
            "Created test DataLoader:\n",
            "  - Batch size: 64\n",
            "  - Shuffle: False\n",
            "  - Workers: 2\n",
            "  - Classes: ['Glioblastoma', 'glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
            "  - Number of samples: 655\n",
            "==================================================\n",
            "DATASET ANALYSIS\n",
            "==================================================\n",
            "Total samples: 655\n",
            "Class distribution:\n",
            "  Glioblastoma: 90 (13.7%)\n",
            "  glioma_tumor: 149 (22.7%)\n",
            "  meningioma_tumor: 163 (24.9%)\n",
            "  no_tumor: 95 (14.5%)\n",
            "  pituitary_tumor: 158 (24.1%)\n",
            "2025-11-03 09:58:26,158 - model_evaluation - INFO - Evaluating on 655 test samples\n",
            "2025-11-03 09:58:26,158 - model_evaluation - INFO - Running evaluation on test set...\n",
            "2025-11-03 09:58:28,441 - model_evaluation - INFO - Processed 10/11 batches\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - \n",
            "==================================================\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - FINAL TEST RESULTS\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - ==================================================\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - Test Loss: 0.7112\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - Test Accuracy: 70.99%\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - Test Precision: 71.93%\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - Test Recall: 70.99%\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - Test F1-Score: 70.77%\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - ==================================================\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - \n",
            "DETAILED CLASSIFICATION REPORT:\n",
            "2025-11-03 09:58:28,534 - model_evaluation - INFO - ==================================================\n",
            "2025-11-03 09:58:28,541 - model_evaluation - INFO - \n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Glioblastoma       0.87      0.96      0.91        90\n",
            "    glioma_tumor       0.70      0.51      0.59       149\n",
            "meningioma_tumor       0.55      0.71      0.62       163\n",
            "        no_tumor       0.75      0.63      0.69        95\n",
            " pituitary_tumor       0.81      0.81      0.81       158\n",
            "\n",
            "        accuracy                           0.71       655\n",
            "       macro avg       0.74      0.72      0.72       655\n",
            "    weighted avg       0.72      0.71      0.71       655\n",
            "\n",
            "2025-11-03 09:58:28,541 - model_evaluation - INFO - \n",
            "CONFUSION MATRIX:\n",
            "2025-11-03 09:58:28,541 - model_evaluation - INFO - ==================================================\n",
            "2025-11-03 09:58:28,548 - model_evaluation - INFO - \n",
            "[[ 86   2   2   0   0]\n",
            " [  5  76  51   2  15]\n",
            " [  5  15 115  15  13]\n",
            " [  2   2  28  60   3]\n",
            " [  1  13  13   3 128]]\n",
            "2025-11-03 09:58:29,279 - model_evaluation - INFO - Confusion matrix saved as 'plots/confusion_matrix.png'\n",
            "2025-11-03 09:58:29,279 - model_evaluation - INFO - \n",
            "==================================================\n",
            "2025-11-03 09:58:29,279 - model_evaluation - INFO - ROC CURVE ANALYSIS\n",
            "2025-11-03 09:58:29,279 - model_evaluation - INFO - ==================================================\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - ROC curve saved as 'plots/roc_curve.png'\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - \n",
            "AUC Scores:\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO -   Glioblastoma: 0.9956\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO -   glioma_tumor: 0.8565\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO -   meningioma_tumor: 0.8414\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO -   no_tumor: 0.9553\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO -   pituitary_tumor: 0.9607\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO -   Micro-average: 0.9341\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - \n",
            "PER-CLASS ACCURACY:\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - ==================================================\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - Glioblastoma: 95.56%\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - glioma_tumor: 51.01%\n",
            "2025-11-03 09:58:30,184 - model_evaluation - INFO - meningioma_tumor: 70.55%\n",
            "2025-11-03 09:58:30,185 - model_evaluation - INFO - no_tumor: 63.16%\n",
            "2025-11-03 09:58:30,185 - model_evaluation - INFO - pituitary_tumor: 81.01%\n",
            "2025-11-03 09:58:30,185 - model_evaluation - INFO - === Model Evaluation Completed ===\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "✓ Results saved to: results/final_evaluation_results.json\n",
            "\n",
            "✓ Evaluation completed! Check:\n",
            "  - logs/model_evaluation.log for detailed logs\n",
            "  - results/final_evaluation_results.json for comprehensive results\n",
            "  - plots/ for confusion matrix and ROC curves\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deleting the previously created folder \"SSCLNet-implementation-outputs\" and recreating it and saving everything in one go\n",
        "# !rm -rf '/content/SSCLNet-implementation-outputs'"
      ],
      "metadata": {
        "id": "01U705WVwBHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving it all for backup\n",
        "import os\n",
        "\n",
        "# Make a new folder in Colab’s /content directory\n",
        "new_folder = \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "os.makedirs(new_folder, exist_ok=True)\n",
        "\n",
        "print(f\"Created: {new_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8A-xGk59EGK",
        "outputId": "1c3061e6-ecac-4824-ec10-afcf31e7d933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: /content/SSCLNet-implementation-outputs/5-class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/checkpoints \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/configs \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/logs \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/models \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/plots \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/results \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/runs \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "!cp -r /content/training_output \"/content/SSCLNet-implementation-outputs/5-class\"\n",
        "\n",
        "!zip -r SSCLNet_implementation_outputs_5Class.zip \"/content/SSCLNet-implementation-outputs/5-class\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbTOpWny9av5",
        "outputId": "8f7f9a5b-2382-4267-e987-df9c6709628a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/SSCLNet-implementation-outputs/5-class/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/results/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/results/final_evaluation_results.json (deflated 59%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/results/test_results.txt (deflated 42%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/contrastive_pretraining/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/contrastive_pretraining/events.out.tfevents.1762154879.464ac1c992af.1469.0 (deflated 72%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/supervised_finetuning/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/supervised_finetuning/events.out.tfevents.1762163829.464ac1c992af.39845.0 (deflated 75%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/model_evaluation/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/runs/model_evaluation/events.out.tfevents.1762163904.464ac1c992af.40230.0 (deflated 9%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/logs/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/logs/contrastive_pretraining.log (deflated 89%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/logs/model_evaluation.log (deflated 79%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/logs/supervised_finetuning.log (deflated 91%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/supervised_training/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/supervised_training/models/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/supervised_training/models/brain_mri_5class/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/supervised_training/models/brain_mri_5class/supervised_final.pth (deflated 7%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/contrastive_training/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/contrastive_training/models/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/training_output/contrastive_training/models/contrastive_pretrained.pth (deflated 7%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_89.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_9.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_25.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_45.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_19.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_38.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_21.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_37.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_12.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_7.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_72.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_8.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_26.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_16.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_10.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/contrastive_epoch_100.pth (deflated 9%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_11.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_42.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_85.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_59.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_76.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_28.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_65.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_75.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_6.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_15.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_30.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_4.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_3.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_29.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_5.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_13.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_46.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/contrastive_epoch_80.pth (deflated 9%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_17.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/contrastive_epoch_60.pth (deflated 9%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/contrastive_epoch_40.pth (deflated 9%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_39.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_34.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_1.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_62.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/contrastive_epoch_20.pth (deflated 9%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_20.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_87.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/checkpoints/supervised_best_epoch_53.pth (deflated 8%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/plots/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/plots/contrastive_loss.png (deflated 23%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/plots/supervised_training_history.png (deflated 25%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/plots/roc_curve.png (deflated 19%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/plots/class_distribution.png (deflated 25%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/plots/confusion_matrix.png (deflated 24%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/configs/ (stored 0%)\n",
            "  adding: content/SSCLNet-implementation-outputs/5-class/models/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k8q-vIaDJaY2",
        "outputId": "7159c636-bac9-4cdf-ac9c-8e4db9889b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv SSCLNet_implementation_outputs_5Class.zip \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "Y0w-YhNJJfBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training Phase 2 - Supervised Learning (2-class dataset)\n",
        "\n",
        "**Note:** Update the path to `TRAIN_DATA_PATH`, `TEST_DATA_PATH` and `NUM_CLASSES` in `config.py` to the 2-class dataset."
      ],
      "metadata": {
        "id": "9e3z70WhtXQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/SSCLNet-Implementation/train_supervised.py\""
      ],
      "metadata": {
        "id": "X3FjkH-kty4z",
        "outputId": "f4d8c9ad-caf3-4237-f341-6e1b49ec55ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-01 14:49:28.402390: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762008568.433642   59414 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762008568.440039   59414 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762008568.457087   59414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762008568.457146   59414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762008568.457152   59414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762008568.457155   59414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-01 14:49:28.462071: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ All directories created\n",
            "✓ All directories created\n",
            "✓ Random seed set to: 42\n",
            "2025-11-01 14:49:34,688 - supervised_finetuning - INFO - === Starting TWO-STAGE Supervised Fine-tuning ===\n",
            "Keys in file: odict_keys(['encoder.conv1.weight', 'encoder.bn1.weight', 'encoder.bn1.bias', 'encoder.bn1.running_mean', 'encoder.bn1.running_var', 'encoder.bn1.num_batches_tracked', 'encoder.layer1.0.conv1.weight', 'encoder.layer1.0.bn1.weight', 'encoder.layer1.0.bn1.bias', 'encoder.layer1.0.bn1.running_mean', 'encoder.layer1.0.bn1.running_var', 'encoder.layer1.0.bn1.num_batches_tracked', 'encoder.layer1.0.conv2.weight', 'encoder.layer1.0.bn2.weight', 'encoder.layer1.0.bn2.bias', 'encoder.layer1.0.bn2.running_mean', 'encoder.layer1.0.bn2.running_var', 'encoder.layer1.0.bn2.num_batches_tracked', 'encoder.layer1.0.conv3.weight', 'encoder.layer1.0.bn3.weight', 'encoder.layer1.0.bn3.bias', 'encoder.layer1.0.bn3.running_mean', 'encoder.layer1.0.bn3.running_var', 'encoder.layer1.0.bn3.num_batches_tracked', 'encoder.layer1.0.downsample.0.weight', 'encoder.layer1.0.downsample.1.weight', 'encoder.layer1.0.downsample.1.bias', 'encoder.layer1.0.downsample.1.running_mean', 'encoder.layer1.0.downsample.1.running_var', 'encoder.layer1.0.downsample.1.num_batches_tracked', 'encoder.layer1.1.conv1.weight', 'encoder.layer1.1.bn1.weight', 'encoder.layer1.1.bn1.bias', 'encoder.layer1.1.bn1.running_mean', 'encoder.layer1.1.bn1.running_var', 'encoder.layer1.1.bn1.num_batches_tracked', 'encoder.layer1.1.conv2.weight', 'encoder.layer1.1.bn2.weight', 'encoder.layer1.1.bn2.bias', 'encoder.layer1.1.bn2.running_mean', 'encoder.layer1.1.bn2.running_var', 'encoder.layer1.1.bn2.num_batches_tracked', 'encoder.layer1.1.conv3.weight', 'encoder.layer1.1.bn3.weight', 'encoder.layer1.1.bn3.bias', 'encoder.layer1.1.bn3.running_mean', 'encoder.layer1.1.bn3.running_var', 'encoder.layer1.1.bn3.num_batches_tracked', 'encoder.layer1.2.conv1.weight', 'encoder.layer1.2.bn1.weight', 'encoder.layer1.2.bn1.bias', 'encoder.layer1.2.bn1.running_mean', 'encoder.layer1.2.bn1.running_var', 'encoder.layer1.2.bn1.num_batches_tracked', 'encoder.layer1.2.conv2.weight', 'encoder.layer1.2.bn2.weight', 'encoder.layer1.2.bn2.bias', 'encoder.layer1.2.bn2.running_mean', 'encoder.layer1.2.bn2.running_var', 'encoder.layer1.2.bn2.num_batches_tracked', 'encoder.layer1.2.conv3.weight', 'encoder.layer1.2.bn3.weight', 'encoder.layer1.2.bn3.bias', 'encoder.layer1.2.bn3.running_mean', 'encoder.layer1.2.bn3.running_var', 'encoder.layer1.2.bn3.num_batches_tracked', 'encoder.layer2.0.conv1.weight', 'encoder.layer2.0.bn1.weight', 'encoder.layer2.0.bn1.bias', 'encoder.layer2.0.bn1.running_mean', 'encoder.layer2.0.bn1.running_var', 'encoder.layer2.0.bn1.num_batches_tracked', 'encoder.layer2.0.conv2.weight', 'encoder.layer2.0.bn2.weight', 'encoder.layer2.0.bn2.bias', 'encoder.layer2.0.bn2.running_mean', 'encoder.layer2.0.bn2.running_var', 'encoder.layer2.0.bn2.num_batches_tracked', 'encoder.layer2.0.conv3.weight', 'encoder.layer2.0.bn3.weight', 'encoder.layer2.0.bn3.bias', 'encoder.layer2.0.bn3.running_mean', 'encoder.layer2.0.bn3.running_var', 'encoder.layer2.0.bn3.num_batches_tracked', 'encoder.layer2.0.downsample.0.weight', 'encoder.layer2.0.downsample.1.weight', 'encoder.layer2.0.downsample.1.bias', 'encoder.layer2.0.downsample.1.running_mean', 'encoder.layer2.0.downsample.1.running_var', 'encoder.layer2.0.downsample.1.num_batches_tracked', 'encoder.layer2.1.conv1.weight', 'encoder.layer2.1.bn1.weight', 'encoder.layer2.1.bn1.bias', 'encoder.layer2.1.bn1.running_mean', 'encoder.layer2.1.bn1.running_var', 'encoder.layer2.1.bn1.num_batches_tracked', 'encoder.layer2.1.conv2.weight', 'encoder.layer2.1.bn2.weight', 'encoder.layer2.1.bn2.bias', 'encoder.layer2.1.bn2.running_mean', 'encoder.layer2.1.bn2.running_var', 'encoder.layer2.1.bn2.num_batches_tracked', 'encoder.layer2.1.conv3.weight', 'encoder.layer2.1.bn3.weight', 'encoder.layer2.1.bn3.bias', 'encoder.layer2.1.bn3.running_mean', 'encoder.layer2.1.bn3.running_var', 'encoder.layer2.1.bn3.num_batches_tracked', 'encoder.layer2.2.conv1.weight', 'encoder.layer2.2.bn1.weight', 'encoder.layer2.2.bn1.bias', 'encoder.layer2.2.bn1.running_mean', 'encoder.layer2.2.bn1.running_var', 'encoder.layer2.2.bn1.num_batches_tracked', 'encoder.layer2.2.conv2.weight', 'encoder.layer2.2.bn2.weight', 'encoder.layer2.2.bn2.bias', 'encoder.layer2.2.bn2.running_mean', 'encoder.layer2.2.bn2.running_var', 'encoder.layer2.2.bn2.num_batches_tracked', 'encoder.layer2.2.conv3.weight', 'encoder.layer2.2.bn3.weight', 'encoder.layer2.2.bn3.bias', 'encoder.layer2.2.bn3.running_mean', 'encoder.layer2.2.bn3.running_var', 'encoder.layer2.2.bn3.num_batches_tracked', 'encoder.layer2.3.conv1.weight', 'encoder.layer2.3.bn1.weight', 'encoder.layer2.3.bn1.bias', 'encoder.layer2.3.bn1.running_mean', 'encoder.layer2.3.bn1.running_var', 'encoder.layer2.3.bn1.num_batches_tracked', 'encoder.layer2.3.conv2.weight', 'encoder.layer2.3.bn2.weight', 'encoder.layer2.3.bn2.bias', 'encoder.layer2.3.bn2.running_mean', 'encoder.layer2.3.bn2.running_var', 'encoder.layer2.3.bn2.num_batches_tracked', 'encoder.layer2.3.conv3.weight', 'encoder.layer2.3.bn3.weight', 'encoder.layer2.3.bn3.bias', 'encoder.layer2.3.bn3.running_mean', 'encoder.layer2.3.bn3.running_var', 'encoder.layer2.3.bn3.num_batches_tracked', 'encoder.layer3.0.conv1.weight', 'encoder.layer3.0.bn1.weight', 'encoder.layer3.0.bn1.bias', 'encoder.layer3.0.bn1.running_mean', 'encoder.layer3.0.bn1.running_var', 'encoder.layer3.0.bn1.num_batches_tracked', 'encoder.layer3.0.conv2.weight', 'encoder.layer3.0.bn2.weight', 'encoder.layer3.0.bn2.bias', 'encoder.layer3.0.bn2.running_mean', 'encoder.layer3.0.bn2.running_var', 'encoder.layer3.0.bn2.num_batches_tracked', 'encoder.layer3.0.conv3.weight', 'encoder.layer3.0.bn3.weight', 'encoder.layer3.0.bn3.bias', 'encoder.layer3.0.bn3.running_mean', 'encoder.layer3.0.bn3.running_var', 'encoder.layer3.0.bn3.num_batches_tracked', 'encoder.layer3.0.downsample.0.weight', 'encoder.layer3.0.downsample.1.weight', 'encoder.layer3.0.downsample.1.bias', 'encoder.layer3.0.downsample.1.running_mean', 'encoder.layer3.0.downsample.1.running_var', 'encoder.layer3.0.downsample.1.num_batches_tracked', 'encoder.layer3.1.conv1.weight', 'encoder.layer3.1.bn1.weight', 'encoder.layer3.1.bn1.bias', 'encoder.layer3.1.bn1.running_mean', 'encoder.layer3.1.bn1.running_var', 'encoder.layer3.1.bn1.num_batches_tracked', 'encoder.layer3.1.conv2.weight', 'encoder.layer3.1.bn2.weight', 'encoder.layer3.1.bn2.bias', 'encoder.layer3.1.bn2.running_mean', 'encoder.layer3.1.bn2.running_var', 'encoder.layer3.1.bn2.num_batches_tracked', 'encoder.layer3.1.conv3.weight', 'encoder.layer3.1.bn3.weight', 'encoder.layer3.1.bn3.bias', 'encoder.layer3.1.bn3.running_mean', 'encoder.layer3.1.bn3.running_var', 'encoder.layer3.1.bn3.num_batches_tracked', 'encoder.layer3.2.conv1.weight', 'encoder.layer3.2.bn1.weight', 'encoder.layer3.2.bn1.bias', 'encoder.layer3.2.bn1.running_mean', 'encoder.layer3.2.bn1.running_var', 'encoder.layer3.2.bn1.num_batches_tracked', 'encoder.layer3.2.conv2.weight', 'encoder.layer3.2.bn2.weight', 'encoder.layer3.2.bn2.bias', 'encoder.layer3.2.bn2.running_mean', 'encoder.layer3.2.bn2.running_var', 'encoder.layer3.2.bn2.num_batches_tracked', 'encoder.layer3.2.conv3.weight', 'encoder.layer3.2.bn3.weight', 'encoder.layer3.2.bn3.bias', 'encoder.layer3.2.bn3.running_mean', 'encoder.layer3.2.bn3.running_var', 'encoder.layer3.2.bn3.num_batches_tracked', 'encoder.layer3.3.conv1.weight', 'encoder.layer3.3.bn1.weight', 'encoder.layer3.3.bn1.bias', 'encoder.layer3.3.bn1.running_mean', 'encoder.layer3.3.bn1.running_var', 'encoder.layer3.3.bn1.num_batches_tracked', 'encoder.layer3.3.conv2.weight', 'encoder.layer3.3.bn2.weight', 'encoder.layer3.3.bn2.bias', 'encoder.layer3.3.bn2.running_mean', 'encoder.layer3.3.bn2.running_var', 'encoder.layer3.3.bn2.num_batches_tracked', 'encoder.layer3.3.conv3.weight', 'encoder.layer3.3.bn3.weight', 'encoder.layer3.3.bn3.bias', 'encoder.layer3.3.bn3.running_mean', 'encoder.layer3.3.bn3.running_var', 'encoder.layer3.3.bn3.num_batches_tracked', 'encoder.layer3.4.conv1.weight', 'encoder.layer3.4.bn1.weight', 'encoder.layer3.4.bn1.bias', 'encoder.layer3.4.bn1.running_mean', 'encoder.layer3.4.bn1.running_var', 'encoder.layer3.4.bn1.num_batches_tracked', 'encoder.layer3.4.conv2.weight', 'encoder.layer3.4.bn2.weight', 'encoder.layer3.4.bn2.bias', 'encoder.layer3.4.bn2.running_mean', 'encoder.layer3.4.bn2.running_var', 'encoder.layer3.4.bn2.num_batches_tracked', 'encoder.layer3.4.conv3.weight', 'encoder.layer3.4.bn3.weight', 'encoder.layer3.4.bn3.bias', 'encoder.layer3.4.bn3.running_mean', 'encoder.layer3.4.bn3.running_var', 'encoder.layer3.4.bn3.num_batches_tracked', 'encoder.layer3.5.conv1.weight', 'encoder.layer3.5.bn1.weight', 'encoder.layer3.5.bn1.bias', 'encoder.layer3.5.bn1.running_mean', 'encoder.layer3.5.bn1.running_var', 'encoder.layer3.5.bn1.num_batches_tracked', 'encoder.layer3.5.conv2.weight', 'encoder.layer3.5.bn2.weight', 'encoder.layer3.5.bn2.bias', 'encoder.layer3.5.bn2.running_mean', 'encoder.layer3.5.bn2.running_var', 'encoder.layer3.5.bn2.num_batches_tracked', 'encoder.layer3.5.conv3.weight', 'encoder.layer3.5.bn3.weight', 'encoder.layer3.5.bn3.bias', 'encoder.layer3.5.bn3.running_mean', 'encoder.layer3.5.bn3.running_var', 'encoder.layer3.5.bn3.num_batches_tracked', 'encoder.layer4.0.conv1.weight', 'encoder.layer4.0.bn1.weight', 'encoder.layer4.0.bn1.bias', 'encoder.layer4.0.bn1.running_mean', 'encoder.layer4.0.bn1.running_var', 'encoder.layer4.0.bn1.num_batches_tracked', 'encoder.layer4.0.conv2.weight', 'encoder.layer4.0.bn2.weight', 'encoder.layer4.0.bn2.bias', 'encoder.layer4.0.bn2.running_mean', 'encoder.layer4.0.bn2.running_var', 'encoder.layer4.0.bn2.num_batches_tracked', 'encoder.layer4.0.conv3.weight', 'encoder.layer4.0.bn3.weight', 'encoder.layer4.0.bn3.bias', 'encoder.layer4.0.bn3.running_mean', 'encoder.layer4.0.bn3.running_var', 'encoder.layer4.0.bn3.num_batches_tracked', 'encoder.layer4.0.downsample.0.weight', 'encoder.layer4.0.downsample.1.weight', 'encoder.layer4.0.downsample.1.bias', 'encoder.layer4.0.downsample.1.running_mean', 'encoder.layer4.0.downsample.1.running_var', 'encoder.layer4.0.downsample.1.num_batches_tracked', 'encoder.layer4.1.conv1.weight', 'encoder.layer4.1.bn1.weight', 'encoder.layer4.1.bn1.bias', 'encoder.layer4.1.bn1.running_mean', 'encoder.layer4.1.bn1.running_var', 'encoder.layer4.1.bn1.num_batches_tracked', 'encoder.layer4.1.conv2.weight', 'encoder.layer4.1.bn2.weight', 'encoder.layer4.1.bn2.bias', 'encoder.layer4.1.bn2.running_mean', 'encoder.layer4.1.bn2.running_var', 'encoder.layer4.1.bn2.num_batches_tracked', 'encoder.layer4.1.conv3.weight', 'encoder.layer4.1.bn3.weight', 'encoder.layer4.1.bn3.bias', 'encoder.layer4.1.bn3.running_mean', 'encoder.layer4.1.bn3.running_var', 'encoder.layer4.1.bn3.num_batches_tracked', 'encoder.layer4.2.conv1.weight', 'encoder.layer4.2.bn1.weight', 'encoder.layer4.2.bn1.bias', 'encoder.layer4.2.bn1.running_mean', 'encoder.layer4.2.bn1.running_var', 'encoder.layer4.2.bn1.num_batches_tracked', 'encoder.layer4.2.conv2.weight', 'encoder.layer4.2.bn2.weight', 'encoder.layer4.2.bn2.bias', 'encoder.layer4.2.bn2.running_mean', 'encoder.layer4.2.bn2.running_var', 'encoder.layer4.2.bn2.num_batches_tracked', 'encoder.layer4.2.conv3.weight', 'encoder.layer4.2.bn3.weight', 'encoder.layer4.2.bn3.bias', 'encoder.layer4.2.bn3.running_mean', 'encoder.layer4.2.bn3.running_var', 'encoder.layer4.2.bn3.num_batches_tracked', 'projection_head.mlp.0.weight', 'projection_head.mlp.0.bias', 'projection_head.mlp.2.weight', 'projection_head.mlp.2.bias', 'projection_head.mlp.4.weight', 'projection_head.mlp.4.bias', 'projection_head.mlp.6.weight', 'projection_head.mlp.6.bias', 'projection_head.mlp.9.weight', 'projection_head.mlp.9.bias', 'classifier.classifier.0.weight', 'classifier.classifier.0.bias', 'classifier.classifier.2.weight', 'classifier.classifier.2.bias', 'classifier.classifier.4.weight', 'classifier.classifier.4.bias', 'classifier.classifier.6.weight', 'classifier.classifier.6.bias', 'classifier.classifier.8.weight', 'classifier.classifier.8.bias', 'classifier.classifier.10.weight', 'classifier.classifier.10.bias', 'classifier.classifier.12.weight', 'classifier.classifier.12.bias', 'classifier.classifier.14.weight', 'classifier.classifier.14.bias'])\n",
            "✓ It's a model file - loading directly\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SSCLNet-Implementation/train_supervised.py\", line 223, in <module>\n",
            "    train_supervised()\n",
            "  File \"/content/SSCLNet-Implementation/train_supervised.py\", line 37, in train_supervised\n",
            "    model.load_state_dict(checkpoint, strict=False)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 2624, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for SSCLNet:\n",
            "\tsize mismatch for classifier.classifier.14.weight: copying a param with shape torch.Size([5, 16]) from checkpoint, the shape in current model is torch.Size([2, 16]).\n",
            "\tsize mismatch for classifier.classifier.14.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model Evaluation (2-class dataset)"
      ],
      "metadata": {
        "id": "i6o5ua1WvVC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing / model evaluation:\n",
        "!python \"/content/SSCLNet-Implementation/eval.py\""
      ],
      "metadata": {
        "id": "0enTVxdYvUv7",
        "outputId": "412f9c49-87a6-4494-a37e-fd672b2afcce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-01 14:11:59.013368: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762006319.044785   49718 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762006319.054319   49718 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762006319.077162   49718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762006319.077197   49718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762006319.077204   49718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762006319.077207   49718 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-01 14:11:59.084034: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "✓ All directories created\n",
            "✓ All directories created\n",
            "2025-11-01 14:12:05,587 - model_evaluation - INFO - === Model Evaluation on Test Set ===\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/SSCLNet-Implementation/eval.py\", line 216, in <module>\n",
            "    results = evaluate_model()\n",
            "              ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/SSCLNet-Implementation/eval.py\", line 30, in evaluate_model\n",
            "    model.load_state_dict(torch.load(config.SUPERVISED_SAVE_PATH))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 2624, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for SSCLNet:\n",
            "\tsize mismatch for classifier.classifier.14.weight: copying a param with shape torch.Size([5, 16]) from checkpoint, the shape in current model is torch.Size([2, 16]).\n",
            "\tsize mismatch for classifier.classifier.14.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Saving all the results and downloading it"
      ],
      "metadata": {
        "id": "EpoehPFIv-78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving it all for backup\n",
        "import os\n",
        "\n",
        "# Make a new folder in Colab’s /content directory\n",
        "new_folder = \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "os.makedirs(new_folder, exist_ok=True)\n",
        "\n",
        "print(f\"Created: {new_folder}\")"
      ],
      "metadata": {
        "id": "moy9a0cE2eUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/configs \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "!cp -r /content/logs \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "!cp -r /content/models \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "!cp -r /content/plots \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "!cp -r /content/results \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "!cp -r /content/runs \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "!cp -r /content/training_output \"/content/SSCLNet-implementation-outputs/2-class\"\n",
        "\n",
        "!zip -r SSCLNet_implementation_outputs_2Class.zip \"/content/SSCLNet-implementation-outputs/2-class\""
      ],
      "metadata": {
        "id": "zE1D5Tqq2kLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv SSCLNet_implementation_outputs_2Class.zip \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "8_kG0lVdzM25"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}